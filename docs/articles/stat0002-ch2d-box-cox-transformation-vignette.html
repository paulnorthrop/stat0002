<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chapter 2: Transformation Of Variable • stat0002</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/paper/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Chapter 2: Transformation Of Variable">
<meta property="og:description" content="stat0002">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">stat0002</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/stat0002-ch1a-shuttle-vignette.html">Chapter 1: The Challenger Space Shuttle Disaster</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch1b-stochastic-simulation-vignette.html">Chapter 1: Stochastic Simulation</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch2a-descriptive-statistics-vignette.html">Chapter 2: Descriptive Statistics</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch2b-graphs-vignette.html">Chapter 2: Graphs (One Variable)</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch2c-graphs-vignette.html">Chapter 2: Graphs (More Than One Variable)</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch2d-box-cox-transformation-vignette.html">Chapter 2: Transformation Of Variable</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch5a-discrete-random-variables-vignette.html">Chapter 5: binomial, geometric and Poisson distributions</a>
    </li>
    <li>
      <a href="../articles/stat0002-ch5b-continous-random-variables-vignette.html">Chapter 5: uniform, exponential and normal distributions</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/paulnorthrop/stat0002/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="stat0002-ch2d-box-cox-transformation-vignette_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Chapter 2: Transformation Of Variable</h1>
                        <h4 class="author">Paul Northrop</h4>
            
            <h4 class="date">2020-09-15</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/paulnorthrop/stat0002/blob/master/vignettes/stat0002-ch2d-box-cox-transformation-vignette.Rmd"><code>vignettes/stat0002-ch2d-box-cox-transformation-vignette.Rmd</code></a></small>
      <div class="hidden name"><code>stat0002-ch2d-box-cox-transformation-vignette.Rmd</code></div>

    </div>

    
    
<p><em>The vignette involves concepts that we won’t cover until Chapters 4 and 5 of the course: the probability density function (p.d.f.) of a continuous random variable and p.d.f.s of the normal and exponential distributions. For the purpose of this vignette we just need to appreciate that and that skewness (asymmetry) in the p.d.f. will tend to be reflected by skewness in data sampled from these distributions.</em></p>
<p>Suppose that we are provided with data, <span class="math inline">\((x_1, \ldots, x_n)\)</span> say, relating to a variable <span class="math inline">\(X\)</span> and a question of interest concerning some aspect of this variable. Our task is to analyse these data in order to try to answer the question. Naively, we may think that we must perform our calculations using <span class="math inline">\((x_1, \ldots, x_n)\)</span>, but this is not the case. It can be perfectly acceptable to analyse instead <span class="math inline">\((y_1, \ldots, y_n)\)</span>, where <span class="math inline">\(y_1 = g(x_1), \ldots, y_n = g(x_n)\)</span>, provided that the function <span class="math inline">\(g\)</span> used to transform <span class="math inline">\(x_i\)</span> into <span class="math inline">\(y_i\)</span> is such that our results can be translated back to answer the original question. Typically, <span class="math inline">\(g\)</span> is an invertible continuous function. The transformations that we have used in lectures: power and logarithmic transformations have these properties.</p>
<p>Your initial reaction may be that this seems like cheating: indeed some students have already suggested this to me. However, we do this kind of thing in mathematics all the time to simplify problems. We use transformation of variable (perhaps calling it <em>substitution</em>) to: solve polynomial equations; solve systems of equations; perform differentiation (e.g. the chain rule); transform a difficult integral into one that is easier, or that we have solved before; solve differential equations.</p>
<p>There can be benefits to working with <span class="math inline">\((y_1, \ldots, y_n)\)</span> instead of <span class="math inline">\((x_1, \ldots, x_n)\)</span>. The methods that we use to perform <em>statistical inference</em> (i.e. to analyse data to infer answers to questions) are often based on assumptions about the behaviour of the data. For example, we may assume that the data have been sampled from a particular probability distribution, e.g. a normal distribution, or that the mean of one variable of interest is linearly related to the value of another variable. These assumptions can be convenient because they lead to methods of analysis that are simple, convenient and well-understood. For more information and examples see <a href="https://en.wikipedia.org/wiki/Data_transformation_(statistics)">Data transformation</a>.</p>
<p>We don’t need to believe that these assumptions are exactly correct, but we should appreciate that if they are very far from being correct then our inferences may be misleading. If, for example, it seems clear from a plot of <span class="math inline">\((x_1, \ldots, x_n)\)</span> that the variable <span class="math inline">\(X\)</span> has a distribution that is strongly skewed then assuming that <span class="math inline">\((x_1, \ldots, x_n)\)</span> have been randomly from a normal distribution (which is a symmetric distribution) may be a bad idea. However, perhaps <span class="math inline">\(\ln X\)</span>, for example, is much closer being normally distributed than <span class="math inline">\(X\)</span>, or at least seems closer to being symmetrically distributed. If we use a method that is intended to work well for data sampled randomly from a normal distribution then it is better to analyse <span class="math inline">\((\ln x_1, \ldots, \ln x_n)\)</span> than <span class="math inline">\((x_1, \ldots, x_n)\)</span>.</p>
<p>Please note that transformation of data is by no means the only way to solve the problem that data do not behave in a way that is consistent with a convenient simple model. In particular, note that although the normal distribution is used in many areas of Statistics there are many instances where methods based on other distributions are more appropriate.</p>
<p>If we <em>do</em> wish to transform data then we need to consider which transformation to apply. The following family of <em>power</em> transformations can be helpful, provided that the data are positive. If they are not we could first add a constant to the data to achieve this property, or use a similar transformation (<span class="citation">Yeo and Johnson (2000)</span>) that does not require the data to be positive.</p>
<div id="box-cox-transformation" class="section level2">
<h2 class="hasAnchor">
<a href="#box-cox-transformation" class="anchor"></a>Box-Cox transformation</h2>
<p>The transformation that we have considered in the lectures is called a <a href="https://en.wikipedia.org/wiki/Power_transform#Box.E2.80.93Cox_transformation">Box-Cox transformation</a>, after the authors of a paper (<span class="citation">Box and Cox (1964)</span>) in which this type of transformation was studied extensively. (The names of the authors are a very pleasing coincidence, see <a href="https://en.wikipedia.org/wiki/Box_and_Cox">Box and Cox</a>.)</p>
<p>In it’s simplest form a Box-Cox transformation of <span class="math inline">\(x\)</span> to <span class="math inline">\(y\)</span> is given by <span class="math display">\[
  y = \left.
  \begin{cases}
    \displaystyle\frac{x^\lambda - 1}{\lambda}, &amp; \text{for } \lambda \neq 0, \\
    \ln (x), &amp; \text{for } \lambda = 0. \\
  \end{cases}
  \right.
\]</span> The inverse of this transformation is <span class="math display">\[
  x = \left.
  \begin{cases}
    \displaystyle(\lambda y + 1)^{1 / \lambda}, &amp; \text{for } \lambda \neq 0, \\
    \exp(y), &amp; \text{for } \lambda = 0. \\
  \end{cases}
  \right.
\]</span> Firstly, we consider how we could use a Box-Cox transformation to transform data relating to one variable so that they appear to be more symmetrically distributed. In <a href="#linearity">Transformation to Approximate Linearity</a> we use Box-Cox transformation to make the apparent relationship between two variables closer to being linear.</p>
</div>
<div id="transformation-to-approximate-symmetry" class="section level2">
<h2 class="hasAnchor">
<a href="#transformation-to-approximate-symmetry" class="anchor"></a>Transformation to Approximate Symmetry</h2>
<p>The normal (or Gaussian) distribution (Section 5.7 of the <a href="https://moodle.ucl.ac.uk/course/view.php?id=8579&amp;section=3">STAT0002 notes</a>) is a symmetric probability distribution. If <span class="math inline">\(Y = \ln X\)</span> has a normal distribution then <span class="math inline">\(X\)</span> has a <em>log-normal</em> distribution. This is a convenient example to study because if we know that we have a sample from a log-normal distribution then taking logs of the data produces a sample from a normal distribution.</p>
<div id="log-normal-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#log-normal-distribution" class="anchor"></a>Log-normal distribution</h3>
<p>The following code: simulates a sample of size 100 from a log-normal distribution; draws a histogram of these data with the log-normal p.d.f. superimposed; and then produces a similar plot after transforming using a log transformation (<code>lambda = 0</code>).</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r">&gt; library(stat0002)
Loading required package: rpanel
Loading required package: tcltk
Package `rpanel', version 1.1-4: type help(rpanel) for summary information
&gt; x &lt;- rlnorm(100)
&gt; boxcox_plot(x, density_fn = dlnorm, main = "data and true density function")
&gt; boxcox_plot(x, density_fn = dlnorm, lambda = 0, main = "after transformation")</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-3-1.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-3-2.png" width="326.4"></p>
<ol style="list-style-type: decimal">
<li><strong>I suggest that you try different values of <code>lambda</code> and look at the result in the plot.</strong></li>
</ol>
<p>In this example we <em>know</em> which value of <span class="math inline">\(\lambda\)</span> should produce approximate symmetry. When confronted with real data we won’t be in this position. However, we could look at a plot of the original data and judge whether we need to make the data less positively skewed (use <span class="math inline">\(\lambda &lt; 1\)</span>) or less negatively skewed (use <span class="math inline">\(\lambda &gt; 1\)</span>), and then use trial-and-error.</p>
<p>There is also a more automatic way to suggest a suitable value for <span class="math inline">\(\lambda\)</span>: we try a number of values of <span class="math inline">\(\lambda\)</span> and summarise how well a normal distribution fits the transformed data using the value of something called a <em>profile log-likelihood</em>. Don’t worry about what this means, just appreciate that larger values of the profile log-likelihood suggest a better fit. This produces a ‘best guess’ at the value of <span class="math inline">\(\lambda\)</span>. We can also produce a confidence interval for <span class="math inline">\(\lambda\)</span>. We don’t study confidence intervals in detail in STAT0002. The idea is that this interval is a measure of uncertainty about the value of <span class="math inline">\(\lambda\)</span>.</p>
<p>The function <code>boxcox</code> in the MASS package (<span class="citation">Venables and Ripley (2002)</span>) produces plot of the profile log-likelihood against <span class="math inline">\(\lambda\)</span>, with a 95% confidence interval for <span class="math inline">\(\lambda\)</span>. The <code>~ 1</code> bit in the <em>formula</em> notation <code>x ~ 1</code> below is specifying that there is no other variable to consider in addition to <code>x</code>. In <a href="#linearity">Transformation to Approximate Linearity</a> below we will extend this notation to deal with the case when consider two variables.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r">&gt; library(MASS, warn.conflicts = FALSE)
&gt; res &lt;- MASS::boxcox(x ~ 1)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-4-1.png" width="624"></p>
<div class="sourceCode" id="cb3"><html><body><pre class="r">&gt; # Find the value of lambda with the largest profile log-likelihood
&gt; res$x[which.max(res$y)]
[1] 0.1010101</pre></body></html></div>
<p>As we expect the ‘best’ value of <span class="math inline">\(\lambda\)</span> is close to zero and zero lies within the confidence intervals for <span class="math inline">\(\lambda\)</span>. Typically, we choose a simple value of <span class="math inline">\(\lambda\)</span>, e.g. a simple fraction or whole number, that is close to the ‘best’ and lies within the confidence interval.</p>
</div>
<div id="exponential-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#exponential-distribution" class="anchor"></a>Exponential distribution</h3>
<p>An exponential random variable (Section 5.6 of the <a href="https://moodle.ucl.ac.uk/course/view.php?id=8579&amp;section=3">STAT0002 notes</a>) exhibits strong positive skewness. Therefore, if we wish to Box-Cox transform data that have been sampled from an exponential distribution in order to make it more symmetric then we should use <span class="math inline">\(\lambda &lt; 1\)</span>. We can use the MASS function <code>boxcox</code> to help us to decide which value of <span class="math inline">\(\lambda\)</span> we could use. However, an exponential distribution is a special case of a gamma distribution (we don’t study this in STAT0002) and it has long been known (<span class="citation">Wilson and Hilferty (1931)</span>) that a cube root transformation tends to make a gamma random variable behave rather like a normal random variable. Therefore, <span class="math inline">\(\lambda = 1/3\)</span> might work well.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r">&gt; x2 &lt;- rexp(100)
&gt; boxcox_plot(x2, density_fn = dexp, main = "data and true density function")
&gt; boxcox_plot(x2, density_fn = dexp, lambda = 1 / 3, main = "after transformation")
&gt; boxcox(x2 ~ 1)
&gt; abline(v = 1/3, col = "red")</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-5-1.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-5-2.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-5-3.png" width="326.4"></p>
<p>We find that <span class="math inline">\(\lambda = 1/3\)</span> does work well and that the ‘best’ value, calculated by <code>boxcox</code> is close to 1/3.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Again, you could see the effects of using different values of <code>lambda</code>.</strong></li>
</ol>
</div>
<div id="a-triangular-distribution" class="section level3">
<h3 class="hasAnchor">
<a href="#a-triangular-distribution" class="anchor"></a>A triangular distribution</h3>
<p>We consider a simple probability distribution with p.d.f. <span class="math display">\[
  f_X(x) = \left.
  \begin{cases}
    2\,x, &amp; \text{for } 0 &lt; x &lt; 1, \\
    0, &amp; \text{otherwise}. \\
  \end{cases}
  \right.
\]</span> i.e. a triangle with base along (0,1). The functions <code>dtri</code> and <code>rtri</code> in the following code are used to calculate this p.d.f. and to simulate from this distribution, respectively. The latter uses the <em>inversion method</em> of simulation. See the <a href="https://moodle.ucl.ac.uk/course/view.php?id=8579&amp;section=8">Stochastic simulation video</a> for details.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r">&gt; # A function to define the p.d.f.
&gt; dtri &lt;- function(x) {
+   return(ifelse(x &gt; 0 &amp; x &lt; 1, 2 * x, 0))
+ }  
&gt; # A function to simulate from this distribution
&gt; rtri &lt;- function(n = 1) {
+   return(sqrt(runif(n)))
+ }  </pre></body></html></div>
<p>In this example it can be shown that using <span class="math inline">\(\lambda = 2\)</span> will produce a random variable whose p.d.f. is constant (and equal to 2) over the range (-1/2, 0), that is, we produce a uniform U(-1/2, 0) random variable (see Section 5.5 of the <a href="https://moodle.ucl.ac.uk/course/view.php?id=8579&amp;section=3">STAT0002 notes</a>).</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Can you prove that if a random variable <span class="math inline">\(X\)</span> has the triangular p.d.f. above then <span class="math inline">\(X^2\)</span> has a standard U(0,1) distribution and hence that <span class="math inline">\((X^2-1)/2\)</span> has a U(-1/2,0) distribution?</strong></li>
</ol>
<p>We simulate same data from this triangular distribution and show that using <span class="math inline">\(\lambda = 2\)</span> does indeed produce a density that is flat, and therefore symmetric.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r">&gt; x3 &lt;- rtri(200)
&gt; boxcox_plot(x3, density_fn = dtri)
&gt; boxcox_plot(x3, density_fn = dtri, lambda = 2)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-7-1.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-7-2.png" width="326.4"></p>
<p>Interestingly the <code>boxcox</code> function suggests a values of <span class="math inline">\(\lambda\)</span> that is close to 1.5 and the resulting transformed density is not particularly close to being symmetric. This is because the objective of the <code>boxcox</code> function is to seek a Box-Cox transformation for which the transformed density is as close as possible to being normal. It can’t do this very well in this case but we know that <span class="math inline">\(\lambda = 2\)</span> produces a density that is perfectly symmetric, although it is a uniform density, not a normal density.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r">&gt; boxcox(x3 ~ 1, lambda = seq(0, 4, 1 / 10))
&gt; boxcox_plot(x3, density_fn = dtri, lambda = 1.5)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-8-1.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-8-2.png" width="326.4"></p>
</div>
<div id="the-oxford-births-data" class="section level3">
<h3 class="hasAnchor">
<a href="#the-oxford-births-data" class="anchor"></a>The Oxford births data</h3>
<p>Suppose that we create a vector <code>x4</code> containing the Oxford birth durations. These are real data so we don’t know the true p.d.f.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r">&gt; x4 &lt;- ox_births$time
&gt; boxcox_plot(x4)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-9-1.png" width="624"></p>
<ol start="4" style="list-style-type: decimal">
<li><strong>What kind of Box-Cox transformation makes these data more symmetrically distributed?</strong></li>
</ol>
</div>
</div>
<div id="linearity" class="section level2">
<h2 class="hasAnchor">
<a href="#linearity" class="anchor"></a>Transformation to Approximate Linearity</h2>
<p>In Chapter 8 of the <a href="https://moodle.ucl.ac.uk/course/view.php?id=8579&amp;section=3">STAT0002 notes</a>) we study simple linear regression. In short, the idea is to suppose that the distribution of a <em>response variable</em> <span class="math inline">\(Y\)</span> has a mean that is a linear function of the observed value <span class="math inline">\(x\)</span> of an *explanatory variable <span class="math inline">\(X\)</span>. Alternatively, we could think of this as <span class="math inline">\(Y\)</span> being a linear function of <span class="math inline">\(x\)</span> plus some random error that has a zero mean.</p>
<div id="us-presidential-election-data-in-florida" class="section level3">
<h3 class="hasAnchor">
<a href="#us-presidential-election-data-in-florida" class="anchor"></a>2000 US Presidential Election Data in Florida</h3>
<p>Consider the following plot of the percentage of the vote obtained by the candidate Pat Buchanan (<span class="math inline">\(Y\)</span>) against the total population (in thousands of people) of the county (<span class="math inline">\(x\)</span>) in each of the 67 counties in Florida.</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r">&gt; xlab &lt;- "population (1000s)"
&gt; ylab &lt;- "Buchanan's % vote"
&gt; y &lt;- 100 * USelection$buch / USelection$tvot
&gt; x &lt;- USelection$npop / 1000
&gt; plot(x, y, pch = 16, xlab = xlab, ylab = ylab)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-10-1.png" width="624"></p>
<p>Clearly <span class="math inline">\(Y\)</span> is not linearly related to <span class="math inline">\(x\)</span>. In Section 8.4 of the notes we consider the use of transformation in the setting of simple linear regression. If we are hoping to use a <em>linear</em> regression model then one of the most important considerations is whether the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(x\)</span> is approximately linear. If it is not then one approach is to consider transforming <span class="math inline">\(Y\)</span> and/or <span class="math inline">\(x\)</span>. In the  we saw that we could choose these transformations using trial-and-error.</p>
<p>In <span class="citation">Smith (2002)</span> the author uses <span class="math inline">\(\sqrt{Y}\)</span> instead of <span class="math inline">\(Y\)</span> and <span class="math inline">\(\log(x)\)</span> instead of <span class="math inline">\(x\)</span>. In a lecture we found that this did indeed produce a relationship that looked much closer to being linear. Here we also use <span class="math inline">\(\log(x)\)</span> instead of <span class="math inline">\(x\)</span> and we use the <code>boxcox</code> function to suggest a Box-Cox transformation for <span class="math inline">\(y\)</span>. [It is possible to look to look simultaneously for the ‘best’ Box-Cox transformations of both <span class="math inline">\(Y\)</span> and <span class="math inline">\(x\)</span>, but the <code>boxcox</code> doesn’t provide this option.] In the regression setting the <code>boxcox</code> function seeks a transformation of <span class="math inline">\(Y\)</span> for which the distribution of the random error is as close as possible to being normal.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r">&gt; boxcox(y ~ log(x))</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-11-1.png" width="700"></p>
<p>Here the plot suggests that we might also transform <span class="math inline">\(Y\)</span> using <span class="math inline">\(\log(Y)\)</span>. The plot on the left below is of <span class="math inline">\(\log(Y)\)</span> against <span class="math inline">\(\log(x)\)</span> (we plot both variables on log scales). The plot on the right is of <span class="math inline">\(\sqrt{Y}\)</span> against <span class="math inline">\(x\)</span>.</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r">&gt; xlab &lt;- "population (1000s)"
&gt; ylab &lt;- "Buchanan vote"
&gt; plot(x, y, pch = 16, log = "xy", xlab = xlab, ylab = ylab)
&gt; ylab &lt;- expression(sqrt(Buchanan~vote))
&gt; plot(x, sqrt(y), pch = 16, log = "x", xlab = xlab, ylab = ylab)</pre></body></html></div>
<p><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-12-1.png" width="326.4"><img src="stat0002-ch2d-box-cox-transformation-vignette_files/figure-html/unnamed-chunk-12-2.png" width="326.4"></p>
<p>In both plots the relationships between the variables is closer to being approximately linear than in the original plot. We might argue that the plot on the left looks lightly better than the other plot and therefore we may question why Smith chose <span class="math inline">\(\sqrt{Y}\)</span> rather than <span class="math inline">\(\log Y\)</span>. However, the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(x\)</span> is far from the whole story. Smith’s model was much more complicated than this, and he has to worry about other assumptions, in addition to linearity.</p>
</div>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<script type="text/x-mathjax-config">
   MathJax.Hub.Config({  "HTML-CSS": { minScaleAdjust: 125, availableFonts: [] }  });
</script><div id="refs" class="references">
<div id="ref-BC1964">
<p>Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 26 (2): 211–52. <a href="https://doi.org/10.1111/j.2517-6161.1964.tb00553.x">https://doi.org/10.1111/j.2517-6161.1964.tb00553.x</a>.</p>
</div>
<div id="ref-Smith2002">
<p>Smith, R. L. 2002. “A Statistical Assessment of Buchanan’s Vote in Palm Beach County.” <em>Statist. Sci.</em> 17 (4): 441–57. <a href="https://doi.org/10.1214/ss/1049993203">https://doi.org/10.1214/ss/1049993203</a>.</p>
</div>
<div id="ref-MASS">
<p>Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with S</em>. Fourth. New York: Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4">http://www.stats.ox.ac.uk/pub/MASS4</a>.</p>
</div>
<div id="ref-WH1931">
<p>Wilson, E. B., and M. M. Hilferty. 1931. “The Distribution of Chi-Square.” <em>Proc. Natl. Acad. Sci. USA</em> 17 (12): 684–88. <a href="https://doi.org/10.1073/pnas.17.12.684">https://doi.org/10.1073/pnas.17.12.684</a>.</p>
</div>
<div id="ref-YJ2000">
<p>Yeo, I.-K., and Richard A. Johnson. 2000. “A New Family of Power Transformations to Improve Normality or Symmetry.” <em>Biometrika</em> 87 (4): 954–59. <a href="https://doi.org/10.1093/biomet/87.4.954">https://doi.org/10.1093/biomet/87.4.954</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Paul J. Northrop.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
