[{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1a-shuttle-vignette.html","id":"preliminaries","dir":"Articles","previous_headings":"","what":"Preliminaries","title":"Chapter 1: The Challenger Space Shuttle Disaster","text":"vignette contains ideas techniques covered later STAT0002 others (stochastic simulation logistic regression) part STAT0002 syllabus. Therefore, worry much details: just try get sense R code works. questions comments prompt think things. information R see STAT0004 Moodle page (taking STAT0004) Introduction R Moodle page (taking STAT0004, e.g. Natural Sciences students). functions shuttle_sim shuttle_sim_plot can viewed typing name function R command prompt >.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1a-shuttle-vignette.html","id":"the-challenger-space-shuttle-disaster","dir":"Articles","previous_headings":"","what":"The Challenger Space Shuttle Disaster","title":"Chapter 1: The Challenger Space Shuttle Disaster","text":"first lecture discussed Challenger Space Shuttle Disaster. vignette concerned mainly R code, little discussion problem, data statistical ideas. vignette consider R can used analyse data related disaster. See Dalal, Fowlkes, Hoadley (1989) information data analyses estimate probability catastrophic failure Challenger space shuttle launch conditions 28th January 1986. following R commands follow command prompt > # used create comment, , prevent R trying execute text contains comments rather command. First load stat0002 package.","code":"> library(stat0002)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1a-shuttle-vignette.html","id":"the-o-ring-data","dir":"Articles","previous_headings":"The Challenger Space Shuttle Disaster","what":"The O-ring data","title":"Chapter 1: The Challenger Space Shuttle Disaster","text":"data available data frame called shuttle. data frame R calls table data. Use ?shuttle find data. think NA means? Can guess R function prints last 6 lines data? Note different way get column want. produce bar plot numbers distressed O-rings scatter plot temperature pressure. See also vignette Chapter 2: Graphs (one variable).  Can see attach(shuttle) enabled us ? Type ?attach find attach() function . also note warning message? means exists another variable called pressure, R package called datasets. [Type library(help = \"datasets\") see datasets available datasets package.] Using attach(shuttle) means ask R variable pressure R gives us shuttle[, \"pressure\"]. Otherwise pressure give us data datasets package. highlights fact use attach() need careful.  Can work 3:5 bit used pairs() function ? Can see vector not_zero contains?  Can see/guess functions range title function arguments xlim, ann, xlab ylab ? see yet another way refer variable temperature shuttle dataset?","code":"> # Print the data to the screen  > shuttle    flight       date damaged temperature pressure 1       1 21/04/1981       0          66       50 2       2 12/11/1981       1          70       50 3       3 22/03/1982       0          69       50 4       4 11/11/1982       0          68       50 5       5 04/04/1983       0          67       50 6       6 18/06/1983       0          72       50 7       7 30/08/1983       0          73      100 8       8 28/11/1983       0          70      100 9       9 03/02/1984       1          57      200 10     10 06/04/1984       1          63      200 11     11 30/08/1984       1          70      200 12     12 05/10/1984       0          78      200 13     13 08/11/1984       0          67      200 14     14 24/01/1985       3          53      200 15     15 12/04/1985       0          67      200 16     16 29/04/1985       0          75      200 17     17 17/06/1985       0          70      200 18     18 29/07/1985       0          81      200 19     19 27/08/1985       0          76      200 20     20 03/10/1985       0          79      200 21     21 30/10/1985       2          75      200 22     22 26/11/1986       0          76      200 23     23 21/01/1986       1          58      200 24     24 28/01/1986      NA          31      200 > # The function head() prints only the first 6 lines of the data (useful to see the structure of large datasets) > head(shuttle)   flight       date damaged temperature pressure 1      1 21/04/1981       0          66       50 2      2 12/11/1981       1          70       50 3      3 22/03/1982       0          69       50 4      4 11/11/1982       0          68       50 5      5 04/04/1983       0          67       50 6      6 18/06/1983       0          72       50 > # Tabulate the number of O-rings with thermal distress > table(shuttle[, \"damaged\"])   0  1  2  3  16  5  1  1 > # Repeat and assign the output to the vector o_ring_table  > o_ring_table <- table(shuttle[, 3]) > barplot(o_ring_table, xlab = \"number of distressed O-rings\", ylab = \"frequency\") > attach(shuttle) The following object is masked from package:datasets:      pressure > plot(pressure, temperature) > # The opposite of the function attach() is the function detach() > detach(shuttle) > pairs(shuttle[, 3:5]) > # Remove the zeros from the O-ring damage data > not_zero <- shuttle$damaged > 0 > not_zero  [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE [13] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE  TRUE    NA > xlim <- range(shuttle$temperature) > xlim [1] 31 81 > # Plot with no zeros > plot(shuttle$temperature[not_zero], shuttle$damaged[not_zero], xlim = xlim, ylim = c(0, 3), ann = FALSE) > title(xlab = \"temperature / deg F\", ylab = \"number of distressed O-rings\") > # Plot of all the data > plot(shuttle$temperature, shuttle$damaged, ann = FALSE) > title(xlab = \"temperature / deg F\", ylab = \"number of distressed O-rings\")"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1a-shuttle-vignette.html","id":"relating-the-probability-of-o-ring-damage-to-temperature","dir":"Articles","previous_headings":"The Challenger Space Shuttle Disaster","what":"Relating the probability of O-ring damage to temperature","title":"Chapter 1: The Challenger Space Shuttle Disaster","text":"section involves statistical model, logistic regression model, part STAT0002 syllabus, don’t worry much details follow. However, section involves things study later STAT0002, namely independence, binomial distribution (general concept ) regression. fit model using general fitting method called maximum likelihood estimation. method formally part STAT0002 syllabus, look briefly later course. Consider six O-rings space shuttle. suppose launch temperature \\(t\\) degrees F: O-ring probability \\(p(t)\\) suffering thermal distress; whether given O-ring suffers thermal distress affected whether O-rings suffer thermal distress, , O-rings independent respect. assumptions number O-rings suffer thermal distress binomial distribution parameters \\(6\\) \\(p(t)\\). study distribution Chapter 5 STAT0002 notes. reason believe \\(p(t)\\) depends \\(t\\), , probability O-ring suffers thermal distress different different launch temperatures. simple model used kind situation linear logistic regression model, \\[ \\ln \\left(\\frac{p(t)}{1-p(t)}\\right) = \\alpha + \\beta t, \\] unknown constants \\(\\alpha\\) \\(\\beta\\). , logit \\(\\log[p(t) / (1-p(t))]\\) \\(p(t)\\) assumed linear function \\(t\\). Inverting equation gives \\[ p(t) = \\frac{e^{\\alpha + \\beta t}}{1 + e^{\\alpha + \\beta t}}. \\] make sense suppose \\(p(t)\\) linear function \\(t\\)? [Bear mind \\(p(t)\\) probability therefore can smaller 0 larger 1.] \\(p(t)\\) behave \\(t\\) becomes small, \\(t\\) becomes large, depend value \\(\\beta\\)? happens special case \\(\\beta = 0\\)? linear logistic regression model special case Generalized Linear Model. function glm() can used fit type model, using maximum likelihood estimation estimate unknown parameters (coefficients) \\(\\alpha\\) \\(\\beta\\). First create response data y (numbers O-rings without thermal distress) explanatory data x (launch temperatures). fit model. calculate fitted, estimated probability \\(p(t)\\) range temperatures includes 31 degrees F, stored numbers vector called fitted_probs. Can guess function seq ? Use ?seq find . plot proportions distressed O-rings temperature fitted logistic probability curve \\(p(t)\\) superimposed. second plot plot lecture slides.  Now produce better plot, one similar plot appears lecture slides.  Can see second plot different first plot identify bits R code ? find many options changing appearance plot use ?par.","code":"> # Create a matrix y containing 2 columns: > #   column 1: number of O-rings WITH thermal distress > #   column 2: number of O-rings WITHOUT thermal distress > y <- cbind(shuttle[1:23, 3], 6 - shuttle[1:23, 3]) > head(y)      [,1] [,2] [1,]    0    6 [2,]    1    5 [3,]    0    6 [4,]    0    6 [5,]    0    6 [6,]    0    6 > x <- shuttle[1:23, 4] > x  [1] 66 70 69 68 67 72 73 70 57 63 70 78 67 53 67 75 70 81 76 79 75 76 58 > shuttle_fit <- glm(y ~ x, family = binomial) > # Produce a summary of the estimates.  There is a lot of output: only look at the > # numbers in the column headed \"Estimate\". > summary(shuttle_fit)  Call: glm(formula = y ~ x, family = binomial)  Coefficients:             Estimate Std. Error z value Pr(>|z|)    (Intercept)  6.75183    2.97989   2.266  0.02346 *  x           -0.13971    0.04647  -3.007  0.00264 ** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  (Dispersion parameter for binomial family taken to be 1)      Null deviance: 28.761  on 22  degrees of freedom Residual deviance: 19.093  on 21  degrees of freedom AIC: 36.757  Number of Fisher Scoring iterations: 5 > alpha_hat <- shuttle_fit$coefficients[1] > beta_hat <- shuttle_fit$coefficients[2] > temp <- seq(from = 30, to = 85, by = 0.1) > linear_predictor <- alpha_hat + beta_hat * temp > fitted_curve <- exp(linear_predictor) / (1 + exp(linear_predictor)) > plot(shuttle$temperature, shuttle$damaged / 6, ann = FALSE, ylim = c(0, 1)) > title(xlab = \"temperature / deg F\", ylab = \"proportion of distressed O-rings\") > lines(temp, fitted_curve) > repeated_data <- which(duplicated(shuttle[, 3:4])) > shuttle[repeated_data, ]    flight       date damaged temperature pressure 11     11 30/08/1984       1          70      200 13     13 08/11/1984       0          67      200 15     15 12/04/1985       0          67      200 17     17 17/06/1985       0          70      200 22     22 26/11/1986       0          76      200 > new_damaged <- shuttle$damaged > new_damaged[c(11, 13, 17, 22)] <- new_damaged[c(11, 13, 17, 22)] + 0.2   > new_damaged[15] <- new_damaged[15] - 0.2   > plot(shuttle$temperature, new_damaged / 6, ann = FALSE, ylim = c(0, 1), pch = 16) > title(xlab = \"temperature (deg F)\", ylab = \"proportion of distressed O-rings\") > lines(temp, fitted_curve) > legend(\"topright\", legend = c(\"sample proportions\", \"fitted curve\"), pch=c(16, -1), lty = c(-1, 1)) > abline(v = 31, lty = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1a-shuttle-vignette.html","id":"using-stochastic-simulation-to-assess-uncertainty","dir":"Articles","previous_headings":"The Challenger Space Shuttle Disaster","what":"Using stochastic simulation to assess uncertainty","title":"Chapter 1: The Challenger Space Shuttle Disaster","text":"smooth curve superimposed plot immediately thought “truth”: merely estimate \\(\\hat{p}(t)\\), based single dataset simple modelling assumptions, probability \\(p(t)\\) O-ring distress might depend launch temperature \\(t\\). launches repeated, exactly conditions produced original data, (high probability) obtain different dataset hence different fitted smooth curve. , different experiments produce different datasets, leads different estimated curves therefore uncertainty \\(p(t)\\). reality able repeat launches one dataset, producing one estimated curve. However, appreciate dataset (estimated curve) one example taken population datasets (respective estimated curves) obtained. size uncertainty based one dataset related variable population estimated curves. estimated curves similar may matter get real dataset, findings similar datasets. However, estimated curves different findings vary lot depending dataset obtained. Although repeat launches can get idea much uncertainty \\(p(t)\\) given values \\(t\\) simulating fake datasets model fitted real data. involves getting computer `decide’ whether given O-ring suffers thermal distress launch temperature \\(t\\), random manner probability distress equals \\(\\hat{p}(t)\\). details can use computer generate pseudo-random numbers (numbers close enough random purposes) see vignette Stochastic simulation. function shuttle_sim simulates fake O-ring thermal distress data Challenger Space Shuttle launches different launch temperatures. following code simulates 10 fake datasets size 23, using real launch temperatures. function can also used simulate number distressed O-rings scenario launch space shuttle many times single temperature. 1000 times 31 degrees F. function shuttle_sim_plot plots multiple linear logistic curves. curve result simulating fake dataset linear logistic model fitted real data estimating linear logistic curve using fake dataset. following plot also contains real data (blue) curve showing curve fitted real data.  Given simulating data using computer consider scenario 10 launches carried temperature real dataset, .e. simulated datasets now size 23 x 10 = 230, rather 23. plot shows estimated curves vary different simulated datasets.  Now consider case simulated datasets size 2300.  See also function shuttle_movie animated version shuttle_sim_plot. Finally, produce plot (almost) Figure 1.6 notes.","code":"> # Simulate 10 fake datasets of size 23, using the real temperatures. > res <- shuttle_sim(n_sim = 10) > res    temps real sim1 sim2 sim3 sim4 sim5 sim6 sim7 sim8 sim9 sim10 1     66    0    0    0    2    0    0    1    0    2    0     0 2     70    1    0    0    0    0    0    1    0    0    1     0 3     69    0    0    0    0    0    0    0    0    1    0     0 4     68    0    0    0    1    0    0    1    0    0    1     2 5     67    0    2    0    0    0    0    0    0    0    0     0 6     72    0    1    1    0    0    0    0    0    0    0     1 7     73    0    0    0    0    0    0    0    0    1    0     0 8     70    0    1    0    1    0    0    2    0    0    0     2 9     57    1    1    0    1    3    0    3    2    1    4     0 10    63    1    1    1    1    0    0    0    0    2    0     0 11    70    1    0    1    1    0    2    1    0    0    0     0 12    78    0    0    0    1    0    0    0    0    0    0     0 13    67    0    1    0    0    1    0    0    0    1    0     0 14    53    3    1    3    3    0    2    3    2    2    1     1 15    67    0    0    0    1    0    1    0    1    1    0     1 16    75    0    0    0    1    0    0    0    0    0    0     0 17    70    0    2    0    0    1    0    1    1    0    1     0 18    81    0    0    1    0    1    0    0    0    0    0     0 19    76    0    0    0    0    0    0    1    0    0    0     0 20    79    0    0    0    0    0    0    0    0    1    1     0 21    75    2    0    0    0    0    0    0    0    0    0     0 22    76    0    0    1    0    1    0    0    0    1    0     0 23    58    1    2    2    0    1    2    2    2    2    0     2 > # Simulate the number of distressed O-rings for 1000 launches at 31 deg F. > res <- shuttle_sim(n_sim = 1000, temperature = 31) > res[1:100]   [1] 5 6 5 6 5 6 6 6 6 6 5 6 6 5 4 4 6 6 6 6 5 6 6 6 5 6 6 6 6 5 5 6 5 6 5 5 6  [38] 5 5 6 5 5 5 6 5 6 4 6 6 6 6 4 5 5 6 4 6 6 5 6 6 6 5 6 5 6 6 6 6 6 5 6 6 5  [75] 5 6 6 5 5 6 6 6 5 6 5 6 5 6 5 6 5 6 6 6 6 6 5 6 6 6 > table(res) res     2     3     4     5     6     15   204  1703  7336 13742 > shuttle_sim_plot(n_sim = 50, col = \"grey\") > shuttle_sim_plot(n_sim = 50, n_reps = 10, plot_real_data = FALSE, lty = 1) > shuttle_sim_plot(n_sim = 50, n_reps = 100, plot_real_data = FALSE, lty = 1) > x <- shuttle_sim_plot(n_sim = 1000, plot = FALSE) Warning: glm.fit: algorithm did not converge Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred > shuttle_sim_hists(x, temps = c(31, 50, 65, 80), col = 8)"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1b-stochastic-simulation-vignette.html","id":"pseudo-random-numbers-in-01","dir":"Articles","previous_headings":"","what":"Pseudo-random numbers in (0,1)","title":"Chapter 1: Stochastic Simulation","text":"basic building block stochastic simulation methods ability simulate numbers (pseudo-) randomly interval (0,1). see Chapter 5 STAT0002 notes equivalent generating numbers behave approximately like random sample standard uniform U(0,1) distribution. function R runif.","code":"> library(stat0002) > runif(10)  [1] 0.2716465 0.2459657 0.7786462 0.9790115 0.4347586 0.9141322 0.4885213  [8] 0.3757858 0.5054086 0.4264149"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1b-stochastic-simulation-vignette.html","id":"simulation-from-a-binomial-distribution","dir":"Articles","previous_headings":"","what":"Simulation from a binomial distribution","title":"Chapter 1: Stochastic Simulation","text":"Challenger Space Shuttle disaster vignette needed simulate numbers binomial distribution parameters \\(6\\) \\(p\\), given value \\(p\\). see Chapter 5 STAT0002 notes distribution arises number ‘successes’ (perversely, space shuttle example thermal distress O-ring ‘success’) fixed number (, 6) independent trials, trial results either ‘success’ ‘failure’. Suppose \\(p=0.2\\), approximate estimated probability (linear logistic model) O-ring suffers thermal distress space shuttle launched 58 degrees Fahrenheit. function R simulates binomial distribution rbinom. Can see convention way R’s simulation functions named? Underlying rbinom algorithm works quickly even cases number trials (size) large. small number trials, like 6, work directly, using numbers produced runif assign result trial ‘success’ ‘failure’. like tossing coin biased ‘heads’ obtained probability 0.2. function rbinomial simulates one value binomial distribution parameters size prob. Use ?rbinomial view help file. function less general less efficient rbinom. However, useful illustrate simple way simulate binomial distribution example can write R functions perform calculations. simulate one value binomial(6, 0.2) distribution. [use set.seed initialize pseudo-random number sequence particular place. enable us repeat calculations using exactly random numbers.] Can work happening line code inside rbinomial? following help. effect sum(distress) quite subtle. Can see happening? Check answer using ?sum. related point turn logical vector distress (contains TRUEs FALSEs) numeric vector, get …","code":"> rbinom(n = 1, size = 6, prob = 0.2) [1] 0 rbinomial <- function(size, prob) {   # Simulate size values (pseudo-)randomly between 0 and 1.   u <- runif(size)   # Find out whether (TRUE) or not (FALSE) each value of u is less than prob.   distress <- u < prob   # Count the number of TRUEs, i.e. the number of successes.   n_successes <- sum(distress)   # Return the number of successes.   return(n_successes) } > set.seed(1826) > rbinomial(size = 6, prob = 0.2) [1] 1 > set.seed(1826) > size <- 6 > prob <- 0.2 > u <- runif(size) > u [1] 0.3561567 0.9131876 0.5627795 0.1879185 0.3193222 0.6738423 > distress <- u < prob > distress [1] FALSE FALSE FALSE  TRUE FALSE FALSE > n_successes <- sum(distress) > n_successes [1] 1 > as.numeric(distress) [1] 0 0 0 1 0 0"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1b-stochastic-simulation-vignette.html","id":"simulation-from-a-exponential-distribution","dir":"Articles","previous_headings":"","what":"Simulation from a exponential distribution","title":"Chapter 1: Stochastic Simulation","text":"exponential distribution example probability distribution continuous random variable. Can guess name R function simulating exponential distribution? simulate sample size 1000 exponential distribution (rate) parameter equal 2. produce histogram simulated values superimpose probability density function (p.d.f.) exponential distribution values simulated.  Can guess function dexp ? Use ?dexp find . following R code also used simulate exponential distribution.","code":"> lambda <- 2 > exp_sim <- rexp(n = 1000, rate = lambda) > # A histogram (see Section 2.5 of the STAT0002 notes) > hist(exp_sim, probability = TRUE, ylim = c(0, lambda), main = \"\") > x <- seq(0, max(exp_sim), len = 500) > lines(x, dexp(x, rate = lambda)) > u <- runif(1000) > exp_inv <- -log(u)/lambda > hist(exp_inv, probability = TRUE, ylim = c(0, lambda), main = \"\", breaks = 14, col = \"grey\") > lines(x, dexp(x, rate = lambda))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1b-stochastic-simulation-vignette.html","id":"the-inversion-method","dir":"Articles","previous_headings":"","what":"The inversion method","title":"Chapter 1: Stochastic Simulation","text":"code immediately example inversion method simulation. following code implements normal distribution.  Use ?qnorm find qnorm . Note help page calls quantile function. alternative name inverse cumulative distribution function inverse c.d.f.","code":"> u <- runif(1000) > mu <- 0 > sigma <- 1 > norm_sim <- qnorm(u, mean = mu, sd = sigma) > hist(norm_sim, probability = TRUE, main = \"\", col = \"grey\") > x <- seq(min(norm_sim), max(norm_sim), len = 500) > lines(x, dnorm(x, mean = mu, sd = sigma))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1b-stochastic-simulation-vignette.html","id":"more-general-methods-of-simulation","dir":"Articles","previous_headings":"","what":"More general methods of simulation","title":"Chapter 1: Stochastic Simulation","text":"Often efficient method simulating values probability distribution one devised particular distribution. However, useful general methods can, principle, used simulate distribution, although, practice, constraints type distribution method can applied. Many methods work proposing values accepting rejecting using rule (hence often called acceptance-rejection rejection methods). See Morgan (1984) Jasra (2011) details. One method generalized ratio--uniforms method (Wakefield, Gelfand, Smith (1991) references therein), can used univariate distributions (involving one random variable) multivariate distributions (involving two random variables), provided p.d.f. distributions satisfies conditions. rust R package (Northrop 2017) implements algorithm. code can used simulate standard normal distribution using function ru.  Note main input function (natural) log p.d.f standard normal distribution, .e. log \\(\\frac{1}{\\sqrt{2\\pi}} e^{-\\frac12 x^2}\\); don’t need include normalizing constant \\(1/\\sqrt{2\\pi}\\), , constant included ensure p.d.f. integrates 1 support \\(-\\infty < x < \\infty\\) distribution. second point, typical feature rejection methods, can important cases can’t easily calculate normalizing constant. use ru simulate multivariate distribution using bivariate normal distribution. distribution studied second-year statistics module STAT0005. See Wikipedia page multivariate normal distribution form p.d.f. distribution. function log_dmvnorm calculates log p.d.f. multivariate normal distribution mean vector mean variance-covariance matrix sigma, ignoring normalizing constant. bivariate case plot method objects class “ru” produces scatter plot simulated values random variables \\((X_1, X_2)\\) contours value p.d.f. superimposed. contour labelled number indicating percentage simulated values lie within contour.  generalized ratio--uniforms method works well enough example efficient way simulate multivariate normal distribution. better function mvrnorm MASS package (Venables Ripley 2002). Use library(MASS) ?mvrnorm find .","code":"> library(rust) > ?ru > # Simulate from a standard normal N(0,1) distribution > ru_sim <- ru(logf = function(x) -x ^ 2 / 2, d = 1, n = 1000, init = 0.1) > # The function ru returns an object of class \"ru\" > class(ru_sim) [1] \"ru\" > # The default plot method for objects of class \"ru\" produces a plot to compare the  > # simulated values and the p.d.f. of the distribution from which they are simulated > plot(ru_sim, xlab = \"x\") > # two-dimensional normal with positive association ---------------- > rho <- 0.9 > covmat <- matrix(c(1, rho, rho, 1), 2, 2) > log_dmvnorm <- function(x, mean = rep(0, d), sigma = diag(d)) { +   x <- matrix(x, ncol = length(x)) +   d <- ncol(x) +   return(- 0.5 * (x - mean) %*% solve(sigma) %*% t(x - mean)) + } > ru_sim2 <- ru(logf = log_dmvnorm, sigma = covmat, d = 2, n = 1000, init = c(0, 0)) > plot(ru_sim2, xlab = expression(X[1]), ylab = expression(X[2]))"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Chapter 1: Stochastic Simulation 2","text":"document provides technical information supplement Stochastic simulation vignette. main purpose worksheet introduce computational technique, called stochastic simulation, lecturers UCL use illustrate statistical ideas results. aims consider stochastic simulation works, provide examples many uses Statistics show perform stochastic simulation using R. One examples, simple model epidemic, included owing relevance recent events, involves challenging material. matters important role played stochastic simulation. Therefore, concentrate text provide technical details appendix. already studied Statistics may familiar terminology used , “probability distribution” “probability density function”. , please worry: matters stage appreciate stochastic simulation useful.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"what-is-stochastic-simulation","dir":"Articles","previous_headings":"","what":"What is stochastic simulation?","title":"Chapter 1: Stochastic Simulation 2","text":"Stochastic means random. Simulate means imitate mimic. Stochastic simulation uses computer-generated pseudo-random numbers mimic stochastic real event dataset. Pseudo-random numbers random, produced deterministic algorithm. However, good pseudo-random number generator produce numbers appear us random may sufficient purposes. Pseudo-random numbers useful can produce lot quickly can repeat generation numbers need reproduce results. common task simulate numbers behave approximately like random sample particular probability distribution, , set numbers characteristic statistical properties distribution approximately unrelated .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"why-use-stochastic-simulation","dir":"Articles","previous_headings":"","what":"Why use stochastic simulation?","title":"Chapter 1: Stochastic Simulation 2","text":"studied Statistics may performed hypothesis testing calculated confidence intervals. examples statistical inference, drawing conclusions analysing data. examples exact mathematical results can derived perform tasks. Simple teaching examples often based random samples normal distributions. However, examples often simplistic real-world problems: involve unrealistically strong assumptions. relax assumptions increase realism tend find maths becomes much difficult. Often need satisfied mathematics produces results exact provide good approximation truth lot data. Stochastic simulation can enable us solve problems can’t maths. can maths can also used check maths. Examples : studying distribution statistic calculated data, sampling distribution; checking statistical procedure properties expect; estimating value integral; investigating properties distribution, model process simulating samples .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"how-to-simulate","dir":"Articles","previous_headings":"","what":"How to simulate","title":"Chapter 1: Stochastic Simulation 2","text":"purposes, knowing exactly pseudo-random numbers produced far less important understanding numbers can useful. However, provide information conveys general ideas.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"pseudo-random-numbers-in-01","dir":"Articles","previous_headings":"How to simulate","what":"Pseudo-random numbers in (0,1)","title":"Chapter 1: Stochastic Simulation 2","text":"building block stochastic simulation methods ability simulate numbers (pseudo-)randomly interval (0,1), using pseudo-random number generator (PRNG). Early approaches used linear congruential generator (LCG), based recurrence relation \\[ X_{+1} = (X_i + b) \\mod m, \\qquad = 0, 1, 2, \\ldots, \\] \\(m\\) positive integer \\(, b\\) \\(X_0\\) integers satisfying \\(0 < < m\\), \\(0 \\leq b < m\\) \\(0 \\leq X_0 < m\\). \\(X_0\\) known seed. \\(X_{+1}\\) remainder \\(X_i + b\\) divided \\(m\\) \\(X_{}\\) integer \\([0, m)\\) \\(\\). let \\(U_i = X_i / m\\) \\(U_i \\[0, 1)\\) \\(\\). seed \\(X_0\\) set numbers \\(U_1, U_2, \\ldots\\) clearly random: number determined previous one. Also, maximum number unique values \\(U_i\\) \\(m\\) therefore sequence values repeat period \\(k \\leq m\\). However, values \\(, b\\) \\(m\\) set carefully \\(k\\) large number \\(U_1, U_2, \\ldots\\) may appear initially us unrelated uniformly spread interval \\([0, 1)\\). Appearances can deceptive. Consider RANDU generator, used \\(m=2^{31}, =65539\\) \\(b=0\\). good PRNG produce numbers spread close randomly interval \\((0, 1)\\), successive pairs numbers spread close randomly unit square, successive triplets spread close randomly unit cube, . However, RANDU property consecutive triplets numbers fall one 15 two-dimensional planes, large spaces planes numbers can ever produced. LCGs non-random structure like , RANDU particularly bad example therefore longer used. following R function randu produces successive triplets RANDU generator, using \\(X_0 = 1\\). need worry code works, find functions involved using, example ?numeric help(numeric). call randu() argument N = 1000 simulate 10000 triplets. triplets plotted 3D scatter plot, using plot3d function rgl R package, loaded using library(rgl). rgl one many packages contributed individuals supplement base R. time writing 15707 packages. install package use, example, install.packages(\"rgl\"). 3D scatter plot successive triplets RANDU generator. plot rotated can see points lie 2D planes 3D space. able left click plot move mouse order rotate plot 3D. orientate plot correctly see RANDU’s non-random behaviour. (doesn’t work please look plot RANDU.) RANDU particularly bad PRNG. PRNG can perfect want avoid obvious non-random behaviour. Various statistical tests designed detect certain types non-random behaviour PRNG output. vignette RDieHarder R package provides examples. Improvements made basic setup described , resulting improved performance. general idea implementation complicated. interested please see Wikipedia PRNG page. mention briefly alternative approach, aims produce true random numbers, based measurements phenomena behave randomly. R packages random qrandom provide functions .","code":"randu <- function(N, X0 = 1) {   #   # Generates N successive triplets from the RANDU PRNG     #   # Arguments:   #   N  - an integer. The number of successive triplets required.   #   X0 - an integer. The value of the seed, the default value is 1.   # Returns:   #   An N by 3 numeric matrix.  Row i contains the ith triplet.   #   res <- numeric(N + 2)   res[1] <- X0       m <- 2 ^ 31   for (i in 2 + (0:N)) {     res[i] <- (65539 * res[i - 1]) %% m   }     res <- res / m   return(embed(res, 3)) } randu <- randu(10000) library(rgl) par(mar = c(0, 0, 0, 0)) plot3d(randu[, 1], randu[, 2], randu[, 3], xlab = expression(u[i]),         ylab = expression(u[i + 1]), zlab = expression(u[i + 2]))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"simulation-of-pseudo-random-numbers-in-r","dir":"Articles","previous_headings":"How to simulate","what":"Simulation of pseudo-random numbers in R","title":"Chapter 1: Stochastic Simulation 2","text":"generate pseudo-random numbers interval (0, 1) may use runif function. unif part name relates uniform distribution. view numbers generated using runif behaving approximately like random sample standard uniform U(0, 1) distribution. often refer simulating (random sample) uniform distribution. default R uses Mersenne-Twister generator. See ?Random details. repeat 3D plot exposed big problem RANDU, using numbers generated runif. 3D scatter plot successive triplets RANDU generator. plot rotated see obvious structure. non-random structure hidden can’t identify ! may use set.seed function set seed. set us R sets seed automatically based current time. following code simulates sample size 6 uniform distribution. get different sets numbers. set seed, simulate sample, reset seed simulate , obtain exactly numbers. may seem like strange thing , instances like use exactly set pseudo-random numbers, perhaps replicate previous results facilitate comparison two different approaches. seen can simulate \\(U(0, 1)\\) distribution, produce numbers \\(u_1, u_2, \\ldots\\). can use numbers simulate distributions.","code":"x <- embed(runif(10000 + 2), 3) par(mar = c(0, 0, 0, 0)) plot3d(x[, 1], x[, 2], x[, 3], xlab = expression(u[i]),         ylab = expression(u[i + 1]), zlab = expression(u[i + 2])) runif(6) [1] 0.20986848 0.72650247 0.08130657 0.33601900 0.16481928 0.90761011 runif(6) [1] 0.6682228 0.6435920 0.2264839 0.3549336 0.5715362 0.7045238 # Set a random number `seed'.   set.seed(29052020) runif(6) [1] 0.09185512 0.83476898 0.99637843 0.28297779 0.98253045 0.42240114 set.seed(29052020) runif(6) [1] 0.09185512 0.83476898 0.99637843 0.28297779 0.98253045 0.42240114"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"binomial","dir":"Articles","previous_headings":"How to simulate","what":"Simulation from a binomial distribution","title":"Chapter 1: Stochastic Simulation 2","text":"Consider experiment two outcomes possible: failure success. call experiment Bernoulli trial. Suppose conduct \\(n\\) Bernoulli trials record total number \\(Y\\) successes. suppose : () trials independent, , outcome trial completely unrelated outcome trials, (b) probability success equal \\(p\\), \\(0 \\leq p \\leq 1\\), trial. assumptions \\(Y\\) binomial distribution parameters \\(n\\) \\(p\\), \\(Y \\sim \\mbox{bin}(n, p)\\) short. direct, naive, way simulate binomial distribution use \\(n\\) numbers \\(u_1, \\ldots, u_n\\) generated runif. numbers property less \\(p\\) probability \\(p\\). Therefore, \\(u_1 < p\\) conclude result first trial success, similarly trials. like tossing coin biased ‘heads’ (success) obtained probability \\(p\\). simply count number successes. function rbinomial simulates one value binomial distribution parameters size (\\(n\\)) prob (\\(p\\)). simulate one value \\(\\mbox{bin}(6, 0.2)\\) distribution. Can work happening line code inside rbinomial? following help. effect sum(outcome) quite subtle. Can see happening? Check answer using ?sum. related point turn logical vector outcome (contains TRUEs FALSEs) numeric vector, get … function rbinomial slow \\(n\\) large. Can see ? -built function R simulates binomial distribution rbinom. Use ?rbinom find arguments rbinom mean. Unlike simple function rbinomial function rbinom can simulate one value binomial distribution. Can see convention way R’s simulation functions named? Underlying rbinom algorithm works quickly even cases number trials (size) large.","code":"rbinomial <- function(size, prob) {   #   # Simulates one value from a binomial(size, prob) distribution in a direct,     # but inefficient, way.   #   # Arguments:   #   size - an integer. The number of independent Bernoulli trials.   #   prob - a number in [0, 1] integer. The probability of success.   # Returns:   #   An integer: the total number of successes in size trials.   #   # Simulate size values (pseudo-)randomly between 0 and 1.   u <- runif(size)   # Find out whether (TRUE) or not (FALSE) each value of u is less than p.   outcome <- u < prob   # Count the number of TRUEs, i.e. the number of successes.   n_successes <- sum(outcome)   # Return the number of successes.   return(n_successes) } set.seed(2020) rbinomial(size = 6, prob = 0.2) [1] 2 set.seed(2020) size <- 6 prob <- 0.2 u <- runif(size) u [1] 0.64690284 0.39422576 0.61850181 0.47689114 0.13609719 0.06738439 outcome <- u < prob outcome [1] FALSE FALSE FALSE FALSE  TRUE  TRUE n_successes <- sum(outcome) n_successes [1] 2 as.numeric(outcome) [1] 0 0 0 0 1 1 rbinom(n = 1, size = 6, prob = 0.2) [1] 0 rbinom(n = 10, size = 6, prob = 0.2)  [1] 1 0 1 2 2 2 1 1 1 3"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"exponential","dir":"Articles","previous_headings":"How to simulate","what":"Simulation from an exponential distribution","title":"Chapter 1: Stochastic Simulation 2","text":"Consider non-negative continuous random variable \\(T\\) property \\(P(T > t) = e^{-\\lambda t}\\), \\(t \\geq 0\\) \\(\\lambda > 0\\). say \\(T\\) exponential distribution rate parameter \\(\\lambda\\) write \\(T \\sim \\mbox{exp}(\\lambda)\\) short. distribution appear later simple model epidemic expect can guess name R function simulating exponential distribution! simulate sample size 1000 exponential distribution parameter equal 2. crude check produce histogram simulated values superimpose probability density function (p.d.f.) exponential distribution values simulated.  p.d.f. exp(\\(\\lambda\\)) distribution given \\[   f_T(t) = \\left.   \\begin{cases}     \\lambda e^{-\\lambda t}, & \\text{} t \\geq 0 \\\\     0, & \\text{} t < 0. \\\\   \\end{cases}   \\right. \\] p.d.f. property integrates 1 real line can used calculate probabilities form \\(P(T \\[, b])\\). exponential case, \\(b > \\geq 0\\), \\[ P(T \\[, b]) = \\int_a^b f(t) \\mbox{ d}t = \\int_a^b \\lambda e^{-\\lambda t} \\mbox{ d}t = e^{-\\lambda } - e^{-\\lambda b}. \\] Can guess function dexp ? Use ?dexp find . can shown \\(U \\sim U(0,1)\\) \\(T = -\\frac{1}{\\lambda} \\ln U \\sim \\mbox{exp}(\\lambda)\\). means use following R code simulate exponential distribution.","code":"lambda <- 2 exp_sim <- rexp(n = 1000, rate = lambda) par(mar = c(4, 4, 1, 1)) hist(exp_sim, probability = TRUE, ylim = c(0, lambda), main = \"\", xlab = \"t\", ylab = \"density\") x <- seq(0, max(exp_sim), len = 500) lines(x, dexp(x, rate = lambda)) u <- runif(1000) exp_inv <- -log(u)/lambda par(mar = c(4, 4, 1, 1)) hist(exp_inv, probability = TRUE, ylim = c(0, lambda), main = \"\", xlab = \"t\", ylab = \"density\") lines(x, dexp(x, rate = lambda))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"the-inversion-method","dir":"Articles","previous_headings":"How to simulate","what":"The inversion method","title":"Chapter 1: Stochastic Simulation 2","text":"code immediately example inversion method simulation. following code implements normal distribution.  Use ?qnorm find qnorm . Note help page calls quantile function. alternative name inverse cumulative distribution function inverse c.d.f. c.d.f. random variable \\(X\\) \\(F_X(x) = P(X \\leq x)\\). denote inverse c.d.f. \\(F^{-1}_X(x)\\). can shown \\(U \\sim U(0,1)\\) \\(X = F_X^{-1}(U)\\) c.d.f. \\(F_X(x)\\), , \\(X\\) required distribution. inversion method requires us able evaluate quickly quantile function variable question. always case. Although may seem easy use qnorm simulate normal distribution using inversion method, calculations using qnorm fast R’s function rnorm uses efficient method avoids using quantile function. See ?rnorm. illustrated inversion method using one-dimensional continuous random variables, univariate case. approach can used simulate distribution discrete random variable multivariate case, , (joint) distribution set two related random variables.","code":"u <- runif(1000) mu <- 0 sigma <- 1 norm_sim <- qnorm(u, mean = mu, sd = sigma) hist(norm_sim, probability = TRUE, main = \"\", col = \"grey\",       xlab = \"simulated value\") x <- seq(min(norm_sim), max(norm_sim), len = 500) lines(x, dnorm(x, mean = mu, sd = sigma))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"other-methods-of-simulation","dir":"Articles","previous_headings":"How to simulate","what":"Other methods of simulation","title":"Chapter 1: Stochastic Simulation 2","text":"Often efficient method simulating values probability distribution one devised particular distribution. However, useful general methods can, principle, used simulate distribution, although, practice, constraints type distribution method can applied. Many methods work proposing values accepting rejecting using rule, hence often called acceptance-rejection rejection methods. principle methods can used \\(m\\)-dimensional multivariate case practice quickly become inefficient \\(m\\) increases.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"example-1--estimating-statistical-properties","dir":"Articles","previous_headings":"","what":"Example 1. Estimating statistical properties","title":"Chapter 1: Stochastic Simulation 2","text":"commonly-used summary random variable mean, also known expectation. random variable \\(X\\), denoted \\(\\mbox{E}(X)\\). continuous random variable \\(X\\), \\[ \\mbox{E}(X) = \\int_{-\\infty}^{\\infty} x f_X(x) \\mbox{ d}x. \\] simple cases integral can evaluated easily, instances easy. example, cases value p.d.f. \\(f_X(x)\\) calculated. able simulate distribution \\(X\\) can use simulated values estimate \\(\\text{E}(X)\\). technique called Monte Carlo integration.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"monte-carlo-integration","dir":"Articles","previous_headings":"Example 1. Estimating statistical properties","what":"Monte Carlo integration","title":"Chapter 1: Stochastic Simulation 2","text":"Suppose \\(X \\sim U(0,1)\\) can shown \\(\\mbox{E}(X) = 1/2\\). Can provide non-mathematical argument result? simulate large sample \\(x_1, \\ldots, x_n\\) \\(U(0,1)\\) distribution expect sample mean \\[\\bar{x} = \\frac1n \\sum_{=1}^{n} x_i\\] close \\(1/2\\). following R code checks . Hopefully, seems obvious. theory supports idea, Law large numbers. Loosely speaking, means estimate expectation variable provided sample mean can made precise like increasing size \\(n\\) simulated sample. short, sample mean converges expectation \\(n\\) tends infinity. illustrated following plot.  convergence see non-random quantity getting inexorably closer closer limit \\(1/2\\), \\(n\\) increases estimate can move \\(1/2\\) move back towards . -called weak law large numbers idea however close \\(1/2\\) require estimate , \\(n\\) tends infinity probability requirement satisfied tends \\(0\\). idea can generalised. Suppose \\(Y\\) p.d.f. \\(f_Y(y)\\) instead \\(\\mbox{E}(Y)\\) interested \\(\\mbox{E}(g(Y))\\) function \\(g\\). \\(\\mbox{E}(g(Y))\\) can calculated using \\[\\mbox{E}(g(Y)) = \\int_{-\\infty}^{\\infty} g(y) f_Y(y) \\mbox{ d}y.\\] simulate sample \\(y_1, \\ldots, y_n\\) distribution \\(Y\\) \\[\\frac1n \\sum_{=1}^{n} g(y_i)\\] can used estimate \\(\\mbox{E}(g(Y))\\).","code":"u <- runif(10000) mean(u) [1] 0.4994436 m <- cumsum(u) / seq_along(u) plot(seq_along(u), m, type = \"l\", xlab = \"n\", ylab = expression(estimate~of~E(X))) abline(h = 1/2, col = \"blue\", lty = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"estimating-pi-using-monte-carlo-integration","dir":"Articles","previous_headings":"Example 1. Estimating statistical properties","what":"Estimating \\(\\pi\\) using Monte Carlo integration","title":"Chapter 1: Stochastic Simulation 2","text":"familiar mathematical constant \\(\\pi \\approx 3.14159\\). can shown \\[ \\pi = 4 \\int_0^1 \\sqrt{1 - x ^ 2} \\mbox{ d}x = 4 \\int_0^1 g(x) f_X(x) \\mbox{ d}x, \\] \\(g(x) = \\sqrt{1 - x ^ 2}\\) \\(f_X(x) = 1\\) \\(0 \\leq x \\leq 1\\) \\(f(x) = 0\\) otherwise. Can explain true without integration? \\(f_X(x)\\) p.d.f. \\(U(0,1)\\) random variable. Therefore, \\(\\pi = 4\\,\\mbox{E}\\left(\\sqrt{1 - X ^ 2}\\right)\\), \\(X \\sim U(0,1)\\) simulate sample \\(x_1, \\ldots, x_n\\) \\(U(0,1)\\) distribution \\[\\hat{\\pi} = \\frac4n\\sum_{=1}^n \\sqrt{1 - x_i ^ 2}\\] estimate \\(\\pi\\) whose precision increases \\(n\\).  course, isn’t calculate \\(\\pi\\) practice presented 1-dimensional integral ‘hand’, may sensible use method numerical integration, example trapezium rule. However, many statistical problems \\(Y\\) \\(\\mbox{E}(g(Y))\\) \\(1-\\)dimensional \\(m-\\)dimensional, \\(m\\) large. sufficiently large \\(m\\), numerical integration techniques may effective Monte Carlo integration may better option. Monte Carlo estimate E\\((g(Y))\\) random quantity. quality can measured standard deviation, form \\(c /\\sqrt{n}\\). Tricks can used make value \\(c\\) smaller simple version described . can simulate effectively distribution \\(Y\\) (might easy!) make \\(c/\\sqrt{n}\\) small enough can produce precise estimate.","code":"n <- 1000 x <- runif(n) y <- sqrt(1 - x ^ 2) theta <- 4 * cumsum(y) / seq_len(n) plot(1:n, theta, type = \"l\", xlab = \"n\", ylab = expression(estimate~of~pi)) abline(h = pi, col = \"blue\", lty = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"SIR","dir":"Articles","previous_headings":"","what":"Example 2. A simple model for an epidemic","title":"Chapter 1: Stochastic Simulation 2","text":"Unfortunately, well aware serious consequences outbreak infectious disease importance measures mitigate effects epidemic. Understanding way infection spreads within population time, dynamics epidemic, can help governments decide measures use . common approach represent dynamics using model, based set assumptions. model isn’t correct, simplification reality. However, captures important aspects behaviour epidemic can useful. particular, may used answer `?’ questions, “may happen implement, relax, particular public health measures?”.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"SIRmodel","dir":"Articles","previous_headings":"Example 2. A simple model for an epidemic","what":"An SIR model","title":"Chapter 1: Stochastic Simulation 2","text":"consider simple epidemic model based stochastic process, collection quantities vary time undergoing random fluctuations. measure time days. simplicity, assume everybody recovers disease people population either: susceptible catching disease, infected disease, recovered disease life-long immunity disease. infected person recovers disease either become immune disease, enter recovered category, develop immunity return susceptible category. model general type called SIR model. describing assumptions model concept Poisson process important. Informally, Poisson process events interest occur singly, randomly independently constant rate \\(\\lambda\\) per day. observe differing numbers events different days, mean number \\(\\lambda\\) events per day constant time. key property Poisson process inspect arbitrarily chosen time time next event exponential(\\(\\lambda\\)) distribution. Model assumptions New people enter population Poisson process rate \\(\\alpha\\) per day. new person arrives probability \\(p_I\\) infected disease. infected person contacts people Poisson process rate \\(\\beta\\) per day. infected person contacts susceptible person infected immediately. infected person recovers time exponential(\\(\\gamma\\)) distribution, mean \\(1/\\gamma\\). person recovers probability become immune \\(p_R\\). addition assume person acts independently people processes governing infection, recovery arrival new people independent. relatively simple simulate model, can study epidemic might evolve time. written R function rSIR . function, technical details explain works, given appendix SIR theory simulation code","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"why-simulate-from-this-model","dir":"Articles","previous_headings":"Example 2. A simple model for an epidemic","what":"Why simulate from this model?","title":"Chapter 1: Stochastic Simulation 2","text":"Even simple model important properties may obtained easily using mathematics. example, may interested probability demand treatment disease exceed supply , exceeded, much exceeded long. answers latter questions single numbers probability distributions particular difficult obtain simple form. problem even difficult realistic model. Simulation allows us answer questions simulating model, using parameter values considered relevant, calculating quantities interest based simulated data. simulate many times can estimate probability event happens, using proportion simulations happens, study important quantities vary simulations.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"example-simulations","dir":"Articles","previous_headings":"Example 2. A simple model for an epidemic","what":"Example simulations","title":"Chapter 1: Stochastic Simulation 2","text":"following simulations illustrate general behaviour SIR model epidemic SIR model, using parameter values chosen fairly arbitrary way. cases consider initial population size 1000 people simulate period 100 days.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"what-if-post-infection-immunity-is-likely","dir":"Articles","previous_headings":"Example 2. A simple model for an epidemic > Example simulations","what":"What if post-infection immunity is likely?","title":"Chapter 1: Stochastic Simulation 2","text":"Firstly, suppose initially 10 infected people rest population susceptible. suppose : new people arrive rate \\(\\alpha = 1 / 10\\) per day \\(p_I = 10\\%\\) people infected infected people contact people rate \\(\\beta = 1\\) per day average people remain infected \\(1/\\gamma = 5\\) days immune probability \\(p_R = 90\\%\\).  infection arrives population number infected people increases quickly. expect basic reproduction number \\(R_0\\) equal \\(\\beta / \\gamma = 5\\), greater 1. number infected people drops quickly many people become immune. end 100 days still approximately 100 susceptible people population. means disease spread point future, outbreak may less dramatic proportion susceptible people population low. Suppose resources treat infected 500 people one time. repeat simulation SIR model 100 times. plot evolution number infected people calculate proportion simulations number infected people exceeds 500 100-day period. give estimate 69% probability resources sufficient.","code":"set.seed(31052020) # parameters: (alpha, pI, beta, pR, gamma) pars1 <- c(1/10, 0.1, 1, 1/5, 0.9) I0 <- 10 r1 <- rSIR(pars = pars1, I0 = I0) par(mar = c(4, 4, 1, 1)) leg <- c(\"susceptible\", \"infected\", \"immune\", \"population\") matplot(r1[, 1], r1[, -1], type = \"l\", lty = 1, lwd = 2, col = 1:4,          ylab = \"number of people\", xlab = \"time / days\") legend(\"right\", legend = leg, lty = 1, lwd = 2, col = 1:4, bg = \"transparent\") set.seed(31052020) r1 <- rSIR(pars = pars1, I0 = I0) par(mar = c(4, 4, 1, 1)) matplot(r1[, 1], r1[, 3], type = \"l\", ylab = \"number of infected people\",          xlab = \"time / days\", ylim = c(0, 550), col = 2) nsim <- 100 gt500 <- numeric(nsim) gt500[1] <- any(r1[, 3] > 500) for (i in 2:nsim) {   r2 <- rSIR(pars = pars1, I0 = I0)   matlines(r2[, 1], r2[, 3], col = 2)   gt500[i] <- any(r2[, 3] > 500) } abline(h = 500, lty = 2) mean(gt500) [1] 0.69"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"what-if-post-infection-immunity-is-unlikely","dir":"Articles","previous_headings":"Example 2. A simple model for an epidemic > Example simulations","what":"What if post-infection immunity is unlikely?","title":"Chapter 1: Stochastic Simulation 2","text":"re-run first simulation probability \\(p_R\\) post-infection immunity set 10%, rather 90%. also extend simulation 200 days.  Now behaviour rather different. number people immune rises slowly number infected people drops slowly peak. end 200 days approximately 20% population susceptible disease new infected person arrives. model clearly useful representation COVID-19 outbreak, doesn’t reflect reality way disease transmitted public health measures used mitigate effects. Also parameter values used informed expert knowledge estimated data. Can note ways structure models assumptions unrealistic? might made realistic? see ways kind model extended increase realism regard COVID-19 outbreak, see Simulating COVID-19 interventions R. read see although several simulations performed results averaged simulations presented. Studying behaviour averages time potentially dangerous, may hide important information variable results different simulations.","code":"set.seed(31052020) # parameters: (alpha, pI, beta, pR, gamma) pars2 <- c(1/10, 0.1, 1, 1/5, 0.1) r2 <- rSIR(pars = pars2, I0 = I0, days = 200) par(mar = c(4, 4, 1, 1)) matplot(r2[, 1], r2[, -1], type = \"l\", lty = 1, lwd = 2, col = 1:4,          ylab = \"number of people\", xlab = \"time / days\") legend(\"right\", legend = leg, lty = 1, lwd = 2, col = 1:4, bg = \"transparent\")"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"concluding-remarks","dir":"Articles","previous_headings":"","what":"Concluding remarks","title":"Chapter 1: Stochastic Simulation 2","text":"hope convinced stochastic simulation useful technique given idea works. presented two examples, simulation many uses. example, simulation can used fit models cases possible perform mathematics required traditional fitting methods. general idea data simulated good model real data look like real data, therefore identify combinations parameters case.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"SIRappendix","dir":"Articles","previous_headings":"","what":"Appendix: SIR theory and simulation code","title":"Chapter 1: Stochastic Simulation 2","text":"Let \\(S(t), (t)\\) \\(R(t)\\) denote denote respective numbers susceptible, infected recovered people, \\(N(t) = S(t) + (t) + R(t)\\) population size, time \\(t\\). Let \\(X(t) = (S(t), (t), R(t))\\). start process time \\(0\\), \\(N(0)\\) people population \\(S(0), (0)\\) \\(R(0)\\) people three disease categories. assumptions SIR model convenient mathematically, , make easier study certain properties epidemic. particular, following property holds. Markov property. know value \\(X(t)\\) future evolution disease depend numbers infected, susceptible recovered people prior time \\(t\\).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch1c-stochastic-simulation-vignette-2.html","id":"simulation-from-this-model","dir":"Articles","previous_headings":"Appendix: SIR theory and simulation code","what":"Simulation from this model","title":"Chapter 1: Stochastic Simulation 2","text":"easy simulate Markov process, breaks two separate parts. long something changes? kind change ? common refer change “jump”. , jump reflects something happening one person. question 1, doesn’t matter type event causes jump. Suppose time \\(t\\), \\((S(t), (t)) = (s, )\\). need consider overall rate events happen conditions. rate \\(\\phi = \\alpha + \\beta s / n + \\gamma \\, \\). rate new arrivals \\(\\alpha\\). \\(\\beta s / n\\) term overall infection rate, follows \\(\\) people infect others contacts probability \\(s / n\\) susceptible person. overall recovery rate \\(\\) infected people \\(\\gamma \\, \\), infected person recovering rate \\(\\gamma\\). Special properties exponential distribution mean time next jump exponential distribution, rate equal overall rate. question 2, probability event particular type first event occur proportional rate occurrence. fact, probability proportional ’s rate occurrence. question 2 need also consider whether arrival infected whether infected person becomes immune recovery. Simulation model Suppose \\(X(t) = (S(t), (t), R(t)) = (s, , r)\\). time next jump exponential(\\(\\phi\\)) distribution, \\(\\phi = \\alpha + \\beta s / n + \\gamma \\, \\). \\((s, + 1, r)\\) probability \\(\\alpha p_I / \\phi\\) \\(~~~~~~~~~~~~~~~~~~~~~~~~~~\\)(arrival infected person) \\((s + 1, , r)\\) probability \\(\\alpha (1 - p_I) / \\phi\\) \\(~~~~~~~~~~~~~~~\\) (arrival susceptible person) \\((s, - 1, r + 1)\\) probability \\(\\gamma \\, p_R / \\phi\\) \\(~~~~~~~~~~~~~~~~\\) (recovery immunity) \\((s + 1, - 1, r)\\) probability \\(\\gamma (1 - p_R) / \\phi\\) \\(~~~~~~\\) (recovery immunity) \\((s - 1, + 1, r)\\) probability \\((\\beta s / n) / \\phi\\) \\(~~~~~~~~~~~\\) (infection susceptible) overall rate \\(\\alpha\\) arrival splits rate \\(\\alpha p_I\\) infected arrivals \\(\\alpha (1 - p_I)\\) susceptible arrivals. Similarly, overall recovery rate \\(\\) infected people \\(\\gamma \\), splits rate \\(\\gamma \\, p_R \\) recovery immunity \\(\\gamma (1 - p_R) \\) recovery without immunity. already simulate exponential distribution simulation outcome jump simple extension, 2 outcomes 5 outcomes, idea used simulating binomial distribution. Markov property means process jumps, time \\(t_2 > t\\) say, can just start parts 1 2. value \\(X(t_2)\\) matters, history reached. simulation performed using two R functions. rSIR function call set simulation. SIRjump called repeatedly within rSIR: call simulates next change, jump state process. arguments (inputs) functions explained comments start. Default values arguments given first line function. can change specifying different numbers use rSIR","code":"rSIR <- function(N0 = 1000, I0 = 0, S0 = N0 - I0, days = 100,                   pars = c(1, 0.1, 2, 1, 0.9)) {   #   # Simulates from a simple stochastic SIR epidemic model   #   # Arguments:   #   N0     - an integer. The population size at time 0.   #   I0     - an integer. The initial number of infected people.   #   S0     - an integer. The initial number of susceptible people.   #   R0     - an integer. The initial number of recovered people.   #   days   - an integer. The number of days for which to simulate.   #   pars   - a numeric vector: (alpha, pI, beta, pR, gamma).    #     alpha : rate of arrival of people into the population   #     pI    : probability that an arrival is infected   #     beta  : individual infection rate at time t is beta / Nt   #     gamma : recovery rate for each infected individual   #     pR    : probability that an infected person is immune after recovery   #      # Returns:   #   A numeric matrix with 5 columns.  Row i contains the values of    #   (t, S_t, I_t, R_t, N_t) immediately after transition i - 1.   #   # Checks:   if (I0 + S0 > N0) {     stop(\"There can be at most N people who are susceptible or infected\")   }   # Infer the number of recovered people   R0 <- N0 - I0 - S0   # The initial state, at time = 0   x <- c(0, S0, I0, R0, N0)   # A list in which to store the results   res <- list()   i <- 1   # Simulate the next change, or jump, in the process until days have passed   while (x[1] < days) {     res[[i]] <- x     x <- SIRjump(x, pars)     i <- i + 1   }   # Convert the list to a matrix   res <- do.call(rbind, res)   colnames(res) <- c(\"t\", \"St\", \"It\", \"Rt\", \"Nt\")   return(res) }  SIRjump <- function (x, pars) {   #   # Simulates one jump from a simple stochastic SIS epidemic model   #   # Arguments:   #   x    - a numeric vector: (time, S, I, R, N) at the previous jump.   #   pars - a numeric vector: (alpha, pI, beta, gamma, pR).    #      # Returns:   #   a numeric vector: (time, S, I, R, N) immediately after the next jump     #   # The numbers of susceptible and infected people and the population size   St <- x[2]   It <- x[3]   Rt <- x[4]   Nt <- x[5]   # The parameter values   alpha <- pars[1]   pI <- pars[2]   beta <- pars[3]   gamma <- pars[4]   pR <- pars[5]   # Simulate the time at which the next transition occurs   total_rate <- alpha + beta * St * It / Nt + gamma * It   x[1] <- x[1] + rexp(1, total_rate)   # Jump probabilities   p1 <- alpha * pI / total_rate   p2 <- alpha * (1 - pI) / total_rate   p3 <- gamma * pR * It / total_rate   p4 <- gamma * (1 - pR) * It / total_rate   u <- runif(1)   if (u < p1) {     # Arrival of a new infected person It increases by 1, Nt increases by 1     x[3] <- x[3] + 1      x[5] <- x[5] + 1    } else if (u < p1 + p2) {     # Arrival of a new susceptible person St increases by 1, Nt increases by 1     x[2] <- x[2] + 1      x[5] <- x[5] + 1    } else if (u < p1 + p2 + p3) {     # Infected person becomes immune: It decreases by 1, Rt increases by 1     x[3] <- x[3] - 1     x[4] <- x[4] + 1    } else if (u < p1 + p2 + p3 + p4) {     # Infected person becomes susceptible: It decreases by 1, St increases by 1     x[3] <- x[3] - 1     x[2] <- x[2] + 1    } else {     # Infection of a susceptible: St decreases by 1, It increases by 1     x[2] <- x[2] - 1     x[3] <- x[3] + 1    }   return(x) }"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"the-oxford-birth-times-data","dir":"Articles","previous_headings":"","what":"The Oxford Birth Times data","title":"Chapter 2: Descriptive Statistics","text":"data available data frame ox_births. Use ?ox_births find data. manipulate data matrix format Table 2.1 notes. number birth times varies days pad matrix R’s missing values code NA order column matrix number rows. Can see following parts code ? return matrix later. calculate summary statistics dataset containing birth times days week.","code":"> library(stat0002) > ox_mat <- matrix(NA, ncol = 7, nrow = 16) > for (i in 1:7) { +   day_i_times <- ox_births$time[which(ox_births$day == i)] +   ox_mat[1:length(day_i_times), i] <- sort(day_i_times) +   colnames(ox_mat) <- paste(\"day\", 1:7, sep = \"\") + }   > ox_mat        day1  day2  day3  day4  day5  day6  day7  [1,]  2.10  4.00  2.60  1.50  2.50  4.00  2.00  [2,]  3.40  4.10  3.60  4.70  2.50  4.00  2.70  [3,]  4.25  5.00  3.60  4.70  3.40  5.25  2.75  [4,]  5.60  5.50  6.40  7.20  4.20  6.10  3.40  [5,]  6.40  5.70  6.80  7.25  5.90  6.50  4.20  [6,]  7.30  6.50  7.50  8.10  6.25  6.90  4.30  [7,]  8.50  7.25  7.50  8.50  7.30  7.00  4.90  [8,]  8.75  7.30  8.25  9.20  7.50  8.45  6.25  [9,]  8.90  7.50  8.50  9.50  7.80  9.25  7.00 [10,]  9.50  8.20 10.40 10.70  8.30 10.10  9.00 [11,]  9.75  8.50 10.75 11.50  8.30 10.20  9.25 [12,] 10.00  9.75 14.25    NA 10.25 12.75 10.70 [13,] 10.40 11.00 14.50    NA 12.90 14.60    NA [14,] 10.40 11.20    NA    NA 14.30    NA    NA [15,] 16.00 15.00    NA    NA    NA    NA    NA [16,] 19.00 16.50    NA    NA    NA    NA    NA > i <- 4 > ox_births$day == i  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE [49]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE > which(ox_births$day == i)  [1] 44 45 46 47 48 49 50 51 52 53 54 > ox_births$time[which(ox_births$day == i)]  [1]  8.10 10.70 11.50  7.20  7.25  9.50  8.50  1.50  4.70  4.70  9.20 > paste(\"day\", 1:7, sep = \"\") [1] \"day1\" \"day2\" \"day3\" \"day4\" \"day5\" \"day6\" \"day7\" > paste(\"day\", 1:7, sep = \" \") [1] \"day 1\" \"day 2\" \"day 3\" \"day 4\" \"day 5\" \"day 6\" \"day 7\" > birth_times <- ox_births[, \"time\"] > sort(birth_times)  [1]  1.50  2.00  2.10  2.50  2.50  2.60  2.70  2.75  3.40  3.40  3.40  3.60 [13]  3.60  4.00  4.00  4.00  4.10  4.20  4.20  4.25  4.30  4.70  4.70  4.90 [25]  5.00  5.25  5.50  5.60  5.70  5.90  6.10  6.25  6.25  6.40  6.40  6.50 [37]  6.50  6.80  6.90  7.00  7.00  7.20  7.25  7.25  7.30  7.30  7.30  7.50 [49]  7.50  7.50  7.50  7.80  8.10  8.20  8.25  8.30  8.30  8.45  8.50  8.50 [61]  8.50  8.50  8.75  8.90  9.00  9.20  9.25  9.25  9.50  9.50  9.75  9.75 [73] 10.00 10.10 10.20 10.25 10.40 10.40 10.40 10.70 10.70 10.75 11.00 11.20 [85] 11.50 12.75 12.90 14.25 14.30 14.50 14.60 15.00 16.00 16.50 19.00"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"five-number-summary","dir":"Articles","previous_headings":"","what":"Five number summary","title":"Chapter 2: Descriptive Statistics","text":"function five_number calculates five number summary data, using particular method estimating lower quartile, median upper quartile described STAT0002 notes. summary function can also used calculate five number summary. (ignore fact summary also calculates sample mean) summary produce values five_number? , estimates lower quartile differ. functions summary five_number use different rules estimate quantiles: summary calls quantile using type = 7 whereas five_number uses type = 6. call five_number type = 7 get numbers summary. fact function quantile 9 different options type. Use ?quantile information.","code":"> five_number(birth_times)   min   25%   50%   75%   max   1.50  4.90  7.50  9.75 19.00 > summary(birth_times)    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    1.500   4.950   7.500   7.723   9.750  19.000 > five_number(birth_times, type = 7)   min   25%   50%   75%   max   1.50  4.95  7.50  9.75 19.00"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"sample-mean","dir":"Articles","previous_headings":"","what":"Sample mean","title":"Chapter 2: Descriptive Statistics","text":"","code":"> mean(birth_times) [1] 7.723158"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"sample-standard-deviation-and-variance","dir":"Articles","previous_headings":"","what":"Sample standard deviation and variance","title":"Chapter 2: Descriptive Statistics","text":"","code":"> sd(birth_times) [1] 3.568097 > var(birth_times) [1] 12.73132 > sd(birth_times) ^ 2 [1] 12.73132"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"measures-of-skewness","dir":"Articles","previous_headings":"","what":"Measures of skewness","title":"Chapter 2: Descriptive Statistics","text":"2017/18 STAT0002 notes gave -0.063 sample quartile skewness. used default setting, type = 7, quantile function calculating …","code":"> # Standardized sample skewness > skew(birth_times) [1] 0.6254774 > # Sample quartile skewness > q_skew(birth_times) [1] -0.07216495 > q_skew(birth_times, type = 7) [1] -0.0625"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2a-descriptive-statistics-vignette.html","id":"summary-statistics-for-each-day","dir":"Articles","previous_headings":"","what":"Summary statistics for each day","title":"Chapter 2: Descriptive Statistics","text":"can also calculate summary statistics seven days week, .e. columns ox_mat. following effect colMeans function fairly obvious. apply useful function. Use ?apply see .","code":"> five_number(ox_mat, na.rm = TRUE)       day1    day2   day3 day4    day5   day6    day7 min  2.100  4.0000  2.600  1.5  2.5000  4.000  2.0000 25%  5.800  5.5500  5.000  4.7  4.0000  5.675  2.9125 50%  8.825  7.4000  7.500  8.1  7.4000  7.000  4.6000 75% 10.300 10.6875 10.575  9.5  8.7875 10.150  8.5000 max 19.000 16.5000 14.500 11.5 14.3000 14.600 10.7000 > summary(ox_mat)       day1             day2             day3            day4         Min.   : 2.100   Min.   : 4.000   Min.   : 2.60   Min.   : 1.500    1st Qu.: 6.200   1st Qu.: 5.650   1st Qu.: 6.40   1st Qu.: 5.950    Median : 8.825   Median : 7.400   Median : 7.50   Median : 8.100    Mean   : 8.766   Mean   : 8.312   Mean   : 8.05   Mean   : 7.532    3rd Qu.:10.100   3rd Qu.:10.062   3rd Qu.:10.40   3rd Qu.: 9.350    Max.   :19.000   Max.   :16.500   Max.   :14.50   Max.   :11.500                                      NA's   :3       NA's   :5              day5             day6             day7         Min.   : 2.500   Min.   : 4.000   Min.   : 2.000    1st Qu.: 4.625   1st Qu.: 6.100   1st Qu.: 3.237    Median : 7.400   Median : 7.000   Median : 4.600    Mean   : 7.243   Mean   : 8.085   Mean   : 5.537    3rd Qu.: 8.300   3rd Qu.:10.100   3rd Qu.: 7.500    Max.   :14.300   Max.   :14.600   Max.   :10.700    NA's   :2        NA's   :3        NA's   :4 > colMeans(ox_mat, na.rm = TRUE)     day1     day2     day3     day4     day5     day6     day7  8.765625 8.312500 8.050000 7.531818 7.242857 8.084615 5.537500 > apply(ox_mat, 2, sd, na.rm = TRUE)     day1     day2     day3     day4     day5     day6     day7  4.296654 3.629348 3.733798 2.937880 3.565532 3.223313 2.887286 > skew(ox_mat, na.rm = TRUE) [1]  0.6868543  0.8553875  0.2874617 -0.5639013  0.4105886  0.5136015  0.4524077 > q_skew(ox_mat, na.rm = TRUE) [1] -0.3444444  0.2798054  0.1031390 -0.4166667 -0.4203655  0.4078212  0.3959732"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"the-oxford-birth-times-data","dir":"Articles","previous_headings":"","what":"The Oxford Birth Times data","title":"Chapter 2: Graphs (One Variable)","text":"data available data frame ox_births.","code":"> library(stat0002) > birth_times <- ox_births[, \"time\"] > sort(birth_times)  [1]  1.50  2.00  2.10  2.50  2.50  2.60  2.70  2.75  3.40  3.40  3.40  3.60 [13]  3.60  4.00  4.00  4.00  4.10  4.20  4.20  4.25  4.30  4.70  4.70  4.90 [25]  5.00  5.25  5.50  5.60  5.70  5.90  6.10  6.25  6.25  6.40  6.40  6.50 [37]  6.50  6.80  6.90  7.00  7.00  7.20  7.25  7.25  7.30  7.30  7.30  7.50 [49]  7.50  7.50  7.50  7.80  8.10  8.20  8.25  8.30  8.30  8.45  8.50  8.50 [61]  8.50  8.50  8.75  8.90  9.00  9.20  9.25  9.25  9.50  9.50  9.75  9.75 [73] 10.00 10.10 10.20 10.25 10.40 10.40 10.40 10.70 10.70 10.75 11.00 11.20 [85] 11.50 12.75 12.90 14.25 14.30 14.50 14.60 15.00 16.00 16.50 19.00"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"empirical-cumulative-distribution-function","dir":"Articles","previous_headings":"The Oxford Birth Times data","what":"Empirical cumulative distribution function","title":"Chapter 2: Graphs (One Variable)","text":"Can work output function ecdf ? Use ?ecdf check answer. plot method object returned ecdf produces plot much like (hollow circles ) Figure 2.3 STAT0002 notes. label lot axes “time (hours)”. make lives little easier create character variable called xlab.  obvious arguments xlab ylab . think main = \"\" pch = 1 ? Use ?title ?par (respectively) find . ?par lists lots arguments can used adjust graph.","code":"> ox_ecdf <- ecdf(birth_times) > ox_ecdf(1) [1] 0 > ox_ecdf(2) [1] 0.02105263 > 2/95 [1] 0.02105263 > ox_ecdf(4.7) [1] 0.2421053 > 23/95 [1] 0.2421053 > ox_ecdf(19) [1] 1 > ox_ecdf(100) [1] 1 > xlab <- \"time (hours)\" > plot(ox_ecdf, main = \"\", xlab = xlab, ylab = \"cumulative relative frequency\", pch = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"histogram","dir":"Articles","previous_headings":"The Oxford Birth Times data","what":"Histogram","title":"Chapter 2: Graphs (One Variable)","text":"following code produces histograms feature STAT0002 notes. Note first plot probability = TRUE (prob = TRUE short) argument important: ensures total area rectangles histogram equal 1. second plot isn’t necessary include prob = TRUE bin widths unequal (sensibly) hist uses prob = TRUE.  Can see argument breaks ? … function seq? hist function returns object (list several objects fact) containing information used construct plot. assign R object, ox_tab say, can look information perhaps use . ls function tells us names objects list. Use ?hist find objects . use information ox_tab reproduce plot Figure 2.2 notes.  think function cumsum ? following code produces histogram-like alternative plots. can see can many things change appearance plots. Use ?par see list graphical parameters can use.","code":"> hist(birth_times, prob = TRUE, col = 8, main = \"\", xlab = xlab) > br <- c(seq(from = 0, to = 12, by = 2), 20) > hist(birth_times, breaks = br, col = 8, main = \"\", xlab = xlab) > ox_tab <- hist(birth_times, plot = FALSE) > ls(ox_tab) [1] \"breaks\"   \"counts\"   \"density\"  \"equidist\" \"mids\"     \"xname\" > cum_rel_freq <- cumsum(c(0, ox_tab$counts)) / length(birth_times) > plot(ox_tab$breaks, cum_rel_freq, type = \"b\", pch = 16, ylab = \"cumulative relative frequency\", xlab = xlab) > abline(h = 1, lty = 2) > # adjust plot margins, produce a 2 by 2 array of plots (fill row 1 then row 2) > par(mar = c(4, 4, 1, 1), mfrow = c(2, 2)) > # no vertical axis > hist(birth_times, col = 8, prob = TRUE, axes = FALSE, xlab = xlab, ylab = \"\", main = \"\") > axis(1, line = 0.5) > # no vertical axis plus rug of points > hist(birth_times, col = 8, prob = TRUE, axes = FALSE, xlab = xlab, ylab = \"\",main = \"\") > axis(1, line = 0.5) > rug(birth_times, line = 0.5, ticksize = 0.05) > # non-shaded frequency polygon > n <- length(ox_tab$mids) > ox_tab$mids <- c(ox_tab$mids[1], ox_tab$mids, ox_tab$mids[n]) > ox_tab$density <- c(0, ox_tab$density, 0) > plot(ox_tab$mids, ox_tab$density, xlab = xlab, ylab = \"density\", type = \"l\", las = 1)  > axis(1, line = 0) > # shaded frequency polygon with no vertical axis > plot(ox_tab$mids, ox_tab$density, xlab = xlab, ylab = \"\", type = \"l\", bty= \"l\", axes = FALSE) > axis(1, line = -0.4) > polygon(ox_tab$mids, ox_tab$density, col = 8)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"stem-and-leaf-plot","dir":"Articles","previous_headings":"The Oxford Birth Times data","what":"Stem-and-leaf plot","title":"Chapter 2: Graphs (One Variable)","text":"Use ?stem see scale .","code":"> # The default plot > stem(birth_times)    The decimal point is at the |     0 | 5    2 | 015567844466    4 | 00012233779035679    6 | 1334455890023333355558    8 | 12333555558902335588   10 | 0123444778025   12 | 89   14 | 33560   16 | 05   18 | 0 >  > # The plot that appears in the notes > stem(birth_times, scale = 2)    The decimal point is at the |     1 | 5    2 | 0155678    3 | 44466    4 | 00012233779    5 | 035679    6 | 133445589    7 | 0023333355558    8 | 123335555589    9 | 02335588   10 | 0123444778   11 | 025   12 | 89   13 |    14 | 3356   15 | 0   16 | 05   17 |    18 |    19 | 0"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"dotplot","dir":"Articles","previous_headings":"The Oxford Birth Times data","what":"Dotplot","title":"Chapter 2: Graphs (One Variable)","text":"surprisingly difficult produce nice-looking dotplot using standard R functions. One possibility use stripchart. code also produces plots Figure 2.5 notes.   Find functions pretty axis .","code":"> stripchart(birth_times, method = \"stack\", pch = 16, at = 0, offset = 2/3) > title(xlab = xlab) > x <- round(birth_times) > stripchart(x, method = \"stack\", pch = 16, at = 0, axes = FALSE, offset = 2/3) > title(xlab = xlab) > x_labs <- c(min(x), pretty(x), max(x)) > axis(1, at = x_labs)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"boxplot","dir":"Articles","previous_headings":"The Oxford Birth Times data","what":"Boxplot","title":"Chapter 2: Graphs (One Variable)","text":"function produces boxplot (box--whisker plot) called boxplot. Inside boxplot estimation quartiles, box part plot based, uses default value argument type (.e. type = 7) call quantile. order can change value type wish stat0002 contains function box_plot, copy boxplot extra argument type added. box_plot default type = 6, corresponds particular way estimating quartiles described STAT0002 lecture notes slides. See Descriptive Statistics vignette information quantile argument type. many cases need worry choice value type. Unless dataset small value type enough effect appearance boxplot matter. certainly case birth_times data.   know Descriptive Statistics vignette estimates lower quartile differ type = 6 type = 7 cases. can check using objects b1 b2 returned . Can work output graphs boxplot returns list component stats? Check answer using ?boxplot. obtain values data points lie outside whiskers? read documentation boxplot carefully (see ?boxplot ?bxp) can lot control graph produces. following code produces plots Figure 2.7 STAT0002 notes.  Chapter 2: Graphs (one variable) vignette consider variables ox_births data frame, .e. numeric continuous variable time categorical variable day, producing separate boxplots time day week.","code":"> # type = 6 > b1 <- box_plot(birth_times, horizontal = TRUE, main = \"type = 6\", xlab = xlab) > # type = 7 > b2 <- boxplot(birth_times, horizontal = TRUE, main = \"type = 7\") > as.vector(b1$stats) [1]  1.50  4.90  7.50  9.75 16.50 > as.vector(b2$stats) [1]  1.50  4.95  7.50  9.75 16.50 > par(mar = c(4, 1, 0.5, 1)) > x_labs <- c(min(birth_times), pretty(birth_times), max(birth_times)) > # top left > box_plot(birth_times, horizontal = TRUE, col = 8, xlab = xlab, pch = 16) > # top right > boxplot(birth_times, horizontal = TRUE, col = 8, axes = FALSE, xlab = xlab, pch = 16) > axis(1, at = x_labs, labels = x_labs) > # bottom left > boxplot(birth_times, horizontal = TRUE, axes = FALSE, xlab = xlab, pch = 16, lty = 1, range = 0, staplewex = 0) > axis(1, at = x_labs, labels = x_labs) > # bottom right > boxplot(birth_times, horizontal = TRUE, axes = FALSE, xlab = xlab, pch = 16, lty = 1, range = 0, boxcol = \"white\", staplewex = 0, medlty = \"blank\", medpch = 16) > axis(1, at = x_labs, labels = x_labs)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"boxplots-and-extreme-observations","dir":"Articles","previous_headings":"The Oxford Birth Times data > Boxplot","what":"Boxplots and extreme observations","title":"Chapter 2: Graphs (One Variable)","text":"purposes whiskers boxplot provide measure spread supplement inter-quartile range range, highlight observations extreme,sense small large relative observations lie close centre distribution. whiskers used automatic way detect outliers. Consider numerical experiment simulate repeatedly random normal samples size \\(n\\). \\(n=100\\) \\(50\\%\\) datasets least one observation outside whiskers \\(n=1000\\) rises \\(99\\%\\). know outliers . observations lie outside whiskers boxplots expected .","code":"> # A function to > # 1. simulate a sample of size n from a (standard) normal distribution > # 2. calculate the boxplot statistics > # 3. return TRUE if there are no values outside the whiskers, TRUE otherwise > nextreme <- function(n) { +   y <- boxplot.stats(rnorm(n)) +   return(length(y$out) >= 1) + } > # Find the proportion of datasets for which there are values outside the whiskers > # n = 100 > y <- replicate(n = 10000, nextreme(n = 100)) > mean(y) [1] 0.5208 > # n = 1000 > y <- replicate(n = 10000, nextreme(n = 1000)) > mean(y) [1] 0.997"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"the-challenger-o-ring-data","dir":"Articles","previous_headings":"","what":"The Challenger O-ring data","title":"Chapter 2: Graphs (One Variable)","text":"return data feature Challenger Space Shuttle disaster vignette. column data frame contains observed numbers O-rings suffer thermal distress. numerical discrete variable. fact can precise , integer variable. One way summarize data graphically using bar plot. order produce bar plot first need tabulate data, using functiontable calculate frequencies numbers distressed O-rings. table OK include zero frequencies categories 4, 5 6. can expect output table include categories 4, 5 6?","code":"> shuttle$damaged  [1]  0  1  0  0  0  0  0  0  1  1  1  0  0  3  0  0  0  0  0  0  2  0  1 NA > O_tab <- table(shuttle$damaged) > O_tab   0  1  2  3  16  5  1  1"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"a-digression-table-and-classes-of-r-objects","dir":"Articles","previous_headings":"The Challenger O-ring data","what":"A digression: table and classes of R objects","title":"Chapter 2: Graphs (One Variable)","text":"answer question 8. “R can’t possibly know values variable shuttle$damaged ”. obvious us, know data mean space shuttle 6 O-rings, R’s table function infer data alone. example probably doesn’t matter zero frequencies missing. However, consider following example. simulate 10 values Poisson distribution mean 5. introduction simulation see Stochastic simulation vignette. data real, imagine respective numbers earthquakes occur particular area years 2008 2017. know data non-negative integers. R know included columns table non-zero frequencies, .e. values 4, 5, 6, 7, 8 10. least might want zero frequencies values 0, 1, 2, 3 9 included, perhaps also something indicate values greater 10. One possibility following. particularly elegant quite effective. Can work code ? might help look ?c. really fussy change name final heading table. explore another option return variable shuttle$damaged. R system R objects categorized different classes. effect given R function may depend class object provided function. function class can used find class object . R thinks (correctly) shuttle$damaged integer variable. Unfortunately, far aware, mechanism us tell R integer variable can take values 0, 1, 2, 3, 4, 5, 6. However, way get R treat shuttle$damaged categorical variable. can provide R information possible levels categorical variable shuttle$damaged. R categorical variables called factors. use function factor create new variable fac_dam () factor, (b) levels 0, 1, 2, 3, 4, 5 6. Now use table output reflects automatically possible values variable.","code":"> set.seed(47) > x <- rpois(10, 5) > table(x) x  4  5  6  7  8 10   2  3  2  1  1  1 > table(c(x, 0:11)) - 1   0  1  2  3  4  5  6  7  8  9 10 11   0  0  0  0  2  3  2  1  1  0  1  0 > tab <- table(c(x, 0:11)) - 1 > names(tab)[12] <- \">10\" > tab   0   1   2   3   4   5   6   7   8   9  10 >10    0   0   0   0   2   3   2   1   1   0   1   0 > class(shuttle$damaged) [1] \"integer\" > fac_dam <- factor(shuttle$damaged, levels = 0:6) > class(fac_dam) [1] \"factor\" > O_tab_fac <- table(fac_dam) > O_tab_fac fac_dam  0  1  2  3  4  5  6  16  5  1  1  0  0  0"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"bar-plot","dir":"Articles","previous_headings":"The Challenger O-ring data","what":"Bar plot","title":"Chapter 2: Graphs (One Variable)","text":"following code reproduces graphs Figure 2.8 notes.  instead use O-tab_fac zero frequencies values 4, 5 6 included plot.","code":"> par(mfrow=c(2,2)) > par(oma=c(0,0,0,0),mar=c(4,4,1,2)+0.1) > xlab <- \"number of damaged O-rings\" > ylab <- \"frequency\" > barplot(O_tab, xlab = xlab, ylab = ylab, las = 1) > barplot(O_tab, space = 1, xlab = xlab, ylab = ylab, las = 1) > barplot(O_tab, space = 1, xlab = xlab, ylab = ylab, las = 1) > abline(h=0) > yy <- as.numeric(O_tab) > xx <- as.numeric(unlist(dimnames(O_tab),use.names=F)) > plot(xx, yy, pch = c(\"0\",\"1\",\"2\",\"3\"), axes = FALSE, xlab =\"\", ylab = ylab, ylim = c(0, 16)) > title(xlab=\"number of damaged o-rings\",line=0.25) > axis(2, lty = 1, at = yy, labels = yy, pos = -0.3, las = 1) > barplot(O_tab_fac, xlab = xlab, ylab = ylab, las = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"blood-groups","dir":"Articles","previous_headings":"","what":"Blood groups","title":"Chapter 2: Graphs (One Variable)","text":"data Table 2.8 notes available data frame blood_types.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"bar-plot-1","dir":"Articles","previous_headings":"Blood groups","what":"Bar plot","title":"Chapter 2: Graphs (One Variable)","text":"code produces bar plot left side Figure 2.9.","code":"> blood_types   ABO  Rh percentage 1   O Rh+         37 2   A Rh+         35 3   B Rh+          8 4  AB Rh+          3 5   O Rh-          7 6   A Rh-          7 7   B Rh-          2 8  AB Rh-          1 > lab <- paste(blood_types$ABO, substr(blood_types$Rh, 3, 3), sep = \"\") > barplot(blood_types$percentage, space = 1, xlab = \"blood group\", ylab = \"percentage\", las = 1, names.arg = lab) > abline(h=0)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"pie-chart","dir":"Articles","previous_headings":"Blood groups","what":"Pie chart","title":"Chapter 2: Graphs (One Variable)","text":"desperate need produce pie chart can using following code.  read text Note section ?pie forget function pie exists.","code":"> par(mar = c(1, 1, 0, 1)) > slices <- rep(c(\"white\",\"grey66\",\"grey33\",\"black\"), 2) > pie(blood_types$percentage, labels = lab, col = slices)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"ftse100-data","dir":"Articles","previous_headings":"","what":"FTSE100 data","title":"Chapter 2: Graphs (One Variable)","text":"FTSE 100 share index data described Section 2.5.6 notes available data frame ftse. Handling dates R can tricky. main issue ensure time series, dates, stored correctly. One way achieve use function ts create time series object, specifying frequency data (frequency = 52 means weekly , approximately, 52 weeks year) start data (14th week 1984). time series object vector weekly closing prices two attributes important extra information (metadata) tsp class stored. attribute tsp contains start date, end date frequency observations attribute class indicates ts (time series) object.","code":"> head(ftse)            date  price 1220 1984-04-02 1096.3 1219 1984-04-09 1129.1 1218 1984-04-16 1116.2 1217 1984-04-23 1130.9 1216 1984-04-30 1134.7 1215 1984-05-08 1076.1 > tail(ftse)         date  price 6 2007-07-09 6716.7 5 2007-07-16 6585.2 4 2007-07-23 6215.2 3 2007-07-30 6224.3 2 2007-08-06 6038.3 1 2007-08-13 6143.5 > ftse_ts <- ts(ftse$price, frequency = 52, start = c(1984, 14)) > head(ftse_ts) [1] 1096.3 1129.1 1116.2 1130.9 1134.7 1076.1 > attributes(ftse_ts) $tsp [1] 1984.250 2007.692   52.000  $class [1] \"ts\""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"time-series-plot","dir":"Articles","previous_headings":"FTSE100 data","what":"Time series plot","title":"Chapter 2: Graphs (One Variable)","text":"following code produces time series plot left side Figure 2.10. used function .Date ensure R knows data plotted horizontal axis plot dates. moment make use time series object ftse_ts.  following code produces plot right side Figure 2.10. class ftse_ts \"ts\" R knows use plot(ftse_ts) want time series plot. rest code just adjusts appearance plot.  Can work bit code ?","code":"> plot(as.Date(ftse$date), ftse$price, type = \"l\", ylab = \"weekly FTSE 100 share index\", xlab = \"year\") > plot(ftse_ts, ylab = \"FTSE 100 (in 1000s)\", xlab = \"year\", las = 1, axes = FALSE) > q2 <- c(min(ftse_ts), (2:6) * 1000, max(ftse_ts)) > axis(2, at = q2, labels = round(q2 / 1000, 1), las = 1) > axis(4, at= q2, labels = round(q2 / 1000, 1), las=1) > axis(1) > abline(h = par(\"usr\")[3])"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"influenza-data","dir":"Articles","previous_headings":"","what":"Influenza data","title":"Chapter 2: Graphs (One Variable)","text":"mystery data plotted Figure 2.11 notes numbers people UK visiting doctor symptoms influenza (’flu) four-weekly time periods time period 28th January 1967 13th November 2004. [hope doesn’t spoil surprise .]","code":"> head(flu)         date visits 1 1967-01-28   91.5 2 1967-02-25   86.8 3 1967-03-25   62.1 4 1967-04-22   63.0 5 1967-05-20   57.7 6 1967-06-17   53.7 > tail(flu)           date visits 489 2004-06-26   4.35 490 2004-07-24   2.76 491 2004-08-21   6.36 492 2004-09-18   9.71 493 2004-10-16  12.28 494 2004-11-13  18.99"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2b-graphs-vignette.html","id":"time-series-plot-1","dir":"Articles","previous_headings":"Influenza data","what":"Time series plot","title":"Chapter 2: Graphs (One Variable)","text":"create time series object using ts produce plot Figure 2.11","code":"> par(mar = c(5, 5, 4, 3) + 0.1, cex.axis = 0.8, cex.lab = 0.75) > flu_ts <- ts(flu[,2], frequency = 13, start = c(1967, 4)) > plot(flu_ts, ylab=\"number of 'flu consultations (in 1000s)\", xlab = \"year\", las = 1, axes=FALSE) > q2 <- c(min(flu_ts),(1:6) * 100, max(flu_ts)) > axis(2, at = q2, labels = round(q2, 1), las = 1) > axis(4, at = q2, labels = round(q2, 1), las = 1) > abline(h=0) > axis(1,pos=-1)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2c-graphs-vignette.html","id":"the-oxford-birth-times-data","dir":"Articles","previous_headings":"","what":"The Oxford Birth Times data","title":"Chapter 2: Graphs (More Than One Variable)","text":"data available data frame ox_births. display data manipulate matrix format Table 2.1 notes. number birth times varies days pad matrix R’s missing values code NA order column matrix number rows. numeric continuous variable, birth_times, categorical variable, day. following code produces separate boxplots birth_times day week.","code":"> library(stat0002) > birth_times <- ox_births[, \"time\"] > day <- ox_births[, \"day\"] > ox_mat <- matrix(NA, ncol = 7, nrow = 16) > for (i in 1:7) { +   day_i_times <- ox_births$time[which(ox_births$day == i)] +   ox_mat[1:length(day_i_times), i] <- sort(day_i_times) +   colnames(ox_mat) <- paste(\"day\", 1:7, sep = \"\") + }   > ox_mat        day1  day2  day3  day4  day5  day6  day7  [1,]  2.10  4.00  2.60  1.50  2.50  4.00  2.00  [2,]  3.40  4.10  3.60  4.70  2.50  4.00  2.70  [3,]  4.25  5.00  3.60  4.70  3.40  5.25  2.75  [4,]  5.60  5.50  6.40  7.20  4.20  6.10  3.40  [5,]  6.40  5.70  6.80  7.25  5.90  6.50  4.20  [6,]  7.30  6.50  7.50  8.10  6.25  6.90  4.30  [7,]  8.50  7.25  7.50  8.50  7.30  7.00  4.90  [8,]  8.75  7.30  8.25  9.20  7.50  8.45  6.25  [9,]  8.90  7.50  8.50  9.50  7.80  9.25  7.00 [10,]  9.50  8.20 10.40 10.70  8.30 10.10  9.00 [11,]  9.75  8.50 10.75 11.50  8.30 10.20  9.25 [12,] 10.00  9.75 14.25    NA 10.25 12.75 10.70 [13,] 10.40 11.00 14.50    NA 12.90 14.60    NA [14,] 10.40 11.20    NA    NA 14.30    NA    NA [15,] 16.00 15.00    NA    NA    NA    NA    NA [16,] 19.00 16.50    NA    NA    NA    NA    NA > par(mar = c(4, 4, 0.5, 1)) > xlab <- \"time (hours)\" > x_labs <- c(min(birth_times), pretty(birth_times), max(birth_times)) > # top left > box_plot(birth_times ~ day, col = 8, ylab = xlab, pch = 16, xlab = \"day\") > # top right > box_plot(birth_times ~ day, col = 8, horizontal = TRUE,  axes = FALSE, xlab = xlab, ylab = \"day\", pch = 16) > axis(1, at = x_labs, labels = x_labs) > axis(2, at = 1:7, labels = 1:7, lwd = 0, lty = 0) > # bottom left > box_plot(birth_times ~ day, axes = FALSE, ylab = xlab, pch = 16, lty = 1, range = 0, boxcol = \"white\", staplewex = 0, medlty = \"blank\", medpch = 16, xlab = \"day\") > axis(1, at = 1:7, labels = 1:7, lwd = 0, lty = 0) > axis(2, at = x_labs, labels = x_labs) > # bottom right > box_plot(birth_times ~ day, horizontal = TRUE, axes = FALSE, xlab = xlab, pch = 16, lty = 1, range = 0, boxcol = \"white\", staplewex = 0, medlty = \"blank\", medpch = 16) > axis(1, at = x_labs, labels = x_labs) > axis(2, at = 1:7, labels = 1:7, lwd = 0, lty = 0, las = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2c-graphs-vignette.html","id":"the-2000-us-presidential-election-in-florida","dir":"Articles","previous_headings":"","what":"The 2000 US Presidential Election in Florida","title":"Chapter 2: Graphs (More Than One Variable)","text":"data available data frame USelection. See ?USelection details. moment simply produce scatter plots. separate vignette devoted data. plot show locations counties.  Can see outline state Florida? plot percentage vote Buchanan population size.  Can see code used identify Palm Beach plot works? Pairwise scatter plots demographic variables.  plot square root percentage vote Buchanan population size, thousands people. horizontal axis plotted log scale.  Can see different method identify Palm Beach works? Can guess numbers axes ? See scatter find . Similarly, use scatter_hist create scatter plot distribution variable summarized histogram.  plot lecture slides produced specifying particular bins histograms.","code":"> # County identifiers and location > head(USelection[, 1:4])   co co_names  lat  lon 1  1  Alachua 29.7 82.4 2  2    Baker 30.3 82.3 3  3      Bay 30.2 85.6 4  4 Bradford 29.9 82.2 5  5  Brevard 28.3 80.7 6  6  Broward 26.1 80.5 > # County demographic variables > head(USelection[, 5:12])      npop whit blac hisp  o65 hsed coll  inco 1  198326 74.4 21.8  4.7  9.4 82.7 34.6 19412 2   20761 82.4 16.8  1.5  7.7 64.1  5.7 14859 3  146223 84.2 12.4  2.4 11.9 74.7 15.7 17838 4   24646 76.1 22.9  2.6 11.8 65.0  8.1 13681 5  460977 88.3  9.2  4.1 16.5 82.3 20.4 19567 6 1470758 80.3 17.5 10.9 20.3 76.8 18.8 24706 > # Numbers of votes for candidates > head(USelection[, 13:22])     bush   gore brow nade harr hage buch mcre phil moor 1  34124  47365  658 3226    6   42  263    4   20   21 2   5610   2392   17   53    0    3   73    0    3    3 3  38637  18850  171  828    5   18  248    3   18   27 4   5414   3075   28   84    0    2   65    0    2    3 5 115185  97318  643 4470   11   39  570   11   72   76 6 177323 386561 1212 7101   50  129  788   34   74  124 > plot(-USelection[, \"lon\"], USelection[, \"lat\"], xlab = \"longitude (degrees north)\", ylab = \"latitude (degrees east)\", pch = 16) > pbuch <- 100 * USelection$buch/USelection$tvot > is_PB <- USelection[, \"co_names\"] == \"PalmBeach\" > pch <- 1 + 3 * is_PB > pch  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 [39] 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 > plot(USelection$npop, pbuch, xlab = \"population\", ylab = \"Buchanan % vote\", pch = pch) > which_PB <- which(is_PB) > text(USelection[which_PB, \"npop\"], pbuch[which_PB] + 0.1, \"Palm Beach\", cex = 0.8) > pairs(USelection[, 5:12]) > x <- USelection$npop / 1000 > y <- sqrt(pbuch) > ystring <- expression(sqrt(\"% Buchanan vote\")) > rm_PB <- which(!is_PB) > scatter(x[rm_PB], y[rm_PB], pch = 16, xlab =\"Total Population (1000s)\", ylab = ystring, log = \"x\") > points(x[which_PB], y[which_PB], pch = \"X\") > text(x[which_PB], y[which_PB] + 0.04, \"Palm Beach\", cex = 0.8) > scatter_hist(x, y, log = \"x\", pch = 16, xlab =\"Total Population (1000s)\", ylab = ystring) > logx <- log(x) > xbreaks <- seq(from = min(logx), to = max(logx), len = 25) > ybreaks <- seq(from = min(y), to = max(y), len = 25) > scatter_hist(x, y, log = \"x\", pch = 16, xlab =\"Total Population (1000s)\", ylab = ystring, xbreaks = xbreaks, ybreaks = ybreaks)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"box-cox-transformation","dir":"Articles","previous_headings":"","what":"Box-Cox transformation","title":"Chapter 2: Transformation Of Variable","text":"transformation considered lectures called Box-Cox transformation, authors paper (Box Cox (1964)) type transformation studied extensively. (names authors pleasing coincidence, see Box Cox.) ’s simplest form Box-Cox transformation \\(x\\) \\(y\\) given \\[   y = \\left.   \\begin{cases}     \\displaystyle\\frac{x^\\lambda - 1}{\\lambda}, & \\text{} \\lambda \\neq 0, \\\\     \\ln (x), & \\text{} \\lambda = 0. \\\\   \\end{cases}   \\right. \\] inverse transformation \\[   x = \\left.   \\begin{cases}     \\displaystyle(\\lambda y + 1)^{1 / \\lambda}, & \\text{} \\lambda \\neq 0, \\\\     \\exp(y), & \\text{} \\lambda = 0. \\\\   \\end{cases}   \\right. \\] Firstly, consider use Box-Cox transformation transform data relating one variable appear symmetrically distributed. Transformation Approximate Linearity use Box-Cox transformation make apparent relationship two variables closer linear.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"transformation-to-approximate-symmetry","dir":"Articles","previous_headings":"","what":"Transformation to Approximate Symmetry","title":"Chapter 2: Transformation Of Variable","text":"normal (Gaussian) distribution symmetric probability distribution. \\(Y = \\ln X\\) normal distribution \\(X\\) log-normal distribution. convenient example study know sample log-normal distribution taking logs data produces sample normal distribution.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"log-normal-distribution","dir":"Articles","previous_headings":"Transformation to Approximate Symmetry","what":"Log-normal distribution","title":"Chapter 2: Transformation Of Variable","text":"following code: simulates sample size 100 log-normal distribution; draws histogram data log-normal p.d.f. superimposed; produces similar plot transforming using log transformation (lambda = 0).  suggest try different values lambda look result plot. example know value \\(\\lambda\\) produce approximate symmetry. confronted real data won’t position. However, look plot original data judge whether need make data less positively skewed (use \\(\\lambda < 1\\)) less negatively skewed (use \\(\\lambda > 1\\)), use trial--error. also automatic way suggest suitable value \\(\\lambda\\): try number values \\(\\lambda\\) summarise well normal distribution fits transformed data using value something called profile log-likelihood. Don’t worry means, just appreciate larger values profile log-likelihood suggest better fit. produces ‘best guess’ value \\(\\lambda\\). can also produce confidence interval \\(\\lambda\\). don’t study confidence intervals detail STAT0002. idea interval measure uncertainty value \\(\\lambda\\). function boxcox MASS package (Venables Ripley (2002)) produces plot profile log-likelihood \\(\\lambda\\), 95% confidence interval \\(\\lambda\\). ~ 1 bit formula notation x ~ 1 specifying variable consider addition x. Transformation Approximate Linearity extend notation deal case consider two variables.  expect ‘best’ value \\(\\lambda\\) close zero zero lies within confidence intervals \\(\\lambda\\). Typically, choose simple value \\(\\lambda\\), e.g. simple fraction whole number, close ‘best’ lies within confidence interval.","code":"> library(stat0002) > x <- rlnorm(100) > boxcox_plot(x, density_fn = dlnorm, main = \"data and true density function\") > boxcox_plot(x, density_fn = dlnorm, lambda = 0, main = \"after transformation\") > library(MASS, warn.conflicts = FALSE) > res <- MASS::boxcox(x ~ 1) > # Find the value of lambda with the largest profile log-likelihood > res$x[which.max(res$y)] [1] 0.1010101"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"exponential-distribution","dir":"Articles","previous_headings":"Transformation to Approximate Symmetry","what":"Exponential distribution","title":"Chapter 2: Transformation Of Variable","text":"exponential random variable exhibits strong positive skewness. Therefore, wish Box-Cox transform data sampled exponential distribution order make symmetric use \\(\\lambda < 1\\). can use MASS function boxcox help us decide value \\(\\lambda\\) use. However, exponential distribution special case gamma distribution (don’t study STAT0002) long known (Wilson Hilferty (1931)) cube root transformation tends make gamma random variable behave rather like normal random variable. Therefore, \\(\\lambda = 1/3\\) might work well.  find \\(\\lambda = 1/3\\) work well ‘best’ value, calculated boxcox close 1/3. , see effects using different values lambda.","code":"> x2 <- rexp(100) > boxcox_plot(x2, density_fn = dexp, main = \"data and true density function\") > boxcox_plot(x2, density_fn = dexp, lambda = 1 / 3, main = \"after transformation\") > boxcox(x2 ~ 1) > abline(v = 1/3, col = \"red\")"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"a-triangular-distribution","dir":"Articles","previous_headings":"Transformation to Approximate Symmetry","what":"A triangular distribution","title":"Chapter 2: Transformation Of Variable","text":"consider simple probability distribution p.d.f. \\[   f_X(x) = \\left.   \\begin{cases}     2\\,x, & \\text{} 0 < x < 1, \\\\     0, & \\text{otherwise}. \\\\   \\end{cases}   \\right. \\] .e. triangle base along (0,1). functions dtri rtri following code used calculate p.d.f. simulate distribution, respectively. latter uses inversion method simulation. example can shown using \\(\\lambda = 2\\) produce random variable whose p.d.f. constant (equal 2) range (-1/2, 0), , produce uniform U(-1/2, 0) random variable. Can prove random variable \\(X\\) triangular p.d.f. \\(X^2\\) standard U(0,1) distribution hence \\((X^2-1)/2\\) U(-1/2,0) distribution? simulate data triangular distribution show using \\(\\lambda = 2\\) indeed produce density flat, therefore symmetric.  Interestingly boxcox function suggests values \\(\\lambda\\) close 1.5 resulting transformed density particularly close symmetric. objective boxcox function seek Box-Cox transformation transformed density close possible normal. can’t well case know \\(\\lambda = 2\\) produces density perfectly symmetric, although uniform density, normal density.","code":"> # A function to define the p.d.f. > dtri <- function(x) { +   return(ifelse(x > 0 & x < 1, 2 * x, 0)) + }   > # A function to simulate from this distribution > rtri <- function(n = 1) { +   return(sqrt(runif(n))) + } > x3 <- rtri(200) > boxcox_plot(x3, density_fn = dtri) > boxcox_plot(x3, density_fn = dtri, lambda = 2) > boxcox(x3 ~ 1, lambda = seq(0, 4, 1 / 10)) > boxcox_plot(x3, density_fn = dtri, lambda = 1.5)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"the-oxford-births-data","dir":"Articles","previous_headings":"Transformation to Approximate Symmetry","what":"The Oxford births data","title":"Chapter 2: Transformation Of Variable","text":"Suppose create vector x4 containing Oxford birth durations. real data don’t know true p.d.f.  kind Box-Cox transformation makes data symmetrically distributed?","code":"> x4 <- ox_births$time > boxcox_plot(x4)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"linearity","dir":"Articles","previous_headings":"","what":"Transformation to Approximate Linearity","title":"Chapter 2: Transformation Of Variable","text":"Chapter 8 STAT0002 notes study simple linear regression. short, idea suppose distribution response variable \\(Y\\) mean linear function observed value \\(x\\) *explanatory variable \\(X\\). Alternatively, think \\(Y\\) linear function \\(x\\) plus random error zero mean.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch2d-box-cox-transformation-vignette.html","id":"us-presidential-election-data-in-florida","dir":"Articles","previous_headings":"Transformation to Approximate Linearity","what":"2000 US Presidential Election Data in Florida","title":"Chapter 2: Transformation Of Variable","text":"Consider following plot percentage vote obtained candidate Pat Buchanan (\\(Y\\)) total population (thousands people) county (\\(x\\)) 67 counties Florida.  Clearly \\(Y\\) linearly related \\(x\\). Section 9.4 notes consider use transformation setting simple linear regression. hoping use linear regression model one important considerations whether relationship \\(Y\\) \\(x\\) approximately linear. one approach consider transforming \\(Y\\) /\\(x\\). saw choose transformations using trial--error. Smith (2002) author uses \\(\\sqrt{Y}\\) instead \\(Y\\) \\(\\log(x)\\) instead \\(x\\). lecture found indeed produce relationship looked much closer linear. also use \\(\\log(x)\\) instead \\(x\\) use boxcox function suggest Box-Cox transformation \\(y\\). [possible look look simultaneously ‘best’ Box-Cox transformations \\(Y\\) \\(x\\), boxcox function doesn’t provide option.] regression setting boxcox function seeks transformation \\(Y\\) distribution random error close possible normal.  plot suggests might also transform \\(Y\\) using \\(\\log(Y)\\). plot left \\(\\log(Y)\\) \\(\\log(x)\\) (plot variables log scales). plot right \\(\\sqrt{Y}\\) \\(x\\).  plots relationships variables closer approximately linear original plot. might argue plot left looks lightly better plot therefore may question Smith chose \\(\\sqrt{Y}\\) rather \\(\\log Y\\). However, relationship \\(Y\\) \\(x\\) far whole story. Smith’s model much complicated , worry assumptions, addition linearity.","code":"> xlab <- \"population (1000s)\" > ylab <- \"Buchanan's % vote\" > y <- 100 * USelection$buch / USelection$tvot > x <- USelection$npop / 1000 > plot(x, y, pch = 16, xlab = xlab, ylab = ylab) > boxcox(y ~ log(x)) > xlab <- \"population (1000s)\" > ylab <- \"Buchanan vote\" > plot(x, y, pch = 16, log = \"xy\", xlab = xlab, ylab = ylab) > ylab <- expression(sqrt(Buchanan~vote)) > plot(x, sqrt(y), pch = 16, log = \"x\", xlab = xlab, ylab = ylab)"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch3-probability-vignette.html","id":"kerrichs-coin-data","dir":"Articles","previous_headings":"","what":"Kerrich’s coin data","title":"Chapter 3: Probability","text":"summary data available data frame kerrich. Use ?kerrich information.  extract data frame kerrich number trials (10,000 throws coin) number heads. can calculate estimate probability \\(P(H)\\) outcome trial head.","code":"> library(stat0002) > # This code produces the plot in Figure 3.1 of the STAT0002 notes > plot(kerrich$throws, kerrich$heads / kerrich$throws, +      ylab = \"proportion of heads\", +      xlab = \"number of throws (logarithmic scale)\", lwd = 2, type = \"l\", +      log = \"x\", ylim = c(0,1), axes = FALSE) > abline(h = 0.5, lty = 2) > axis(1, labels = as.character(c(3, 10, 30, 100, 300, 1000, 3000, 10000)), +      at=c(3, 10, 30, 100, 300, 1000, 3000, 10000)) > axis(2, labels = c(0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0), +      at=c(0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0)) > trials <- kerrich[nrow(kerrich), \"throws\"] > heads <- kerrich[nrow(kerrich), \"heads\"] > c(heads, trials) [1]  5067 10000 > phat <- heads / trials > phat [1] 0.5067"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch3-probability-vignette.html","id":"graduate-admissions-at-berkeley","dir":"Articles","previous_headings":"","what":"Graduate Admissions at Berkeley","title":"Chapter 3: Probability","text":"object berkeley 3-dimensional array contains information applicants graduate school UC Berkeley 1973 six largest departments. Use ?UCBAdmissions information. 3 dimensions array correspond gender applicant (dimension named Gender), whether admitted (named Admit) letter code department applied (named Dept). given entry berkeley gives total number applicants corresponding (Admit, Gender, Dept) category. Chapter 3 consider dimensions Admit Gender. following code collapses 3-dimensional array 2-dimensional array summing frequencies six departments, gives central part Table 3.3 notes. Now add column row totals. can divide \\(n\\) (4526) produce Table 3.5 notes. Notice sex_outcome[3, 3] extracts [3, 3] element matrix sex_outcome, , 4526. Can use R perform calculations performed Section 3.4 /3.5 notes?","code":"> # 2-way table: sex and outcome > sex_outcome <- apply(berkeley, 2:1, FUN = sum) > colnames(sex_outcome) <- c(\"A\", \"R\") > rownames(sex_outcome) <- c(\"M\", \"F\") > sex_outcome       Admit Gender    A    R      M 1198 1493      F  557 1278 > # Add column totals > sex_outcome <- rbind(sex_outcome, total = colSums(sex_outcome)) > # Add row totals > sex_outcome <- cbind(sex_outcome, total = rowSums(sex_outcome)) > sex_outcome          A    R total M     1198 1493  2691 F      557 1278  1835 total 1755 2771  4526 > # Convert frequencies to probabilities > pso <- sex_outcome/ sex_outcome[3, 3] > round(pso, 3)           A     R total M     0.265 0.330 0.595 F     0.123 0.282 0.405 total 0.388 0.612 1.000"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch3-probability-vignette.html","id":"blood-types-data","dir":"Articles","previous_headings":"","what":"Blood types data","title":"Chapter 3: Probability","text":"summary data available data frame blood_types. One way estimate probabilities given Table 3.13 based use aggregate function. divide 100 convert frequencies estimates probability following.","code":"> blood_types   ABO  Rh percentage 1   O Rh+         37 2   A Rh+         35 3   B Rh+          8 4  AB Rh+          3 5   O Rh-          7 6   A Rh-          7 7   B Rh-          2 8  AB Rh-          1 > aggregate(percentage ~ Rh, data = blood_types, FUN = sum)     Rh percentage 1 Rh-         17 2 Rh+         83 > aggregate(percentage ~ ABO, data = blood_types, FUN = sum)   ABO percentage 1   A         42 2  AB          4 3   B         10 4   O         44 > propn <- function(x) sum(x) / 100 > aggregate(percentage ~ Rh, data = blood_types, FUN = propn)     Rh percentage 1 Rh-       0.17 2 Rh+       0.83 > aggregate(percentage ~ ABO, data = blood_types, FUN = propn)   ABO percentage 1   A       0.42 2  AB       0.04 3   B       0.10 4   O       0.44"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"a-screening-test","dir":"Articles","previous_headings":"","what":"A screening test","title":"Chapter 4: More Probability","text":"classic application Bayes’ theorem arises screening disease condition. screening test determine whether person disease. used identify individuals relatively high probability disease therefore may benefit definitive diagnostic test.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"notation","dir":"Articles","previous_headings":"A screening test","what":"Notation","title":"Chapter 4: More Probability","text":"Consider person selected random population take screening test. Let \\(D\\) event disease; \\(+\\) event test positive disease; \\(-\\) event test negative disease.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"properties-of-the-test","dir":"Articles","previous_headings":"A screening test","what":"Properties of the test","title":"Chapter 4: More Probability","text":"mathematical properties test governed following probabilities: sensitivity true positive rate, probability \\(P(+ \\mid D)\\) person disease tests positive; *specificity true negative rate**, probability \\(P(- \\mid \\text{}D)\\) person disease tests negative.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"use-of-bayes-theorem","dir":"Articles","previous_headings":"A screening test","what":"Use of Bayes’ theorem","title":"Chapter 4: More Probability","text":"matters person takes test probability disease given result test. use Bayes’ theorem calculate relevant probabilities. probabilities depend pre-test, prior, probability \\(P(D)\\) person disease. current context, person selected random population, \\(P(D)\\) proportion population disease.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"an-example-type-2-diabetes","dir":"Articles","previous_headings":"","what":"An example: type 2 diabetes","title":"Chapter 4: More Probability","text":"screening test type 2 diabetes (hereafter referred simply diabetes) based blood glucose levels 12-hour period fasting. person tests positive diabetes fasting blood glucose level greater 6.5 mmol/L. Among people untreated diabetes probability \\(P(+ \\mid D)\\) \\(0.933\\). Among people diabetes probability \\(P(+ \\mid \\text{}D) = 0.020\\) much smaller, sensitivity \\(P(- \\mid \\text{}D)\\) test \\(1 - 0.020 = 0.98\\). suppose population interest, perhaps people 50 years age, \\(P(D) = 0.03\\), , \\(3\\%\\) population type 2 diabetes. person tests positive probability diabetes? Bayes’ theorem gives \\[P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)} = \\frac{P(+ \\mid D) P(D)}{P(+ \\mid D) P(D) + P(+ \\mid \\text{}D) P(\\text{}D)},\\] used law total probability denominator. Substituting values probabilities, noting \\(P(\\text{}D) = 1 - 0.03\\), gives person tests negative probability diabetes? Bayes’ theorem gives \\[P(\\text{}D \\mid -) = \\frac{P(- \\mid \\text{}D) P(\\text{}D)}{P(-)} = \\frac{P(- \\mid \\text{}D) P(\\text{}D)}{P(- \\mid \\text{}D) P(\\text{}D) + P(- \\mid D) P(D)},\\] \\(P(- \\mid D) = 1 - P(+ \\mid D) = 1 - 0.933 = 0.067\\).","code":"> 0.933 * 0.03 / (0.933 * 0.03 + 0.020 * 0.97) [1] 0.5906309 > 0.98 * 0.97 / (0.98 * 0.97 + 0.067 * 0.03) [1] 0.99789"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch4-more-probability-vignette.html","id":"the-screening_test-function","dir":"Articles","previous_headings":"An example: type 2 diabetes","what":"The screening_test function","title":"Chapter 4: More Probability","text":"stat0002 R package function screening_test performs calculations.","code":"> library(stat0002) > screening_test(prior = 0.03, sensitivity = 0.933, specificity = 0.98) Prevalence, sensitivity, specificity:        P(D)     P(+ | D)  P(- | notD)         0.030        0.933        0.980   P(positive test), positive and negative predictive values:        P(+)     P(D | +)  P(notD | -)       0.04739      0.59063      0.99789"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"discrete-random-variables","dir":"Articles","previous_headings":"","what":"Discrete random variables","title":"Chapter 5: Random Variables","text":"look two example discrete random variables consider find respective modes, medians means.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"an-example-with-finite-support","dir":"Articles","previous_headings":"Discrete random variables","what":"An example with finite support","title":"Chapter 5: Random Variables","text":"Consider random variable \\(X\\) support \\(\\{ 0, 1, 2 \\}\\) p.m.f. satisfying \\[ P(X=0)=\\frac16 \\qquad  P(X=1)=\\frac12 \\qquad P(X=2)=\\frac13. \\] following code produces plots p.m.f. c.d.f. \\(X\\), fiddling basic plots produce slightly prettier ones.   plot p.m.f. shows mode \\(X\\) 1 plot c.d.f. median \\(X\\) 1. random variable finite support. Therefore, mean \\(\\text{E}(X)\\) exists. calculate \\(\\text{E}(X)\\) using following code.","code":"> # Plot the p.m.f. > x <- 0:2 > px <- c(1/6, 1/2, 1/3) > plot(x, px, type = \"h\", axes = FALSE, ylab = \"P(X = x)\", xlab = \"x\", +      ylim = c(0, 1/2), lwd = 4, cex.lab = 1.5, cex.axis = 1.5, las = 1) > axis(1, at = 0:2, lwd = 2) > axis(2, at = c(0, sort(px)), labels = c(\"0\", \"1/6\", \"1/3\", \"1/2\"), lwd = 2) > # Plot c.d.f. > x0 <- c(-0.5, 0, 0, 1, 1, 2, 2) > y0 <- c(0, 0, 1/6, 1/6, 2/3, 2/3, 1) > x1 <- c(0, 0, 1, 1, 2, 2, 2.5) > y1 <- c(0, 1/6, 1/6, 2/3, 2/3, 1, 1) > plot(c(x0, x1), c(y0, y1), axes = FALSE, ylab = \"\", xlab = \"x\", las = 1, type = \"n\", cex.lab = 1.5,  +      cex.axis = 1.5, lwd = 4) > segments(x0, y0, x1, y1, lty = rep(1, 7), lwd = 2, pch = 0) > axis(1, at = 0:2, labels = 0:2, pos = 0, lwd = 2) > axis(2, at = cumsum(c(0, px)), labels = c(\"0\", \"1/6\", \"2/3\", \"1\"), las = 1, lwd = 2) > title(ylab = expression(\"P(X\"<=\"x)\"), cex.lab = 1.5, line = 2.5) > # Add lines to indicate the median of X > axis(2, at = 1 / 2, labels = \"1/2\", las = 1, lwd = 2) > segments(-0.5, 1 / 2, 1, 1 / 2, lty = 2) > segments(1, 0, 1, 1 / 2, lty = 2) > sum(x * px) [1] 1.166667"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"an-example-with-infinite-support","dir":"Articles","previous_headings":"Discrete random variables","what":"An example with infinite support","title":"Chapter 5: Random Variables","text":"Consider function \\[ p(x) = P(X = x) = \\frac{6}{\\pi^2} \\frac{1}{x^2}, \\quad \\mbox{ } x = 1, 2, 3,\\, ....\\] valid p.m.f. discrete random variable \\(X\\), \\(p(x) \\geq 0\\) \\(x = 1, 2, 3,\\, ...\\) \\(\\sum_{x=1}^{\\infty} p(x) = 1\\) (Basel problem) illustrate 2. look following output plot.  Can find median, mode mean \\(X\\)? trouble finding mean \\(S = \\sum_{x=1}^{\\infty} x p(x)\\) converge. Suppose try approximate value sum using \\(\\hat{S}(m) = \\sum_{x=1}^{m} x p(x)\\) large value \\(m\\). following code plots \\(\\hat{S}(m)\\) \\(m\\) \\(m = 1,..., 100\\).  look like \\(\\hat{S}(m)\\) converging \\(m \\rightarrow \\infty\\)? try larger values \\(m\\) investigate. also examine \\(\\sum_{x=1}^{\\infty} x p(x)\\) algebraically. involve example series seen ? series convergent divergent? distribution special case Zeta distribution, parameter \\(s= 2\\). distribution (finite) mean \\(s > 2\\). \\(s \\(1, 2]\\) can argue either distribution mean infinite mean. simulate samples finite size Zeta distribution \\(s = 2\\) can calculate sample means samples. However, sample means little use us distribution finite mean. values sample means liable influenced values largest sample values may large. VGAM R package function rzeta simulates samples Zeta distribution. like explore sample means behave can use code . repeat times look sample means vary. using VGAM package setting argument shape = 1 corresponds distribution considered.","code":"> m <- 100 > x <- 1:m > px <- (6 / pi ^ 2) / x ^ 2 > mat <- cbind(c(0, x), cumsum(c(0, px))) > plot(mat[, 1], mat[, 2], pch = 20, ann  = FALSE) > title(xlab = \"x\", ylab = expression(P(X <= x))) > abline(h = 1, lty = 2) > tail(mat)        [,1]      [,2]  [96,]   95 0.9936343  [97,]   96 0.9937003  [98,]   97 0.9937649  [99,]   98 0.9938282 [100,]   99 0.9938902 [101,]  100 0.9939510 > m <- 100 > x <- 1:m > px <- (6 / pi ^ 2) / x ^ 2 > s <- cumsum(x * px) > plot(x, s, pch = 20, ann = FALSE) > title(xlab = \"m\") > title(ylab = expression(hat(S)(m)), line = 2.25) > # Install VGAM > install.packages(\"VGAM\") > # Load VGAM > library(VGAM) > # Simulate a sample of size 100 > x <- rzeta(n = 100, shape = 1) > # Calculate the sample mean > mean(x)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"continuous-random-variables","dir":"Articles","previous_headings":"","what":"Continuous random variables","title":"Chapter 5: Random Variables","text":"look continuous random variable may used model Oxford birth times data consider calculate mode, median mean random variable.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"a-simple-model-for-the-oxford-birth-times","dir":"Articles","previous_headings":"Continuous random variables","what":"A simple model for the Oxford birth times","title":"Chapter 5: Random Variables","text":"plot bottom Figure 5.2 notes p.d.f. gamma distribution parameters chosen shape p.d.f. similar histogram times Oxford Birth Times dataset. find gamma distribution type ?GammaDist. following code finds values shape parameter \\(\\alpha\\) scale parameter \\(\\sigma\\) mean variance gamma distribution equal, respectively, sample mean sample variance Oxford birth times data. Can see works? produce basic plot gamma distribution fitted data, check done expected. \\(\\alpha\\) greater 1 mode gamma(\\(\\alpha, \\sigma\\)) distribution \\((\\alpha - 1) \\sigma\\). add vertical line mode check .","code":"> library(stat0002) > tbar <- mean(ox_births$time) > vart <- var(ox_births$time) > # Sample mean and variance > c(tbar, vart) [1]  7.723158 12.731320 > scale_par <- vart / tbar > shape_par <- tbar / scale_par > # Estimates of gamma shape and scale parameters > c(shape_par, scale_par) [1] 4.685073 1.648460 > # Produce the plot > curve(dgamma(x, shape = shape_par, scale = scale_par), 0, 20, ylab = \"p.d.f.\", xlab = \"time (hours)\") > gmode <- (shape_par - 1) * scale_par > gmode [1] 6.074698 > # Indicate the mode > segments(gmode, 0, gmode, dgamma(gmode, shape = shape_par, scale = scale_par), lty =2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"a-digression-about-numerical-optimisation","dir":"Articles","previous_headings":"Continuous random variables","what":"A digression about numerical optimisation","title":"Chapter 5: Random Variables","text":"know find mode using values \\(\\alpha\\) \\(\\sigma\\) try find numerically searching point p.d.f. maximised. functions like common seek maximise log p.d.f.. practice, optimisation algorithms, like function optim used , often set minimise function default. set control option fnscale -1 multiply target function \\(-1\\), turning maximisation problem minimisation problem. Note use ... pass values shape, scale log function fn. Also, method = \"L-BFGS-B\" chooses optimisation method allows us set bounds solution lower = 0 gives information know mode less zero.","code":"> # A function to calculate the (log of the) gamma p.d.f. > fn <- function(x, ...) dgamma(x, ...) > find_mode <- optim(1, fn, shape = shape_par, scale = scale_par, log = TRUE,  +                    method = \"L-BFGS-B\", lower = 0, control = list(fnscale = -1)) > # Approximate value of the mode > find_mode$par [1] 6.074697 > # Value of the p.d.f. at this value > exp(find_mode$value) [1] 0.1232569"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch5-random-variables-vignette.html","id":"a-digression-about-numerical-integration","dir":"Articles","previous_headings":"Continuous random variables","what":"A digression about numerical integration","title":"Chapter 5: Random Variables","text":"can shown algebraically gamma p.d.f. integrates 1. (must true otherwise p.d.f..) R function called integrate performs numerical integration estimate value integral. code uses integrate check gamma p.d.f. integrates 1 \\((0, \\infty)\\). also use integrate check fitted gamma distribution mean expect. Note ... definition function integrand calculates integrand can used pass arguments shape /scale function dgamma calculates p.d.f. gamma distribution. qgamma function can used calculate quantiles given gamma distribution. Suppose wish calculate median (\\(50\\%\\) quantile) fitted gamma distribution. following code . also shows can calculate one quantile time. use integrate check qgamma returned correct median, use function pgamma, calculates c.d.f. gamma random variable.","code":"> # Check that the p.d.f. integrates to 1 > integrate(dgamma, 0, Inf, shape = shape_par, scale = scale_par) 1 with absolute error < 1.1e-08 > # Check that the gamma mean is equal to the sample mean, tbar, of the data > integrand <- function(x, ...) x * dgamma(x, ...) > integrate(integrand, 0, Inf, shape = shape_par, scale = scale_par) 7.723158 with absolute error < 3e-07 > tbar [1] 7.723158 > tmedian <- qgamma(1 / 2, shape = shape_par, scale = scale_par) > tmedian [1] 7.181169 > qgamma(c(0.05, 0.5, 0.95), shape = shape_par, scale = scale_par) [1]  2.926326  7.181169 14.370700 > # Two ways to check that the median is correct > integrate(dgamma, 0, tmedian, shape = shape_par, scale = scale_par) 0.5 with absolute error < 1.1e-08 > pgamma(tmedian, shape = shape_par, scale = scale_par) [1] 0.5"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6a-discrete-random-variables-vignette.html","id":"the-binomial-distribution","dir":"Articles","previous_headings":"","what":"The binomial distribution","title":"Chapter 6: binomial, geometric and Poisson distributions","text":"Following STAT0002 notes, let us suppose (observe data) number \\(Y\\) boy babies random variable binomial(44, \\(p\\)) distribution, \\(p\\) probability randomly chosen birth produces boy. use data estimate \\(p\\). function dbinom evaluates p.m.f. binomial distribution. See ?Binomial information function pbinom, qbinom rbinom. following code produces plot similar ones looked lecture. vary p, perhaps setting equal phat, see effect p.m.f. binomial distribution.  purposes illustrating functions pbinom, qbinom rbinom work, let us suppose \\(p = 1/2\\). used values following probabilities lecture, considered surprised might observe number boys 4 expected value 22 hypothesis \\(p = 1/2\\). Suppose want find median \\(Y\\). can use qbinom: following code simulates 100 values Binomial(44, 1/2) distribution.","code":"> nboys <- sum(aussie_births[, \"sex\"] == \"boy\") > ngirls <- sum(aussie_births[, \"sex\"] == \"girl\") > phat <- nboys / (nboys + ngirls) > phat [1] 0.5909091 > # Plot the binomial(44, 1/2) p.m.f.  > n <- nboys + ngirls > p <- 1 / 2 > y <- 0:n > # Note that dbinom calculates the probabilities all values in the vector y > plot(y, dbinom(y, n, p), type = \"h\", lwd = 3, ylab = \"P(Y = y)\", xlab = \"y\") > # Calculate P(Y >= 26) = P(Y > 25) and P(Y <= 18) > pbinom(25, size = n, prob = 1 / 2, lower.tail = FALSE) [1] 0.1456076 > pbinom(18, n, 1 / 2) [1] 0.1456076 > qbinom(1 / 2, n, 1 / 2) [1] 22 > # A check (look at the definition of the median in the notes) > pbinom(21:23, n, 1 / 2) [1] 0.4401979 0.5598021 0.6742061 > ysim <- rbinom(100, 44, 1 / 2) > ysim   [1] 22 26 22 18 22 30 24 24 20 21 18 21 22 24 19 20 26 22 24 17 23 20 16 24 26  [26] 24 17 24 25 18 20 18 24 24 24 27 19 22 18 21 20 25 26 22 21 25 22 25 23 22  [51] 21 22 26 23 21 28 20 23 22 23 26 23 22 22 19 23 23 19 27 23 27 21 24 21 22  [76] 25 18 22 23 23 20 24 24 28 21 21 21 25 25 23 21 24 23 30 28 19 26 28 20 21 > summary(ysim)    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    16.00   21.00   22.50   22.61   24.00   30.00"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6a-discrete-random-variables-vignette.html","id":"the-distributions3-package","dir":"Articles","previous_headings":"The binomial distribution","what":"The distributions3 package","title":"Chapter 6: binomial, geometric and Poisson distributions","text":"September 2019 distributions3 package (Hayes Moller-Trane 2019) released. neat feature package enables us create R object corresponds particular random variable. able easily use simple R functions perform calculations random variable. way works perhaps intuitive way use functions like dbinom() . reproduce plot repeat calculation probabilities.  Now use distributions package performs calculations involved producing lecture slides associated geometric Poisson distributions.","code":"> library(distributions3)  Attaching package: 'distributions3' The following object is masked from 'package:stats':      Gamma The following object is masked from 'package:grDevices':      pdf > # (The warnings tell us that the distributions3 package has functions with the > # same names as functions from other packages and has `masked' them, that is, > # R will use these functions from distributions3, not the other functions.) > # > # Create an R object that is, effectively, a binomial(n, 1/2) random variable > Y <- Binomial(n, 1 / 2) > Y [1] \"Binomial(size = 44, p = 0.5)\" > # Reproduce the plot.   > plot(0:n, pmf(Y, 0:n), type = \"h\", lwd = 3, ylab = \"P(X = x)\", xlab = \"x\") > 1 - cdf(Y, 25) [1] 0.1456076 > cdf(Y, 18) [1] 0.1456076"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6a-discrete-random-variables-vignette.html","id":"the-geometric-distribution","dir":"Articles","previous_headings":"","what":"The geometric distribution","title":"Chapter 6: binomial, geometric and Poisson distributions","text":"recreate table lecture slides, observed frequencies proportions corresponding estimated expected values geometric distribution fitted data. R’s dgeom function, function Geometric distributions package, based number failures first success, number trials. Therefore, subtract 1 call function dgeom. Alternatively, also use distributions3 package calculate probabilities require.","code":"> # Observed, adding a zero for greater than or equal to 6 > geom <- diff(c(0, which(aussie_births$sex == \"boy\"))) > max_w <- max(geom) > geom <- c(1:(max_w + 1), geom) > obs_freq <- table(geom) - 1 > obs_prop <- obs_freq / sum(obs_freq) > round(obs_prop, 3) geom     1     2     3     4     5     6  0.692 0.115 0.154 0.000 0.038 0.000  >  > # Estimated expected, using dgeom > est_prob <- dgeom((1:max_w) - 1, prob = phat) > est_prob <- c(est_prob, 1 - sum(est_prob)) > exp_freq <- nboys * est_prob >  > # The table > round(cbind(w = 1:(max_w + 1), obs_freq, exp_freq, obs_prop, est_prob), 3)   w obs_freq exp_freq obs_prop est_prob 1 1       18   15.364    0.692    0.591 2 2        3    6.285    0.115    0.242 3 3        4    2.571    0.154    0.099 4 4        0    1.052    0.000    0.040 5 5        1    0.430    0.038    0.017 6 6        0    0.298    0.000    0.011 > W <- Geometric(phat) > W [1] \"Geometric(p = 0.5909)\" > # P(W = w), for w = 1, ..., 5 (note the -1) > pmf(W, 1:5 - 1) [1] 0.59090909 0.24173554 0.09889181 0.04045574 0.01655008 > # P(W >= 6) = 1 - P(W < 6) = 1 - P(W <= 5) > 1 - cdf(W, 5 - 1) [1] 0.01145774"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6a-discrete-random-variables-vignette.html","id":"the-poisson-distribution","dir":"Articles","previous_headings":"","what":"The Poisson distribution","title":"Chapter 6: binomial, geometric and Poisson distributions","text":"use distributions package produce plot p.m.f. Poisson(\\(\\hat{\\lambda}\\)) distribution, \\(\\hat{\\lambda}\\) equal sample mean numbers babies born 24 hourly periods. also calculate probabilities involved table observed estimated expected frequencies given lecture.","code":"> lambdahat <- 44 / 24 > N <- Poisson(lambdahat) > N [1] \"Poisson(lambda = 1.833)\" > plot(0:10, pmf(N, 0:10), type = \"h\", lwd = 3, ylab = \"P(N = n)\", xlab = \"n\") >  > pmf(N, 0:4) [1] 0.15987975 0.29311287 0.26868680 0.16419749 0.07525718 > # P(N >= 5) > 1 - cdf(N, 4) [1] 0.03886592"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6b-continous-random-variables-vignette.html","id":"the-uniform-distribution","dir":"Articles","previous_headings":"","what":"The uniform distribution","title":"Chapter 6: uniform, exponential and normal distributions","text":"say much uniform distribution . However, important distribution standard uniform distribution, U(0, 1), use widely simulate values probability distributions. See Stochastic Simulation vignette details. First, show two ways produce (pseudo-)random sample U(0, 1) distribution. use seed (use ?set.seed find ) show approaches equivalent. distributions3 package actually uses function runif background.","code":"> # Using the runif() function in the stats package > set.seed(13112019) > n <- 10 > u1 <- runif(n) > u1  [1] 0.6499195 0.1472341 0.5326011 0.5731850 0.1622124 0.4371483 0.5716510  [8] 0.3743011 0.2070426 0.9377372 > # Using the distributions3 package to define a U(0, 1) object U > library(distributions3)  Attaching package: 'distributions3' The following object is masked from 'package:stats':      Gamma The following object is masked from 'package:grDevices':      pdf > set.seed(13112019) > U <- Uniform(0, 1) > u2 <- random(U, 10) > u2  [1] 0.6499195 0.1472341 0.5326011 0.5731850 0.1622124 0.4371483 0.5716510  [8] 0.3743011 0.2070426 0.9377372"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6b-continous-random-variables-vignette.html","id":"the-exponential-distribution","dir":"Articles","previous_headings":"","what":"The exponential distribution","title":"Chapter 6: uniform, exponential and normal distributions","text":"inversion method (see Stochastic Simulation vignette details) means can easily transform simulated values produced runif way produces (pseudo-)random sample exponential distribution.  produce histogram sample waiting times Australian birth times data, superimposed exponential density.","code":"> lambda <- 2 > u <- runif(1000) > e1 <- -log(u) / lambda > hist(e1, prob = TRUE, main = \"\") > # Calculate the sample waiting times, in minutes > w <- diff(c(0, aussie_births$time))  > # Estimate lambda (rate of births per minute) > lambdahat <- 1 / mean(w) > # The estimate of the rate of births per hour > lambdahat * 60 [1] 1.839721 > # Histogram and superimposed exponential density > hist(w, prob = TRUE, breaks = 8, axes = FALSE, col = 8, ylim = c(0, 0.03), +      xlab = \"time since last birth (minutes)\", main = \"\") > axis(1, at = seq(0, 160, 20)) > axis(2, at = seq(0, 0.03, 0.005)) > curve(dexp(x, rate = lambdahat), add = TRUE, lwd = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6b-continous-random-variables-vignette.html","id":"the-normal-distribution","dir":"Articles","previous_headings":"","what":"The normal distribution","title":"Chapter 6: uniform, exponential and normal distributions","text":"use birth weights Australian birth times data illustrate perform calculations relating normal distribution.  suppose weight \\(W\\) (pounds) randomly chosen baby \\(N(\\mu, \\sigma^2)\\) distribution, even though seems clear histogram assumption may inappropriate. Suppose \\(W\\) normal distribution, mean equal muhat standard deviation equal sigmahat. example notes calculated \\(P(W > 10)\\), using tables c.d.f. standard normal distribution. perform calculation R either following. answer get slightly different one lecture slides, rounded number (2.38) looked value needed table. confirm R gives answer table (5 decimal places). coffee example lecture slides needed calculate 95% quantile standard N(0, 1) normal random variable. one following ways.","code":"> # Convert weights from grams to pounds > wt <- aussie_births$weight / 453.5 > # Produce a histogram of the birth weights > hist(wt, prob = TRUE, xlab = \"weight (pounds)\", col = 8, main = \"\") > # Estimate the mean, variance and (standard deviation) of W > muhat <- mean(wt) > sigma2hat <- var(wt) > sigmahat <- sd(wt) > pnorm(10, mean = muhat, sd = sigmahat, lower.tail = FALSE) [1] 0.008553284 > W <- Normal(mu = muhat, sigma = sigmahat) > 1 - cdf(W, 10) [1] 0.008553284 > pnorm(2.38) [1] 0.9913437 > 1 - pnorm(2.38) [1] 0.008656319 > qnorm(0.95) [1] 1.644854 > Z <- Normal(0, 1) > quantile(Z, 0.95) [1] 1.644854"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6c-qq-plots-vignette.html","id":"normal-qq-plots","dir":"Articles","previous_headings":"","what":"Normal QQ plots","title":"Chapter 6: QQ plots","text":"create plots similar Figure 6.24 notes. slightly different ones notes R’s qqnorm function uses method calculating theoretical quantiles designed specifically normal distribution, whereas Section 6.11.1 used approach ties way calculated sample quantiles earlier STAT0002. dashed lines plots drawn (sample theoretical) lower upper quartiles.","code":"> # Normal > normal <- rnorm(100)   > qqnorm(normal, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"normal\") > qqline(normal, lwd = 3, lty = 2) > # Create an outlier > outlier <- normal > outlier[100] <- 6 > qqnorm(outlier, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"outlier\") > qqline(outlier, lwd = 3, lty = 2) > # Heavy-tailed (Student's t distribution, with 2 degrees of freedom) > StudentsT <- rt(100, 2) > qqnorm(StudentsT, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"heavy-tailed\") > qqline(StudentsT, lwd = 3, lty = 2) > # Light-tailed (Uniform(-3/4, 3/4)) > uniform <- runif(100, -0.75, 0.75) > qqnorm(uniform, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"light-tailed\") > qqline(uniform, lwd = 3, lty = 2) > # Positively skewed (gamma(2, 1) distribution) > gam <- rgamma(100, shape = 2) > qqnorm(gam, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"positive skew\") > qqline(gam, lwd = 3, lty = 2) > # Negatively skewed (10 - gamma(2, 1) distribution) > neggam <- 10 - rgamma(100, 2) > qqnorm(neggam, pch = 16, xlab = \"Theoretical N(0, 1) Quantiles\", main = \"negative skew\") > qqline(neggam, lwd = 3, lty = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch6c-qq-plots-vignette.html","id":"exponential-qq-plots","dir":"Articles","previous_headings":"","what":"Exponential QQ plots","title":"Chapter 6: QQ plots","text":"produce exponential QQ plot based waiting times births Australian birth times dataset. rate \\(\\lambda\\) assumed Poisson process births estimated using reciprocal sample mean, detailed notes. plot equivalent figure notes, simulation envelopes different , unless fix random number seed, simulated datasets envelopes based different time call qexp.  qqexp function offers option estimate \\(\\lambda\\) using \\(\\ln 2 / m\\), \\(m\\) sample median waiting times. Can see makes sense? following code implements shows can alter appearance plot.","code":"> # Calculate the waiting times until each birth > waits <- diff(c(0, aussie_births[, \"time\"])) > # Produce the QQ plot > lambdahat <- qqexp(waits, envelopes = 19) > # Estimate of lambda: rate of births per hour > lambdahat * 60 estimate of lambda            1.839721 > lambdahat2 <- qqexp(waits, statistic = \"median\", envelopes = 19, pch = 16, +                     line = list(lty = 2, lwd = 2, col= \"blue\")) > # Estimate of lambda calculated from the sample median > lambdahat2 * 60 estimate of lambda             1.56939"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch7-statistical-inference-vignette.html","id":"coin-tossing-example","dir":"Articles","previous_headings":"","what":"Coin-tossing example","title":"Chapter 7: Statistical Inference","text":"section relates Section 7.5.1 notes. calculate Kerrich’s coin data estimate \\(\\hat{p}\\) probability coin lands heads side tosses . produce plot like Figure 7.2. idea repeat Kerrich’s 10,000 coin-toss experiment large number (100,000) times. experiments real: computer simulations. simulations based assumption value \\(p\\) \\(1/2\\). case number heads obtained one experiment (10,000 simulated tosses coin) binomial(\\(10,000, 1/2\\)) distribution.  histogram describes sampling distribution estimator \\(\\hat{p}\\) \\(p\\) Kerrich’s experiment assumption \\(p = 1/2\\). use simulated values \\(\\hat{p}\\) help us judge whether surprised Kerrich’s data produced estimate 0.5067. example, might want calculate proportion simulated values \\(\\hat{p}\\) greater \\(0.5067\\) proportion either greater \\(0.5067\\) less \\(1 - 0.5067 = 0.4933\\). following code . Can see works?","code":"> library(stat0002) > phat <- kerrich[nrow(kerrich), \"heads\"] / kerrich[nrow(kerrich), \"throws\"] > phat [1] 0.5067 > # Set the same random number seed that was used to create Figure 7.2 > # If we change the value of seed then we will obtain a slightly different plot > set.seed(37) > # Number of simulated experiments > nsimulations <- 100000 > # Number of coin tosses on each experiment > ntosses <- 10000 > # Simulate nsimulations (=100,000) times from a binomial(10,000, 1/2) distribution > # This produces a vector nheads of length nsimulations (=100,000) > # Divide each value in nhead by ntosses (=10,000) to produce estimates of p  > nheads <- rbinom(nsimulations, size = ntosses, p = 1 / 2) / ntosses > # Plot a histogram > hist(nheads, prob = TRUE, col = 8, xlab = \"proportion of heads\", ylab = \"density\", main = \"\") > mean(nheads > 0.5067) [1] 0.08694 > mean(nheads > 0.5067 | nheads < 1 - 0.5067) [1] 0.1767"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch7-statistical-inference-vignette.html","id":"estimating-the-parameters-of-a-normal-distribution","dir":"Articles","previous_headings":"","what":"Estimating the parameters of a normal distribution","title":"Chapter 7: Statistical Inference","text":"section relates Section 7.5.2 notes. provide code produces plots like Figure 7.3. details please see notes. can change value n investigate effect changing sample size \\(n\\). following code produces plots.","code":"> set.seed(37) > # Set values of mean and standard deviation > mu <- 7.22 > sigma <- sqrt(1.36) > # Set the sample size n > n <- 3 > # The number of simulated datasets of size n to produce > nsim <- 100000 > # Simulate, producing a matrix with nsim columns and n rows > # Each column contains a simulated sample of size n > x <- matrix(rnorm(nsim * n, mean = mu, sd = sigma), ncol = nsim, nrow = n) > # Calculate the sample means and sample variances of each of the nsim samples > xbars <- colMeans(x) > xvars <- apply(x,2,var) > # Histogram of sample means > br <- seq(from = min(xbars), to = max(xbars), len = 100) > hist(xbars, prob = TRUE, breaks = br, col = 8, xlab = \"sample means\", ylab = \"density\", main = \"\") > title(paste0(\"sample size = \", n)) > curve(dnorm(x, mean = mu, sd = sigma), lty = 2, add = TRUE) > # Histogram of sample variances > br <- seq(from = min(xvars), to = max(xvars), len = 100) > hist(xvars, prob = TRUE, breaks = br, col = 8, xlab = \"sample variances\", ylab = \"density\", main = \"\") > title(paste0(\"sample size = \", n))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch7-statistical-inference-vignette.html","id":"assessing-goodness-of-fit","dir":"Articles","previous_headings":"","what":"Assessing goodness-of-fit","title":"Chapter 7: Statistical Inference","text":"calculate values appear Table 7.1 notes. Firstly, calculate observed frequencies, appear first row table. made two attempts tabulating numbers births hour. Can see first attempt correct? Can see second attempt corrects ? Now, estimate rate \\(\\lambda\\) assumed Poisson process births. Finally, calculate estimated expected frequencies residuals print middle part Table 7.1, rounding values 1 decimal place.","code":"> # Hour of birth > birth_hour <- floor(aussie_births$time / 60) + 1 > # Tabulate the number of births in each hour, attempt 1 > table(birth_hour) birth_hour  1  2  3  5  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   1  3  1  4  2  2  1  3  1  2  1  4  1  2  1  3  4  3  2  1  2  > # Tabulate the number of births in each hour, attempt 2 > add_a_birth_in_each_hour <- 1:max(birth_hour) > births_each_hour <- table(c(birth_hour, add_a_birth_in_each_hour)) - 1 > births_each_hour   1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24   1  3  1  0  4  0  0  2  2  1  3  1  2  1  4  1  2  1  3  4  3  2  1  2  > # Check that we have 44 births > sum(births_each_hour) [1] 44 > # Find the observed frequencies > observed <- table(births_each_hour) > # Add the 5+ category, with frequency 0 > observed <- c(observed, 0) > names(observed)[length(observed)] <- \"5+\"  > observed  0  1  2  3  4 5+   3  8  6  4  3  0 > lambda_hat <- sum(births_each_hour) / 24 > lambda_hat [1] 1.833333 > nbirths <- 0:max(births_each_hour) > estimated_expected <- dpois(nbirths, lambda = lambda_hat) * 24 > estimated_expected <- c(estimated_expected, 24 - sum(estimated_expected)) > estimated_expected [1] 3.8371139 7.0347088 6.4484831 3.9407397 1.8061723 0.9327822 > resids <- observed - estimated_expected > round(rbind(observed, estimated_expected, resids), 1)                       0 1    2   3   4   5+ observed            3.0 8  6.0 4.0 3.0  0.0 estimated_expected  3.8 7  6.4 3.9 1.8  0.9 resids             -0.8 1 -0.4 0.1 1.2 -0.9"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"graduate-admissions-at-berkeley","dir":"Articles","previous_headings":"","what":"Graduate Admissions at Berkeley","title":"Chapter 8: Contingency tables","text":"return data considered briefly Chapter 3: Probability article. object berkeley 3-dimensional array contains information applicants graduate school UC Berkeley 1973 six largest departments. Use ?UCBAdmissions information. 3 dimensions array correspond gender applicant (dimension named Gender), whether admitted (named Admit) letter code department applied (named Dept). given entry berkeley gives total number applicants corresponding (Admit, Gender, Dept) category. Chapter 3, viewed data relating population containing 4526 people applied graduate school Berkeley 1973 seek generalise beyond population. words, treated relative frequencies various categories known probabilities. Now, view data sample data may help us make inferences application process Berkeley general. explore associations categorical variables (Admit, Gender, Dept), perhaps just two variables. Note , following standard statistical terminology, R refers categorical variables factors possible values factors levels.","code":"> library(stat0002)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"Chapter 8: Contingency tables","text":"berkeley dataset \\(2 \\times 2 \\times 6\\) contingency table. 6 departments involved \\(2 \\times 2\\) table variables Admit Gender.","code":"> # Find the dimensions of the data > dim(berkeley) [1] 2 2 6 > # What type of R object is berkeley? > class(berkeley) [1] \"table\" > # Print the data > berkeley , , Dept = A            Gender Admit      Male Female   Admitted  512     89   Rejected  313     19  , , Dept = B            Gender Admit      Male Female   Admitted  353     17   Rejected  207      8  , , Dept = C            Gender Admit      Male Female   Admitted  120    202   Rejected  205    391  , , Dept = D            Gender Admit      Male Female   Admitted  138    131   Rejected  279    244  , , Dept = E            Gender Admit      Male Female   Admitted   53     94   Rejected  138    299  , , Dept = F            Gender Admit      Male Female   Admitted   22     24   Rejected  351    317"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"classes-of-r-objects","dir":"Articles","previous_headings":"The data","what":"Classes of R objects","title":"Chapter 8: Contingency tables","text":"Many objects R class attribute contains (character) vector names, perhaps just one name, describes type object . useful types object standard methods provided, perform common tasks like printing, summarising plotting. code , instead typing berkeley typed print(berkeley). R searches appropriate way print R Console object berkeley, class \"table\". R looks , finds, function print.table use printing. come back later, example consider producing plots contingency table data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"way-tables","dir":"Articles","previous_headings":"","what":"2-way tables","title":"Chapter 8: Contingency tables","text":"collapse 3-way table 2-way table ignoring values one 3 categorical variables. One way use xtabs function stats package, comes standard install R. use xtabs first modify structure data table data frame using function .data.frame. following call xtabs creates 2-way table frequency Freq classified Gender Admit. aggregated (summed) Freq within Gender-Admit category, values Dept. Similarly, ignore Gender Admit produce 2-way table remaining two variables. think variables 2-way table may related might imagine Gender affect value Admit, , gender applicant affect probability applicant admitted. , Gender causal effect Admit, main variable interest example. cases like , call Admit response variable Gender explanatory variable Gender may explain variation response variable Admit. natural consider conditional probabilities levels Admit given value Gender may wish create plots mind. Functions available calculating totals proportions appear Section 8.1 notes Berkeley example Chapter 3 notes. class ga ?","code":"> berkdf <- as.data.frame(berkeley) > berkdf       Admit Gender Dept Freq 1  Admitted   Male    A  512 2  Rejected   Male    A  313 3  Admitted Female    A   89 4  Rejected Female    A   19 5  Admitted   Male    B  353 6  Rejected   Male    B  207 7  Admitted Female    B   17 8  Rejected Female    B    8 9  Admitted   Male    C  120 10 Rejected   Male    C  205 11 Admitted Female    C  202 12 Rejected Female    C  391 13 Admitted   Male    D  138 14 Rejected   Male    D  279 15 Admitted Female    D  131 16 Rejected Female    D  244 17 Admitted   Male    E   53 18 Rejected   Male    E  138 19 Admitted Female    E   94 20 Rejected Female    E  299 21 Admitted   Male    F   22 22 Rejected   Male    F  351 23 Admitted Female    F   24 24 Rejected Female    F  317 > ga <- xtabs(Freq ~ Gender + Admit, berkdf) > ga         Admit Gender   Admitted Rejected   Male       1198     1493   Female      557     1278 > # Total number of applicants > marginSums(ga) [1] 4526 > # Number of males and females > marginSums(ga, \"Gender\") Gender   Male Female    2691   1835  > # Number of admitted and rejected applicants > marginSums(ga, \"Admit\") Admit Admitted Rejected      1755     2771  > # Add the marginal totals to the table > addmargins(ga)         Admit Gender   Admitted Rejected  Sum   Male       1198     1493 2691   Female      557     1278 1835   Sum        1755     2771 4526 > # Calculate proportions (relative frequencies) > proportions(ga)         Admit Gender    Admitted  Rejected   Male   0.2646929 0.3298719   Female 0.1230667 0.2823685 > # Row proportions (sum to 1 across the rows) > proportions(ga, \"Gender\")         Admit Gender    Admitted  Rejected   Male   0.4451877 0.5548123   Female 0.3035422 0.6964578 > # Column proportions (sum to 1 down the columns) > proportions(ga, \"Admit\")         Admit Gender    Admitted  Rejected   Male   0.6826211 0.5387947   Female 0.3173789 0.4612053 > class(ga) [1] \"xtabs\" \"table\""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"plotting-frequencies","dir":"Articles","previous_headings":"2-way tables","what":"Plotting frequencies","title":"Chapter 8: Contingency tables","text":"object ga 2 things vector class names: \"xtabs\" \"table\". means available us methods functions created use objects class \"xtabs\" class \"table\". , example, use code plot(ga) , \"xtabs\" appears first vector class names, R looks first function called plot.xtabs. find function name looks plot.table. finds neither uses function plot.default. function plot.default definitely exists, designed specific input object might work. case, function plot.xtabs function plot.table. table least 2 factors plot.table produces plot using function mosaicplot graphics package, also comes standard install R. Let’s see happens .  mosaic plot produced. First, plot area first split two parts vertically, sizes parts reflecting marginal distribution first variable (Gender ). , widths rectangles proportional numbers males females respectively. can see males data females. similar splits made horizontally within vertical parts, sizes parts determined conditional distribution second variable (Admit) conditional value first variable, , conditional Gender = Male Gender = Female. Recall said earlier made sense consider conditioning Gender done plot. Therefore, plot pretty much like . may prefer display conditional distribution Admit given Gender horizontally plot, rather vertically. following code achieves , using argument dir, determines whether split first horizontal vertical direction. information plot , cosmetically slightly different.  can see applicants rejected admitted proportion males admitted greater proportion females admitted. placed variables data frame order , unless make adjustment, mosaic plot produced conditioning Admit first, producing following plot.  wrong, concentrates conditional probabilities Gender given Admit, want. can use argument sort reverse order mosaic plots takes variables reproduce preferred plot.","code":"> plot(ga, main = \"Observed frequencies\", color = TRUE) > plot(ga, main = \"Observed frequencies\", color = TRUE, dir = c(\"h\", \"v\")) > ag <- xtabs(Freq ~ Admit + Gender, berkdf) > ag           Gender Admit      Male Female   Admitted 1198    557   Rejected 1493   1278 > # Alternatively, we could have transposed ga > t(ga)           Gender Admit      Male Female   Admitted 1198    557   Rejected 1493   1278 > plot(ag, main = \"Observed frequencies\", color = TRUE) > plot(ag, main = \"Observed frequencies\", color = TRUE, sort = 2:1)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"calculating-estimated-expected-frequencies","dir":"Articles","previous_headings":"2-way tables","what":"Calculating estimated expected frequencies","title":"Chapter 8: Contingency tables","text":"estimate expected frequencies assumption variables Gender Admit independent. use R calculate , using outer function . Look ?outer see . Alternatively, can use function chisq.test stats package. come back function later, moment want values estimated expected frequencies calculates. also produce mosaic plot estimated expected frequencies  expect, relative sizes estimated expected frequencies Admitted Rejected males females. provides us visual illustration mosaic plots observed frequencies look approximately like variables concerned independent. horizontal vertical gaps rectangles look approximately like grid horizontal gaps vertical gaps approximately lined .","code":"> efreq <- outer(marginSums(ga, \"Gender\"), marginSums(ga, \"Admit\")) / marginSums(ga) > efreq         Admit Gender    Admitted Rejected   Male   1043.4611 1647.539   Female  711.5389 1123.461 > # Check using chisq.test > efreq <- chisq.test(ga)$expected > efreq         Admit Gender    Admitted Rejected   Male   1043.4611 1647.539   Female  711.5389 1123.461 > # Trick R into using plot.table > class(efreq) <- \"table\" > # Plot estimated expected frequencies > plot(efreq, main = \"Estimated expected frequencies\", color = TRUE,  +      dir = c(\"h\", \"v\"))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"plotting-residuals","dir":"Articles","previous_headings":"2-way tables","what":"Plotting residuals","title":"Chapter 8: Contingency tables","text":"assocplot function graphics package produces association plot summarises (Pearson) residuals vary combinations categories. vertical extent rectangle proportional corresponding Pearson residual width proportional square root estimated expected frequency. Therefore, area box proportional corresponding (raw) residual, , difference observed estimated expected frequency. Look definitions residuals Section 8.1.1 see works.  Comparing rectangles horizontal dashed line, see men admitted expected Gender Admit independent.","code":"> assocplot(ga, col = c(\"black\", \"grey\"))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"testing-association","dir":"Articles","previous_headings":"2-way tables","what":"Testing association","title":"Chapter 8: Contingency tables","text":"function chisq.test stats package can used perform chi-squared outlined end Section 8.1.1 notes. specify correct = FALSE produce result given notes, , use Yates’s correction continuity. value test statistic \\(92.205\\) much larger expected hypothesis Gender Admit independent. Therefore, reject hypothesis.","code":"> chisq.test(ga, correct = FALSE)      Pearson's Chi-squared test  data:  ga X-squared = 92.205, df = 1, p-value < 2.2e-16"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"the-vcd-package","dir":"Articles","previous_headings":"2-way tables","what":"The vcd package","title":"Chapter 8: Contingency tables","text":"vcd package (Meyer, Zeileis, Hornik (2022)) provides various functions summarise, visualise make inferences using categorical data. functions mosaic assoc produce plots equivalent produced plot.table assocplot . deals easily aspects tables dimension greater 2 functions base R offers features. One extra feature functions mosaic assoc ability shade rectangles association plot colours reflect size residual. can draw attention cells contingency table large residuals help us spot patterns. default, functions base shading values Pearson residuals. reflects contributions test statistic chi-squared test. might also like option shade based values standardised Pearson residuals. variables Gender Admit independent residuals look approximately sampled standard normal distribution. Therefore, values greater 2 magnitude unusual - approximate probability \\(5%\\) occurring - values greater 4 magnitude surprising. code providing values standardised Pearson residuals functions vcd package, using argument residuals. mosaic plot just effects numbers colour key. association plots using standardisation Pearson residuals changes vertical extents rectangles plots, now area rectangle proportional residual. \\(2 \\times 2\\) case standardised Pearson residuals magnitude vertical extents equal. technical reason, wanting change label legend plot using residuals_type, call vcd function strucplot, plotting function underlying function assoc. function mosaic also allows us colour parts moasic plot based values residuals.    plots indicate (effectively one) standardised Pearson residual magnitude (\\(9.6\\)) much larger expect Gender Admit independent. larger contingency tables, cells (combinations factors) /2 dimensions, can use colouring like draw attention patterns data departures independence.","code":"> library(vcd) > # Extract the standardised Pearson residuals > x2test <- chisq.test(ga) > # Raw residuals > x2test$observed - x2test$expected         Admit Gender    Admitted  Rejected   Male    154.5389 -154.5389   Female -154.5389  154.5389 > # Pearson residuals > x2test$residuals         Admit Gender    Admitted  Rejected   Male    4.784093 -3.807325   Female -5.793466  4.610614 > # Standardised Pearson residuals > x2test$stdres         Admit Gender    Admitted  Rejected   Male    9.602358 -9.602358   Female -9.602358  9.602358 > # Association plot of residuals with Pearson residual shading > assoc(ga, shade = TRUE, margins = c(2.25, 1, 1, 2.5)) > # Association plot of residuals with standardised Pearson residual shading > strucplot(ga, shade = TRUE, residuals = x2test$stdres,  +           margins = c(2.25, 1, 1, 2.5), +           residuals_type = \"Standardised\\nPearson\\nresiduals\", core = struc_assoc, +           keep_aspect_ratio = FALSE, legend_width = 6) > # Mosaic plot with standardised Pearson residual shading > mosaic(ga, shade = TRUE, residuals = x2test$stdres,  +        residuals_type = \"Standardised Pearson\", margins = c(0, 0, 0, 0))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"way-tables-1","dir":"Articles","previous_headings":"","what":"3-way tables","title":"Chapter 8: Contingency tables","text":"3 () variables many possible associations examine. See Section 8.2 notes details. produce moasic plot based three variables berkeley dataset. avoid cluttering plot text, create new object x levels Admit abbreviated.  plot tells us quite lot. look individually parts plot relating departments B F find Gender Admit look approximately independent within departments. department Admit seem depend Gender larger proportion females apply department admitted males.","code":"> b <- berkeley > dimnames(b)$Admit <- c(\"A\", \"R\") > dimnames(b)$Gender <- c(\"M\", \"F\") > plot(b, main = \"Observed frequencies\", sort = 3:1, color = c(1, 8))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"mutual-independence","dir":"Articles","previous_headings":"3-way tables","what":"Mutual independence","title":"Chapter 8: Contingency tables","text":"noted Section 8.2.1 seems little point asking whether 3 variables Gender, Admit Dept independent already concluded Gender Admit independent. However, perform chi-squared test case, time using generic function summary. object class table function calls chisq.test perform test also includes basic summary table output.","code":"> summary(berkeley, correction = FALSE) Number of cases in table: 4526  Number of factors: 3  Test for independence of all factors:     Chisq = 2000.3, df = 16, p-value = 0"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"marginal-independence","dir":"Articles","previous_headings":"3-way tables","what":"Marginal independence","title":"Chapter 8: Contingency tables","text":"examine association Dept Gender Admit Dept. create function assoc2 takes contingency table tab standardised residuals residuals arguments, can shorten code needed create association plot rectangles shaded based standardised Pearson residuals.","code":"> assoc2 <- function(tab, residuals, ...) { +   strucplot(tab, shade = TRUE, residuals = residuals,  +             residuals_type = \"Standardised Pearson\", core = struc_assoc, ...) + }"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"gender-and-department","dir":"Articles","previous_headings":"3-way tables > Marginal independence","what":"Gender and department","title":"Chapter 8: Contingency tables","text":"strong differences preferences females males concerning departments apply. Males prefer departments B females departments, particularly departments C E.","code":"> gd <- xtabs(Freq ~ Gender + Dept, berkdf) > x2test <- chisq.test(gd, correct = FALSE) > assoc2(gd, residuals = x2test$stdres, margins = c(0, 0, 0, 0))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"admittance-and-department","dir":"Articles","previous_headings":"3-way tables > Marginal independence","what":"Admittance and department","title":"Chapter 8: Contingency tables","text":"plot suggests probability admittance much greater departments B, departments males like apply. Departments E F relatively low probability acceptance females likely males apply departments.","code":"> ad <- xtabs(Freq ~ Admit + Dept, berkdf) > x2test <- chisq.test(ad, correct = FALSE) > assoc2(ad, residuals = x2test$stdres, margins = c(0, 0, 0, 0))"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch8-contingency-tables-vignette.html","id":"conditional-independence","dir":"Articles","previous_headings":"3-way tables","what":"Conditional independence","title":"Chapter 8: Contingency tables","text":"plots seen provide possible explanation fact overall probability admittance lower females males: males likely apply departments higher probability admittance. Now explore successful females males admitted Berkeley within departments F, , condition variable Dept. use vcd function cotabplot produce association plot departments F. shading rectangles based Pearson residuals.  see department substantial difference admittance probability females males, females better males. Finally, focus department change shading based standardised Pearson residuals, mainly see common magnitude \\(4.15\\).","code":"> cotabplot(~ Admit + Gender | Dept, data = berkeley, layout = 3:2, shade = TRUE, +           panel = cotab_assoc) > # A function to produce an association plot within a given department > deptplot <- function(dept) { +   temp <- xtabs(Freq ~ Admit + Gender, berkdf,  +                 subset = berkdf[, \"Dept\"] == dept) +   x2test <- chisq.test(temp, correct = FALSE) +   assoc2(temp, residuals = x2test$stdres, main = paste(\"Dept \", dept)) +   return(x2test$stdres) + } > deptplot(\"A\") Gender Admit           Male    Female   Admitted -4.153073  4.153073   Rejected  4.153073 -4.153073"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example data","title":"Chapter 9: Linear regression","text":"use Hubble data described start Section 9.1 notes. data available data frame hubble.","code":"> hubble    distance velocity 1     0.032      170 2     0.034      290 3     0.214     -130 4     0.263      -70 5     0.275     -185 6     0.275     -220 7     0.450      200 8     0.500      290 9     0.500      270 10    0.630      200 11    0.800      300 12    0.900      -30 13    0.900      650 14    0.900      150 15    0.900      500 16    1.000      920 17    1.100      450 18    1.100      500 19    1.400      500 20    1.700      960 21    2.000      500 22    2.000      850 23    2.000      800 24    2.000     1090 > plot(rev(hubble), pch = 16)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"the-r-function-lm","dir":"Articles","previous_headings":"","what":"The R function lm","title":"Chapter 9: Linear regression","text":"R provides function lm fit linear regression models. following code fits simple linear regression model hubble data, distance response variable velocity one explanatory variable. lm function can much example, can fit regression model one explanatory variable. point estimates intercept \\(\\alpha\\) gradient \\(\\beta\\) regression parameters agree title Figure 9.6 notes. Note coef generic function (tries ) extracts parameter estimates fitted model object.","code":"> l3 <- lm(distance ~ velocity, data = hubble) > l3   Call: lm(formula = distance ~ velocity, data = hubble)  Coefficients: (Intercept)     velocity      0.399098     0.001373   > coef(l3) (Intercept)    velocity  0.399098216 0.001372936"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"our-own-function-slm","dir":"Articles","previous_headings":"","what":"Our own function slm","title":"Chapter 9: Linear regression","text":"exercise writing R function demonstrate expressions least squares estimators \\(\\hat{\\alpha}\\) \\(\\hat{\\beta}\\) given Section 9.1.2 correct, write function slm perform simple linear regression. give returned (list) object class \"lm\", including call (code calls function slm) coefficients (estimated regression parameters \\(\\alpha\\) \\(\\beta\\)) print results looks like lm. also include useful quantities, names indicate contain. include argument rto, stands “regression origin”. data, Hubble’s Law gives us reason consider special linear regression model fitted line forced go origin, , intercept parameter \\(\\alpha\\) set \\(0\\) rather estimated data. also deal situation explanatory data provided. information see Section 9.1.3 notes. following code fits Model 3 Section 9.1.3, plots data adds fitted regression line.  sake completeness also fit Models 1 2 Section 9.1.3, assume, respectively, \\(\\beta=0\\) \\(\\alpha = 0\\), show results agree lm.","code":"> slm <- function(y, x, rto = FALSE) { +   # If only response data are provided then fit a horizontal line y = mean(y) +   if (missing(x)) { +     residuals <- y - mean(y) +     rss <- sum(residuals ^ 2) +     n <- length(y) +     estimates <- mean(y) +     names(estimates) <- \"(Intercept)\" +     res <- list(coefficients = estimates, fitted.values = mean(y), +                 residuals = y - mean(y), rss = rss,  +                 sigmahat = sqrt(rss / (n - 1)), y = y, call = match.call()) +     class(res) <- \"lm\" +     return(res) +   } +   # Check that y and x have the same length   +   if (length(y) != length(x)) { +     stop(\"''y'' and ''x'' must have the same length\") +   } +   # Calculate the estimates.  If rto = FALSE (the default) then we estimate  +   # both alpha and beta from the data.  If rto = TRUE then we set alpha = 0 +   # and estimate only beta from the data. +   ybar <- mean(y) +   if (rto) { +     betahat <- mean(x * y) / mean(x ^ 2) +     alphahat <- 0 +     estimates <- betahat +     names(estimates) <- deparse(substitute(x)) +   } else { +     xbar <- mean(x) +     betahat <- mean((x - xbar) * (y - ybar)) / mean((x - xbar) ^ 2) +     alphahat <- ybar - betahat * xbar +     estimates <- c(alphahat, betahat) +     names(estimates) <- c(\"(Intercept)\", deparse(substitute(x))) +   } +   # Calculate the fitted values for y, residuals and residual sum of squares +   fittedy <- alphahat + betahat * x +   residuals <- y - fittedy +   rss <- sum(residuals ^ 2) +   # Estimate of the error standard deviation sigma +   n <- length(y) +   p <- length(estimates) +   sigmahat <- sqrt(rss / (n - p)) +   # Create the results list  +   res <- list(coefficients = estimates, fitted.values = fittedy,  +               residuals = residuals, rss = rss, sigmahat = sigmahat, +               y = y, x = x, call = match.call())   +   class(res) <- \"lm\" +   return(res) + } > # Model 3 > m3 <- slm(y = hubble$distance, x = hubble$velocity) > m3  Call: slm(y = hubble$distance, x = hubble$velocity)  Coefficients:     (Intercept)  hubble$velocity          0.399098         0.001373   > plot(rev(hubble), pch = 16) > abline(coef = coef(m3)) > # Model 1 > # ~1 means that there is no explanatory variable in the model > m1 <- slm(y = hubble$distance) > l1 <- lm(distance ~ 1, data = hubble) > coef(m1) (Intercept)     0.911375  > coef(l1) (Intercept)     0.911375  >  > # Model 2 > # The -1 removes the intercept from the model > m2 <- slm(y = hubble$distance, x = hubble$velocity, rto = TRUE) > l2 <- lm(distance ~ velocity - 1, data = hubble) > coef(m2) hubble$velocity      0.001921806  > coef(l2)    velocity  0.001921806"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"estimating-the-error-standard-deviation","dir":"Articles","previous_headings":"","what":"Estimating the error standard deviation","title":"Chapter 9: Linear regression","text":"unbiased estimator error variance \\(\\sigma^2\\) sum squared residuals divided \\(n - p\\), \\(n\\) sample size \\(p\\) number parameter estimated. See Section 9.1.2, considers case \\(\\alpha\\) \\(\\beta\\) estimated. following, sigma function (tries ) calculate estimate standard deviation \\(\\sigma\\) errors. , commonly case, taking square root estimate \\(\\sigma^2\\). , function agrees output lm.","code":"> m3$sigmahat [1] 0.4049588 > sigma(m3) [1] 0.4049588 > sigma(l3) [1] 0.4049588"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"standardised-residuals","dir":"Articles","previous_headings":"","what":"Standardised residuals","title":"Chapter 9: Linear regression","text":"Section 9.3 notes define standardised residuals \\(\\)th observation data \\[r_i^S = \\frac{r_i}{\\hat{\\sigma}(1-h_{ii})},\\] \\(r_i\\) residual observation \\(\\), \\(\\hat{\\sigma}\\) estimate error standard deviation \\[h_{ii} = \\frac1n + \\frac{(x_i - \\bar{x}) ^ 2}{\\sum_{=1}^n (x_i - \\bar{x}) ^ 2}.\\] leverage observation \\(\\). model correct residuals approximately variance 1. errors normally distributed residuals look like sample standard normal distribution. write function calculate standardised residuals model fit produced slm use function next section produce normal QQ plot standardised residuals.","code":"> stres <- function(slmfit) { +   # The generic function nobs tries to calculate the number of observations +   n <- nobs(slmfit) +   # Extract the values of the explanatory variables +   x <- slmfit$x +   # Calculate the leverage value for each observation +   sx2 <- (x - mean(x)) ^ 2 +   hii <- 1 / n + sx2 / sum(sx2) +   return(slmfit$residuals / (slmfit$sigmahat * sqrt(1 - hii ^ 2))) + }"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9-linear-regression-vignette.html","id":"residual-plots","dir":"Articles","previous_headings":"","what":"Residual plots","title":"Chapter 9: Linear regression","text":"plot residuals values explanatory variable, velocity, fitted values. one explanatory variable plots look identical, apart change scale horizontal axis. fitted values linear function, \\(\\hat{\\alpha} + \\hat{\\beta} x\\), corresponding value \\(x\\) explanatory variable.   Now, produce normal QQ plot standardised residuals check correct using built-plot function lm objects, selecting = 2 ask normal QQ plot.","code":"> plot(m3$x, m3$residual, ylab = \"residual\", xlab = \"velocity\", pch = 16) > abline(h = 0, lty = 2) > plot(m3$fitted.values, m3$residual, ylab = \"residual\", xlab = \"fitted values\", pch = 16) > abline(h = 0, lty = 2) > stresiduals <- stres(m3) > qqnorm(stresiduals, ylab = \"Standardised Residuals\") > qqline(stresiduals) > # By default, the 3 residuals with the largest magnitudes are labelled by their observation number > plot(l3, which = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9plus1-correlation-vignette.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example data","title":"Chapter 10: Correlation","text":"use exchange rate data described start Section 10.1 notes. data available data frame exchange. look first 6 rows data last 6 rows produce plots like Figures 10.1 10.2 notes.","code":"> head(exchange)            USD.GBP CAD.GBP 1997/01/02  1.6865  2.3167 1997/01/03  1.6905  2.3224 1997/01/06  1.6855  2.3056 1997/01/07  1.6951  2.2999 1997/01/08  1.6884  2.2850 1997/01/09  1.6947  2.2906 > tail(exchange)            USD.GBP CAD.GBP 2000/11/14  1.4309  2.2102 2000/11/15  1.4265  2.2121 2000/11/16  1.4229  2.2088 2000/11/17  1.4233  2.2194 2000/11/20  1.4223  2.2172 2000/11/21  1.4169  2.2029 > # Figure 10.1 > plot(exchange, pch = 16, xlab = \"Pounds sterling vs. US dollars\", +      ylab = \"Pounds sterling vs. Canadian dollars\", bty = \"l\",  +      main = \"Raw data\") > # Calculate the log-returns > USDlogr <- diff(log(exchange$USD.GBP)) > CADlogr <- diff(log(exchange$CAD.GBP)) > # Figure 10.2 > plot(USDlogr, CADlogr, pch = 16, xlab = \"Pounds sterling vs. US dollars\", +      ylab = \"Pounds sterling vs. Canadian dollars\", bty = \"l\",  +      main = \"Log-returns\" )"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9plus1-correlation-vignette.html","id":"the-r-function-cor","dir":"Articles","previous_headings":"","what":"The R function cor","title":"Chapter 10: Correlation","text":"R provides function cor calculate sample correlation coefficients. default, calculates sample (product moment) correlation coefficient given Section 10.2.1. can supply either two vectors x y equal length matrix columns containing vectors data want calculate sample correlation coefficient. case, create 2-column matrix using cbind function combine 2 vectors USDlogr CADlogr columnwise matrix. supply matrix R return matrix containing sample correlation coefficients possible pairs columns input matrix, including column , produces values 1 diagonal output matrix. supply vectors x y matter vector entered x y.","code":"> cor(x = USDlogr, y = CADlogr) [1] 0.8201113 > cor(x = CADlogr, y = USDlogr) [1] 0.8201113 > cor(x = cbind(USDlogr, CADlogr))           USDlogr   CADlogr USDlogr 1.0000000 0.8201113 CADlogr 0.8201113 1.0000000"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-ch9plus1-correlation-vignette.html","id":"anscombes-quartet-of-datasets","dir":"Articles","previous_headings":"","what":"Anscombe’s Quartet of datasets","title":"Chapter 10: Correlation","text":"Section 10.3.6 Anscombe’s Quartet dataset provided Figure 10.9. 4 datasets available separate data frames anscombiser package Northrop (2022). Use install.packages(\"anscombiser\") install package. see paired data datasets almost exactly sample correlation coefficient. many summary statistics common. See Section 10.3.6 details. method argument cor enables us ask R calculate Spearman’s rank correlation coefficient (See Section 2.3.5). values sample correlation coefficient differ datasets.","code":"> library(anscombiser) > cor(anscombe1)           x1        y1 x1 1.0000000 0.8164205 y1 0.8164205 1.0000000 > cor(anscombe2)           x2        y2 x2 1.0000000 0.8162365 y2 0.8162365 1.0000000 > cor(anscombe3)           x3        y3 x3 1.0000000 0.8162867 y3 0.8162867 1.0000000 > cor(anscombe4)           x4        y4 x4 1.0000000 0.8165214 y4 0.8165214 1.0000000 > cor(anscombe1, method = \"spearman\")           x1        y1 x1 1.0000000 0.8181818 y1 0.8181818 1.0000000 > cor(anscombe2, method = \"spearman\")           x2        y2 x2 1.0000000 0.6909091 y2 0.6909091 1.0000000 > cor(anscombe3, method = \"spearman\")           x3        y3 x3 1.0000000 0.9909091 y3 0.9909091 1.0000000 > cor(anscombe4, method = \"spearman\")     x4  y4 x4 1.0 0.5 y4 0.5 1.0"},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"copy-and-paste","dir":"Articles","previous_headings":"","what":"Copy-and-paste","title":"Creating PDF files using R markdown","text":"least elegant approach, simple. weekly exercises include title like “Exercises 1” full name student ID number. Type text answer questions usual way. Highlight code output, e.g. using left click mouse. Copy highlighted text e.g. right click Copy. Navigate word processor file paste text like appear, e.g. right click Paste. Right click “Copy Image” paste document, Right click “Save image …”, save import image file document, Click “Export” plot “Copy Clipboard”, Click “Export” “Save image …”, save import image file document. finished, save file PDF format. weekly exercises","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"r-markdown-in-rstudio","dir":"Articles","previous_headings":"","what":"R Markdown in RStudio","title":"Creating PDF files using R markdown","text":"assume using RStudio. might find R Markdown: Definitive Guide helpful. provided template R Markdown file ex1template.Rmd use. may like rename file. replace ex1template text name choose. Follow link, click “Download raw file” (downwards pointing arrow) icon near top right page. Move file directory choice click open new RStudio session. file open RStudio, RStudio installed. several ways create PDF using .Rmd file. easiest way use Knit button, also outline approaches call R function command prompt > RStudio Console.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"using-the-knit-button","dir":"Articles","previous_headings":"","what":"Using the Knit button","title":"Creating PDF files using R markdown","text":"title “Template Rmd document Exercises 1” Knit button triangle right side.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"knit-to-word","dir":"Articles","previous_headings":"Using the Knit button","what":"Knit to Word","title":"Creating PDF files using R markdown","text":"Click triangle select either “Knit Word”. file ex1template.docx created chosen directory. software enables open Word document ex1template.docx file can save file PDF format.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"knit-to-html","dir":"Articles","previous_headings":"Using the Knit button","what":"Knit to HTML","title":"Creating PDF files using R markdown","text":"select “Knit HTML” file ex1template.html created. can create PDF file ex1template.html opening browser, e.g. Google chrome, printing PDF.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"knit-to-pdf","dir":"Articles","previous_headings":"Using the Knit button","what":"Knit to PDF","title":"Creating PDF files using R markdown","text":"possible Knit directly PDF format selecting “Knit PDF” option. However, requires installation LaTeX - software designed create nice-looking mathematics - available RStudio computer using. expect never heard LaTeX, may need unless final year project. However, “Knit PDF” work like see follow instructions Chapter 1 Installation R Markdown: Definitive Guide creating LaTeX installation using TinyTeX.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"using-an-r-function","dir":"Articles","previous_headings":"","what":"Using an R function","title":"Creating PDF files using R markdown","text":"Knit button creates output different types calling R function, rmarkdown package, called render. following code work provided Rmd file located current working directory, case started RStudio session clicking Rmd file open . check , use getwd function:","code":"> getwd()"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"the-accessr-package","dir":"Articles","previous_headings":"Using an R function","what":"The accessr package","title":"Creating PDF files using R markdown","text":"accessr package provides functions call render certain output file formats. following command line R code creates Word HTML documents. Word document look bit different one produced accessr uses different default style Word document.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"word-and-html","dir":"Articles","previous_headings":"Using an R function > The accessr package","what":"Word and HTML","title":"Creating PDF files using R markdown","text":"","code":"> # Load accessr > library(accessr) > # Knit and render to Word  > rmd2word(\"ex1template\", pdf = FALSE) > # Knit and render to HTML > rmd2html(\"ex1template\", pdf = FALSE)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"pdf","dir":"Articles","previous_headings":"Using an R function > The accessr package","what":"PDF","title":"Creating PDF files using R markdown","text":"using Microsoft Windows can set pdf = TRUE create automatically PDF copy output Word document. requires OfficeToPDF software installed. Similarly, Windows, macOS linux, can print HTML output PDF automatically.","code":"> # Install OfficeToPDF from https://github.com/cognidox/OfficeToPDF/releases > install_otp(dir = \"accessr\") > # Knit and render to Word and PDF > # (Microsoft Windows only) > rmd2word(\"ex1template\", pdf = TRUE) > # Knit and render to HTML and print to PDF > # (Need a browser, such as Google Chrome or Microsoft Edge) > rmd2html(\"ex1template\", pdf = TRUE)"},{"path":"https://github.com/paulnorthrop/stat0002/articles/stat0002-creating-pdf-files-vignette.html","id":"the-stat0002-package","dir":"Articles","previous_headings":"Using an R function","what":"The stat0002 package","title":"Creating PDF files using R markdown","text":"installed stat0002 package can save key strokes using convenience functions word() html, example:","code":"> # Load stat0002 > library(stat0002) > word(\"ex1template\", pdf = FALSE) > html(\"ex1template\", pdf = FALSE)"},{"path":"https://github.com/paulnorthrop/stat0002/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Paul J. Northrop. Author, maintainer, copyright holder.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Northrop PJ (2025). stat0002: Introduction Probability Statistics. R package version 1.2.3, https://github.com/paulnorthrop/stat0002, https://paulnorthrop.github.io/stat0002/.","code":"@Manual{,   title = {stat0002: Introduction to Probability and Statistics},   author = {Paul J. Northrop},   year = {2025},   note = {R package version 1.2.3,      https://github.com/paulnorthrop/stat0002},   url = {https://paulnorthrop.github.io/stat0002/}, }"},{"path":[]},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"what-does-stat0002-do","dir":"","previous_headings":"Introduction to Probability and Statistics","what":"What does stat0002 do?","title":"Introduction to Probability and Statistics","text":"stat0002 package provides R code, datasets, articles (tutorials demonstrating use R code) ‘movies’ (interactive plots) help students taking STAT0002 Introduction Probability Statistics University College London (UCL) understand course material see R can used perform analyses course. Currently, compulsory use R studying STAT0002. However, strongly recommended use R make use content stat0002 package. able use statistical computing package like R essential performing statistical analyses many students taking STAT0002 need use R modules. information R see STAT0004 Moodle page (taking STAT0004) Introduction R Moodle page (taking STAT0004, e.g. Natural Sciences students).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"software-required","dir":"","previous_headings":"Introduction to Probability and Statistics","what":"Software required","title":"Introduction to Probability and Statistics","text":"need install R can get CRAN. Choose computer’s operating system: Windows, macOS Linux. change default installation settings. users older Intel Macs: parts stat0002 uses tcltk package, may need install XQuartz. recommend use RStudio (free user-friendly front-end R). Install Download RStudio page. Find Installers near bottom page choose installer operating system.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"installation-of-stat0002","dir":"","previous_headings":"Introduction to Probability and Statistics","what":"Installation of stat0002","title":"Introduction to Probability and Statistics","text":"Copy paste following R console press return. copy paste ONE following R Console press return. Choose option relevant computer.","code":"install.packages(c(\"accessr\", \"anscombiser\", \"distributions3\", \"plotrix\", \"rgl\", \"rpanel\", \"rust\", \"smovie\", \"SuppDists\", \"tkrplot\", \"vcd\"))"},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"windows","dir":"","previous_headings":"Introduction to Probability and Statistics > Installation of stat0002","what":"Windows","title":"Introduction to Probability and Statistics","text":"","code":"install.packages(\"https://github.com/paulnorthrop/stat0002/raw/master/install/stat0002.zip\", repos = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"apple-macos","dir":"","previous_headings":"Introduction to Probability and Statistics > Installation of stat0002","what":"Apple MacOS","title":"Introduction to Probability and Statistics","text":"","code":"install.packages(\"https://github.com/paulnorthrop/stat0002/raw/master/install/stat0002.tgz\", repos = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"linux","dir":"","previous_headings":"Introduction to Probability and Statistics > Installation of stat0002","what":"Linux","title":"Introduction to Probability and Statistics","text":"","code":"install.packages(\"https://github.com/paulnorthrop/stat0002/raw/master/install/stat0002.tar.gz\", repos = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"getting-started","dir":"","previous_headings":"Introduction to Probability and Statistics","what":"Getting started","title":"Introduction to Probability and Statistics","text":"type open main help page, contains links articles tutorials R code, datasets movies. Index bottom links help files individual functions datasets. ?stat0002 doesn’t work close RStudio, reopen try . However, perhaps convenient source information stat0002 home page GitHub, help files Reference tutorials Articles (direct link: Articles).","code":"library(stat0002) ?stat0002"},{"path":"https://github.com/paulnorthrop/stat0002/index.html","id":"suggestions-about-how-to-use-this-resource","dir":"","previous_headings":"Introduction to Probability and Statistics","what":"Suggestions about how to use this resource","title":"Introduction to Probability and Statistics","text":"Use tutorials see content STAT0002 produced. questions consider tutorials. Look example datasets arise module. Play R. Run ‘movies’ shown STAT0002 workshops videos . Look code R functions. example, type scatter R console press return see content function scatter. Use ?scatter find function look code see . find tutorials contain ideas yet covered lectures occasionally things beyond scope STAT0002. want try understand ideas cover please use links information provided.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/aussie_births.html","id":null,"dir":"Reference","previous_headings":"","what":"Australian Birth Times Data — aussie_births","title":"Australian Birth Times Data — aussie_births","text":"baby arrivals data introduced Chapter 6 STAT0002 notes. Information concerning 44 babies (18 girls 26 boys) born 24-hour period Mater Mothers' Hospital, Brisbane, Australia, December 18, 1997.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/aussie_births.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Australian Birth Times Data — aussie_births","text":"","code":"aussie_births"},{"path":"https://github.com/paulnorthrop/stat0002/reference/aussie_births.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Australian Birth Times Data — aussie_births","text":"data frame 44 observations following 3 variables. time: number minutes past midnight   baby born. sex: character variable, sex baby (\"girl\"   \"boy\"). weight: weight baby grams.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/aussie_births.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Australian Birth Times Data — aussie_births","text":"Steele, S. (December 21, 1997), Babies Dozen Christmas: 24-Hour Baby Boom, Sunday Mail (Brisbane), page 7.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/berkeley.html","id":null,"dir":"Reference","previous_headings":"","what":"Student Admisions at UCL Berkeley — berkeley","title":"Student Admisions at UCL Berkeley — berkeley","text":"Aggregate data applicants graduate school Berkeley six largest departments 1973 classified admission sex.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/berkeley.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Student Admisions at UCL Berkeley — berkeley","text":"","code":"berkeley"},{"path":"https://github.com/paulnorthrop/stat0002/reference/berkeley.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Student Admisions at UCL Berkeley — berkeley","text":"object class table dimension 2 x 2 x 6.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/berkeley.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Student Admisions at UCL Berkeley — berkeley","text":"copy UCBAdmissions data   provided datasets package.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Binomial p.m.f. movie — binomial_pmf_movie","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"movie illustrate probability mass function (p.m.f.) binomial (n, p) random variable depends n p. discrete distributions, including geometric Poisson distributions, use smovie::movies() click Discrete menu. based discrete function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"","code":"binomial_pmf_movie(   starting_n = 1,   starting_p = 1/2,   delta_n = 1,   delta_p = 0.05,   observed_value = NA )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"starting_n numeric scalar.  value n first graph. starting_p numeric scalar.  value p first graph. delta_n numeric scalar.  amount n increased (decreased) one click + (-) button parameter window. delta_p numeric scalar.  amount p increased (decreased) one click + (-) button parameter window. observed_value non-negative integer.  observed_value supplied corresponding line plot p.m.f. coloured red.  observed_value integer round(observed_value) used.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"probability mass function binomial random variable   parameters \\(n\\) (number Bernoulli trials performed)   \\(p\\) (probabilities success trial) plotted.   values \\(n\\) \\(p\\) can changed clicking   relevant buttons.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/binomial_pmf_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Binomial p.m.f. movie — binomial_pmf_movie","text":"","code":"binomial_pmf_movie()   # Increase n and see what happens binomial_pmf_movie(delta_n = 10)  # Sample size of the Aussie births data (26 boys, 18 girls) binomial_pmf_movie(starting_n = 44, starting_p = 0.1, delta_p = 0.1,                    observed_value = 26)   # Start at p = 0.591 (approximately 26/44) binomial_pmf_movie(starting_n = 44, starting_p = 0.591, delta_p = 0.01,                    observed_value = 26)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/birds.html","id":null,"dir":"Reference","previous_headings":"","what":"Between-species dominance in birds data — birds","title":"Between-species dominance in birds data — birds","text":"Francis et al. (2018) conducted experiment study competitive interactions 10 species birds.  data presented Table 1 paper.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/birds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Between-species dominance in birds data — birds","text":"","code":"birds"},{"path":"https://github.com/paulnorthrop/stat0002/reference/birds.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Between-species dominance in birds data — birds","text":"data frame 10 observations following 8 variables. species: two-letter abbreviation bird species. species_name: common bird species name. sci_name: scientific bird species name. mass_g: mean species mass grams. dom_rank: dominance rank, smaller value   dominant species tends species. dom_rank_LCI: lower 95% confidence limit dominance   rank. dom_rank_UCI: upper 95% confidence limit dominance   rank.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/birds.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Between-species dominance in birds data — birds","text":"S1 dataset.   Data species identities, mass dominance rankings   Francis et al (2018).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/birds.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Between-species dominance in birds data — birds","text":"Francis M.L., Plummer K.E., Lythgoe B.., Macallan C., Currie T.E.,   Blount J.D. (2018) Effects supplementary feeding interspecific   dominance hierarchies garden birds. PLoS ONE 13(9): e0202152.   https://doi.org/10.1371/journal.pone.0202152","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/blood_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Blood Types — blood_types","title":"Blood Types — blood_types","text":"Percentages people UK 8 main ABO-Rhesus blood groups.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/blood_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blood Types — blood_types","text":"","code":"blood_types"},{"path":"https://github.com/paulnorthrop/stat0002/reference/blood_types.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Blood Types — blood_types","text":"data frame 8 observations following 3 variables. ABO: Blood type ABO system (, B O). rhesus: Blood type Rhesus system (Rh+ Rh-). percentage: Percentage people ABO-Rhesus blood type .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Box-Cox transformed density functions — boxcox_plot","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"Box-Cox transforms input data x plots histogram transformed data.  Box-Cox transformation parameter lambda. probability density function (pdf) data arisen known function density_fn supplied calculate pdf also Box-Cox transformed resulting transformed pdf superimposed histogram.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"","code":"boxcox_plot(   x,   lambda = 1,   density_fn = NULL,   breaks = \"Sturges\",   main = \"\",   ... )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"x numeric vector data. lambda numeric scalar.  Box-Cox transformation parameter \\(\\lambda\\). density_fn function calculate pdf underlying input data. breaks argument breaks hist. Provided give control appearance histograms. main argument main hist. Provided enable title added plot. ... arguments density_fn ().","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"Nothing, just plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"equation $$y = (x ^ \\lambda - 1) / \\lambda.$$   Box-Cox transformation variable \\(x\\) produce   transformed variable variable \\(y\\).  value parameter   \\(\\lambda\\) governs behaviour transformation. See vignette Chapter 2: Graphs (One Variable) details code Examples .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxcox_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Box-Cox transformed density functions — boxcox_plot","text":"","code":"# Log-normal distribution --------------------  # X has a log-normal distribution if ln(X) has a normal distribution  # Simulate a sample of size 100 from a log-normal distribution x <- rlnorm(100)  # Plot the data and the log-normal density function boxcox_plot(x, density_fn = dlnorm, main = \"data and true density function\")  # If we want to transform to approximate normality which power should we use? boxcox_plot(x, density_fn = dlnorm, lambda = 0, main = \"after transformation\")   # We can use the data to suggest a good value of lambda. # We need the boxcox() function in the MASS package. library(MASS) #>  #> Attaching package: 'MASS' #> The following object is masked from 'package:stat0002': #>  #>     shuttle  # Very loosely speaking ... # In this plot better values of lambda have the largest values. # \"Better\" means \"transformed data closer to looking like a sample # from a normal distribution. # We could choose a nice value of lambda close to the best value. # The interval is a 95% confidence interval for lambda. boxcox(x ~ 1)   # exponential distribution --------------------  x2 <- rexp(100) boxcox_plot(x2 ,density_fn = dexp, main = \"data and true density function\")   boxcox_plot(x2, density_fn = dexp, lambda = 1 / 3, main = \"after transformation\")  boxcox(x2 ~ 1) abline(v = 1/3, col = \"red\")   # A distribution that I made up --------------------  dpn <- function(x) ifelse(x > 0 & x < 1, 2 * x, 0) rpn <- function(n = 1) sqrt(runif(n)) x3 <- rpn(100) boxcox_plot(x3, density_fn = dpn)  boxcox_plot(x3, density_fn = dpn, lambda = 2)   boxcox(x3 ~ 1)  boxcox(x3 ~ 1, lambda = seq(0, 4, 1 / 10))  boxcox_plot(x3, density_fn = dpn, lambda = 1.5)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxplot_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Box Plot Statistics — boxplot_stats","title":"Box Plot Statistics — boxplot_stats","text":"copy boxplot.stats adds argument type passed quantile calculating sample quantiles.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxplot_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box Plot Statistics — boxplot_stats","text":"","code":"boxplot_stats(x, coef = 1.5, do.conf = TRUE, do.out = TRUE, type = 6)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/boxplot_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box Plot Statistics — boxplot_stats","text":"x numeric vector boxplot constructed (NAs NaNs allowed omitted). coef determines far plot whiskers extend box. coef positive, whiskers extend extreme data point coef times length box away box. value zero causes whiskers extend data extremes (outliers returned). .conf, .logicals; FALSE, conf component respectively empty result. type Argument type quantile.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Box plots — box_plot","title":"Box plots — box_plot","text":"Produce box--whisker plot(s) given (grouped) values, option (using argument type) change estimator used estimate quartiles.  argument described type.  details arguments see Arguments section boxplot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Box plots — box_plot","text":"type integer 1 9 selecting one nine quantile algorithms detailed Details section quantile documentation.  default type = 6.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Box plots — box_plot","text":"list contents described Value   section boxplot documentation.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Box plots — box_plot","text":"See Details section boxplot   documentation.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Box plots — box_plot","text":"See Usage section boxplot   documentation.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/box_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Box plots — box_plot","text":"","code":"birth_times <- ox_births[, \"time\"] box_plot(birth_times)  box_plot(birth_times, horizontal = TRUE)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/clouds.html","id":null,"dir":"Reference","previous_headings":"","what":"Cloud-seeding data — clouds","title":"Cloud-seeding data — clouds","text":"data used STAT0002 notes introduce idea transforming data approximate symmetry.  dataset contains amounts rainfall, acre-feet, produced 52 clouds.  Half clouds chosen random seeded silver nitrate.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clouds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cloud-seeding data — clouds","text":"","code":"clouds"},{"path":"https://github.com/paulnorthrop/stat0002/reference/clouds.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cloud-seeding data — clouds","text":"data frame 26 observations following 2 variables. unseeded: rainfall amount unseeded clouds. seeded: rainfall amount unseeded clouds.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clouds.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cloud-seeding data — clouds","text":"Simpson, J., Olsen, . , Eden. J.C. (1975). Bayesian analysis multiplicative treatment effect weather modification. Technometrics, 17, 161-166.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Central Limit Theorem movie: exponential data — clt_exponential_movie","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"movie illustrate idea sampling distribution central limit theorem (CLT) situation data simulated randomly exponential distribution. movie can also opened using smovie::movies() selecting exponential CLT menu. based lev_inf function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"","code":"clt_exponential_movie(   n = 10,   lambda = 1,   xlab = \"x\",   pos = 1,   envir = as.environment(pos) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"n integer scalar.  size samples drawn normal distribution. lambda numeric scalar.  rate parameter exponential distribution data simulated using rexp. xlab character scalar.  name use label horizontal axis plots. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"Loosely speaking, consequence   Central Limit Theorem (CLT)   , many situations, mean large number   independent random variables approximately normal distribution,   even original variables normally distributed. movie illustrates case original variables   exponentially distributed.  Samples size n repeatedly   simulated exponential distribution.  samples   summarized using histogram appears top movie screen.   sample mean n values calculated, stored   added another histogram plotted first histogram.   (exponential) probability density function (p.d.f.) original   variables superimposed top histogram.  bottom histogram   superimposed approximate (large n) p.d.f. given   CLT. user may choose sample size n, , number   values mean calculated, rate parameter lambda   exponential normal distribution values simulated   label xlab horizontal axis. starts, two aspects movie controlled user.   Firstly, buttons increase (+) decrease (-) sample   size, , number values mean calculated.   button labelled \"simulate another sample size n\".   time button clicked new sample simulated sample   mean added bottom histogram. Another movie (clt_normal_movie) considers special case   original variables normally distributed.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_exponential_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Central Limit Theorem movie: exponential data — clt_exponential_movie","text":"","code":"# Produce movie using values based on the Aussie births data clt_exponential_movie(44, 1.84, \"time since last birth (hours)\")   # ... and with some smaller sample sizes clt_exponential_movie(10, 1.84, \"time since last birth (hours)\")   clt_exponential_movie(3, 1.84, \"time since last birth (hours)\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Central Limit Theorem movie: normal data — clt_normal_movie","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"movie illustrate ideas sampling distribution random variable central limit theorem (CLT).  case (based random samples normal distribution) CLT provides exact result. movie can also opened using smovie::movies() selecting normal CLT menu. based lev_inf function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"","code":"clt_normal_movie(   n = 30,   mu = 0,   sigma = 1,   xlab = \"x\",   pos = 1,   envir = as.environment(pos) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"n integer scalar.  size samples drawn normal distribution. mu, sigma Numeric scalars.  respective mean standard deviation normal distribution data simulated using rnorm. xlab character scalar.  name use label horizontal axis plots. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"Loosely speaking, consequence   Central Limit Theorem (CLT)   , many situations, mean large number   independent random variables approximately normal distribution,   even original variables normally distributed. movie illustrates special case original   variables normally distributed.  Samples size n   repeatedly simulated normal distribution.  samples   summarized using histogram appears top movie screen.   sample mean n values calculated, stored   added another histogram plotted first histogram.   respective probability density functions (p.d.f.s) original   variables means superimposed histograms.   latter know exactly normal p.d.f. special case. user may choose sample size n, , number   values mean calculated, mean mu /  standard deviation sigma normal distribution   values simulated label xlab horizontal axis. starts, two aspects movie controlled user.   Firstly, buttons increase (+) decrease (-) sample   size, , number values mean calculated.   button labelled \"simulate another sample size n\".   time button clicked new sample simulated sample   mean added bottom histogram. Another movie (clt_exponential_movie) illustrates CLT   case original variables exponentially distributed.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/clt_normal_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Central Limit Theorem movie: normal data — clt_normal_movie","text":"","code":"clt_normal_movie(44, 7.22, sqrt(1.36), \"weight (pounds)\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"movie illustrate sampling distribution product moment sample correlation coefficient \\(r\\) depends sample size \\(n\\) true correlation \\(\\rho\\).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"","code":"corr_sim_movie(   n = 30,   rho = 0,   panel_plot = TRUE,   hscale = NA,   vscale = hscale,   delta_n = 1,   delta_rho = 0.1,   ... )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"n integer scalar.  initial value sample size. Must less 2. rho numeric scalar.  initial value true correlation \\(\\rho\\).  Must [-1, 1]. panel_plot logical parameter determines whether plot placed inside panel (TRUE) standard graphics window (FALSE).  plot placed inside panel tkrplot library required. hscale, vscale Numeric scalars.  Scaling parameters size plot panel_plot = TRUE. default values 1.4 Unix platforms 2 Windows platforms. delta_n integer scalar.  amount value sample size increased/decreased one click +/- button. delta_rho numeric scalar.  amount value rho increased/decreased one click +/- button. ... Additional arguments rpanel functions rp.button rp.doublebutton, including panel, variable, title, step, action, initval, range.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"Random samples size \\(n\\) simulated   bivariate normal distribution   variables mean 0 variance 1   correlation \\(\\rho\\) variables chosen user. movie contains two plots.  top scatter plot   simulated sample, illustrating strength association   simulated values variables.   new sample produced clicking \"simulate another sample.   simulated sample sample (product moment) correlation   coefficient \\(r\\) calculated displayed title top   plot. values sample correlation coefficients stored   plotted histogram bottom plot.  rug displays individual   values, recent value coloured red. accumulate large   number values histogram shape sampling   distribution \\(r\\) emerges.  exact p.d.f. \\(r\\)   superimposed histogram, value \\(\\rho\\). bottom plot can changed two ways:   () radio button can pressed replace histogram pdf   plot empirical c.d.f. exact cdf;   (ii) variable can changed \\(\\rho\\) Fisher's   z-transformation \\(F(\\rho) = arctanh(\\rho) = [ln(1+\\rho) - ln(1-\\rho)]/2\\).   sufficiently large values \\(n\\), \\(F(\\rho)\\) approximately   normal distribution mean \\(\\rho\\) variance   \\(1 / (n - 3)\\). values sample size \\(n\\) true correlation coefficient   \\(\\rho\\) can changed using respective +/- buttons.   one changed bottom plot   reset using sample correlation coefficient first sample   simulated using new combination \\(n\\) \\(\\rho\\).","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/corr_sim_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sampling distribution of the correlation coefficient movie — corr_sim_movie","text":"","code":"corr_sim_movie(rho = 0.8) corr_sim_movie(n = 10)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Create PDF, Word or HTML R output — create_pdf","title":"Create PDF, Word or HTML R output — create_pdf","text":"Functions create PDF files containing R output /Microsoft Word HTML files PDF files can produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create PDF, Word or HTML R output — create_pdf","text":"","code":"word(x, pdf = isTRUE(.Platform$OS.type == \"windows\"), zip = FALSE, ...)  html(x, pdf = TRUE, zip = FALSE, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create PDF, Word or HTML R output — create_pdf","text":"x character vector containing names (extension) .Rmd files convert current working directory, paths files, either absolute relative current working directory, e.g., DIRECTORY/file1.  output files created directory respective .Rmd file.  x missing output file created .Rmd files current working directory, given getwd(). pdf logical scalar, either TRUE FALSE.   pdf = FALSE PDF files created. pdf = TRUE   happens depends whether word html used. word: Operating System \"windows\", ,     .Platform$OS.type == \"windows\" `OfficeToPDF` software     installed (see install_otp) PDF file     created Word file. Otherwise, PDF files created. html: html file printed PDF file using     chrome_print function pagedown package.     Google Chrome must installed prior use option. error     message like Error servr::random_port(NULL) : find     available TCP port means random_port function     servr package find internet connection Chrome     considers secure.  Perhaps using coffee shop's wifi. zip logical scalar. argument zip rmd2word rmd2html. zip = TRUE zip archives produced containing files created. ... arguments passed rmd2word (function word) rmd2html (function html). Explain zip.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create PDF, Word or HTML R output — create_pdf","text":"addition creating required files, list containing   information files created. See Return section   rmd2word rmd2html   details.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create PDF, Word or HTML R output — create_pdf","text":"functions rmd2word (word)   rmd2html (html)   accessr-package used.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Create PDF, Word or HTML R output — create_pdf","text":"pandoc software version 1.14 higher required,   , rmarkdown::pandoc_available(\"1.14\") must return TRUE.   pandoc installed automatically using RStudio.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/create_pdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create PDF, Word or HTML R output — create_pdf","text":"","code":"if (FALSE) { # \\dontrun{ # We copy example.Rmd to the current working directory. # Then we call word() and html().  eg <- system.file(package = \"stat0002\", \"examples\", \"example.Rmd\") file.copy(eg, getwd(), overwrite = TRUE)  # These examples are not run when the package is tested because they will # not work on all operating systems.  # Create a Word file only word(\"example\", pdf = FALSE)  # Create an HTML file only html(\"example\", pdf = FALSE)  # We repeat this passing pdf = TRUE to create PDF files.  # Create a Word file and a PDF file word(\"example\", pdf = TRUE)  # Create an HTML file and a PDF file html(\"example\", pdf = TRUE) } # }"},{"path":"https://github.com/paulnorthrop/stat0002/reference/daley.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","title":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","text":"Detailed results final Men's Individual 10m platform final Tokyo 2020 Olympic Games.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/daley.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","text":"","code":"daley"},{"path":"https://github.com/paulnorthrop/stat0002/reference/daley.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","text":"data frame 60 observations following 17 variables.   10 competitors one row data 6 dives.   competitor, first row relates first round dives   sixth row last round. Rank: Final position (rank) competition. Name: Full name. NOCcode: Country code. DiveNo: Code type dive performed. DD: Degree difficulty: larger number   difficult dive. J1-J7: Respective scores 7 judges. DivePoints: Points awarded dive, based scores   degree difficulty. DiveRank: rank dive round question.    raw data entries like \"=2\", resulting ties.    daley \"=\" sign removed ranks stored numeric   scalars, e.g. 2. TotalPoints: total point accumulated dives   round competition. OverallRank: rank diver current round.   raw data entries like \"=2\", resulting ties.    daley \"=\" sign removed ranks stored numeric   scalars, e.g. 2. PointsBehind: number points diver behind   leader current round.  diver leader   missing (NA).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/daley.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","text":"Tokyo 2020 Diving Results, specifically Men's 10m Platform Results.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/daley.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tokyo 2020 Olympics Men's Individual 10m platform — daley","text":"DivePoints calculated : removing 2 smallest 2   largest scores 7 scores J1-J7; calculating sum   3 scores remain; multiplying result DD.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/days.html","id":null,"dir":"Reference","previous_headings":"","what":"Mystery data in Exercises 1 — days","title":"Mystery data in Exercises 1 — days","text":"task Exercises 1 guess data represent using summary plots statistics.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/days.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mystery data in Exercises 1 — days","text":"","code":"days"},{"path":"https://github.com/paulnorthrop/stat0002/reference/days.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Mystery data in Exercises 1 — days","text":"numeric vector.  unit measurement days.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculation of diving scores — diving","title":"Calculation of diving scores — diving","text":"Functions implement four ways calculate points awarded dive diving competition, including way used Olympic Games.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculation of diving scores — diving","text":"","code":"dmean(   x,   DD = \"DD\",   scores = paste0(\"J\", 1:7),   trim = 2/7,   replace = TRUE,   reorder = TRUE )  dmedian(   x,   DD = \"DD\",   scores = paste0(\"J\", 1:7),   type = 6,   replace = TRUE,   reorder = TRUE )  dmode(x, DD = \"DD\", scores = paste0(\"J\", 1:7), replace = TRUE, reorder = TRUE)  tables(x, type = 1, diverRanks = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculation of diving scores — diving","text":"x numeric matrix data frame, ideally format daley. DD character (numeric) scalar giving column name (number) x contains DD (degree difficulty) values dive.  default set work data daley. scores character (numeric) vector giving column names (numbers) x contain 7 scores dive.  default set work data daley. trim relevant divemean. Passed mean. default, trim = 2 / 7, corresponds calculation using diving competitions. replace logical scalar.  replace = FALSE vector dive points returned. replace = TRUE DivePoints, DiveRank, TotalPoints, OverallRank PointsBehind columns updated light new values dive points data frame returned.  named columns exist returned object replace = FALSE case. reorder logical scalar.  replace = TRUE reorder determines whether order divers changed reflect new values TotalPoints end competition. type Determines form data frame returned summary table. type = 0: Rank, Name, NOCcode (Country), TotalPoints     end competition. type = 1: DD, J1-J7 dive points (already     x). type = 2: like type = 1 gives dive points,     points based mean, median mode. type = 3: like type = 2 gives total     points accumulated competition, ordered dive points. type = 4: like type = 3 totals replaced     ranks. diverRanks ranks divers included table. example, diverRanks gives medalists.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculation of diving scores — diving","text":"numeric vector dive points replace = FALSE x   appropriately named columns.  Otherwise, dataframe   structure x columns DivePoints,   DiveRank, TotalPoints, OverallRank   PointsBehind updated light new dive points   values.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculation of diving scores — diving","text":"default case, e.g. dmean(daley), 2 smallest   2 largest scores 7 scores removed; sum 3 remaining   scores calculated; result multiplied dive's   degree difficulty. Another way think take sample mean 3   middle scores, multiply 3, multiply degree   difficulty. dmean(daley, trim = 0) case take sample mean   7 scores, multiply 3, multiply degree difficulty.   , trim 2 smallest 2 largest values. Similarly, dmedian(daley) dmode(daley) cases   take sample median mode, respectively, 7 scores,   multiply 3, multiply degree difficulty.   one sample mode use sample mean modes.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/diving.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculation of diving scores — diving","text":"","code":"# The calculation used in competitions (trimmed sample sums) dmean(daley, replace = FALSE) #>  [1] 102.00  81.60  97.20  97.20 101.75 102.60  90.10  94.50  89.25  91.20 #> [11] 102.60 112.75  98.60  91.20  91.80  80.50  94.35  91.80  75.20  91.80 #> [21]  85.75  81.00  94.35  86.40  68.80  91.80  91.80  73.80  83.25  86.40 #> [31]  83.20  79.20  88.20  56.10  75.00  80.00  72.00  86.40  75.85  86.40 #> [41]  35.70  75.60  57.60  61.20  74.25  76.50  72.00  88.80  68.80  72.60 #> [51]  39.60  88.80  69.70  68.40  60.80  79.20  46.20  79.55  56.10  72.00 #> [61]  67.20  59.40  48.60  69.70  66.60  72.15  67.20  59.40  59.50  42.50 #> [71]  72.15  81.00 #> attr(,\"statistic\") #> [1] \"DivePoints\"  # An equivalent calculation without trimming dmean(daley, replace = FALSE, trim = 0) #>  [1] 100.54286  82.28571  96.42857  97.20000 102.27857 104.14286  88.88571 #>  [8]  93.00000  89.25000  92.01429 103.37143 113.33571  97.62857  91.20000 #> [15]  91.80000  81.00000  95.93571  91.80000  74.74286  90.34286  85.50000 #> [22]  79.45714  94.35000  86.40000  69.25714  93.25714  92.57143  74.05714 #> [29]  82.45714  84.08571  84.34286  78.49286  88.71429  56.10000  75.85714 #> [36]  79.54286  71.31429  87.17143  74.52857  85.62857  37.15714  74.82857 #> [43]  58.28571  61.71429  74.25000  76.50000  73.28571  91.17857  69.94286 #> [50]  72.12857  42.42857  89.59286  68.48571  68.65714  60.34286  79.90714 #> [57]  45.96429  80.07857  56.10000  71.31429  67.88571  60.94286  49.37143 #> [64]  67.02857  66.34286  73.73571  67.20000  59.40000  59.25000  43.71429 #> [71]  72.94286  79.45714 #> attr(,\"statistic\") #> [1] \"MeanPoints\"  # An equivalent calculation based on a sample median dmedian(daley, replace = FALSE) #>  [1] 102.00  81.60  97.20  97.20  99.90 102.60  91.80  94.50  89.25  91.20 #> [11] 102.60 110.70  96.90  91.20  91.80  78.75  94.35  91.80  76.80  91.80 #> [21]  84.00  81.00  94.35  86.40  67.20  91.80  91.80  75.60  83.25  86.40 #> [31]  81.60  79.20  86.40  56.10  76.50  81.60  72.00  86.40  77.70  86.40 #> [41]  35.70  75.60  57.60  59.40  74.25  76.50  70.20  88.80  67.20  74.25 #> [51]  39.60  88.80  71.40  70.20  62.40  79.20  44.55  77.70  56.10  72.00 #> [61]  67.20  59.40  48.60  71.40  64.80  72.15  67.20  59.40  57.75  40.80 #> [71]  72.15  81.00 #> attr(,\"statistic\") #> [1] \"MedianPoints\"  # An equivalent calculation based on a sample mode dmode(daley, replace = FALSE) #>  [1] 102.000  81.600  97.200  97.200  99.900 102.600  91.800  94.500  89.250 #> [10]  91.200 102.600 110.700  99.450  91.200  91.800  78.750  94.350  91.800 #> [19]  76.800  91.800  86.625  81.000  94.350  86.400  67.200  91.800  91.800 #> [28]  75.600  83.250  86.400  81.600  79.200  86.400  56.100  72.000  81.600 #> [37]  72.000  86.400  77.700  86.400  35.700  75.600  57.600  59.400  74.250 #> [46]  76.500  70.200  88.800  67.200  74.250  39.600  88.800  71.400  67.500 #> [55]  62.400  79.200  47.025  77.700  56.100  72.000  67.200  59.400  48.600 #> [64]  71.400  67.500  72.150  67.200  59.400  60.375  40.800  72.150  81.000 #> attr(,\"statistic\") #> [1] \"ModePoints\""},{"path":"https://github.com/paulnorthrop/stat0002/reference/exchange.html","id":null,"dir":"Reference","previous_headings":"","what":"UK/US and UK/Canada Exchange Rates — exchange","title":"UK/US and UK/Canada Exchange Rates — exchange","text":"exchange data frame 975 rows 2 columns. columns contain daily exchange rates; UK sterling US dollar (first column) UK sterling Canadian dollar (second column). rownames contain corresponding dates character string format \"2000/05/26\". can converted POSIXct POSIXlt object using .POSIXct .POSIXlt.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/exchange.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"UK/US and UK/Canada Exchange Rates — exchange","text":"","code":"exchange"},{"path":"https://github.com/paulnorthrop/stat0002/reference/exchange.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"UK/US and UK/Canada Exchange Rates — exchange","text":"data frame contains following columns: USD.GBP: US UK exchange rate. CAD.GBP: Canada UK exchange rate.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/exchange.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"UK/US and UK/Canada Exchange Rates — exchange","text":"Coles, S. G. (2001) Introduction Statistical Modelling   Extreme Values. London: Springer.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/exchange.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"UK/US and UK/Canada Exchange Rates — exchange","text":"","code":"# This produces a plot like Figure 10.1 of the STAT0002 notes plot(exchange)   # The produces a plot like Figure 10.2 of the STAT0002 notes # Calculate the log-returns USDlogr <- diff(log(exchange$USD.GBP)) CADlogr <- diff(log(exchange$CAD.GBP)) plot(USDlogr, CADlogr)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":null,"dir":"Reference","previous_headings":"","what":"Five number summary — five_number","title":"Five number summary — five_number","text":"Calculates five number summary vector data column matrix data, using estimators lower quartile, median upper quartile STAT002 notes.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Five number summary — five_number","text":"","code":"five_number(x, type = 6, na.rm = FALSE)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Five number summary — five_number","text":"x numeric vector matrix. type Argument type used call quantile estimate 25%, 50% 75% quantiles. na.rm logical scalar.  true, NA NaNs removed x sample quantiles computed.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Five number summary — five_number","text":"numeric vector (input vector) matrix (input   matrix).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Five number summary — five_number","text":"five number summary contains sample minimum maximum   estimates lower quartile, median upper quartile, .e.   25%, 50% 75% quantiles.  quantiles estimated using   quantile function.  default, type = 6   used call quantile order use estimator defined   STAT002 notes.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/five_number.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Five number summary — five_number","text":"","code":"birth_times <- ox_births[, \"time\"] five_number(birth_times) #>   min   25%   50%   75%   max  #>  1.50  4.90  7.50  9.75 19.00   # Note: summary() uses type = 7 in the call to quantile() five_number(birth_times, type = 7) #>   min   25%   50%   75%   max  #>  1.50  4.95  7.50  9.75 19.00  summary(birth_times) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   1.500   4.950   7.500   7.723   9.750  19.000"},{"path":"https://github.com/paulnorthrop/stat0002/reference/flu.html","id":null,"dir":"Reference","previous_headings":"","what":"Influenza data — flu","title":"Influenza data — flu","text":"numbers people (thousands people) UK visiting doctor symptoms influenza (flu) four-weekly time periods time period 28th January 1967 13th November 2004.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/flu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Influenza data — flu","text":"","code":"flu"},{"path":"https://github.com/paulnorthrop/stat0002/reference/flu.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Influenza data — flu","text":"data frame 494 observations following 2 variables. date: date. visits: number people visiting doctor symptoms flu.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ftse.html","id":null,"dir":"Reference","previous_headings":"","what":"FTSE 100 Share Index — ftse","title":"FTSE 100 Share Index — ftse","text":"Weekly closing prices FTSE 100 share index 2nd April 1984 13th August 2007.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ftse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"FTSE 100 Share Index — ftse","text":"","code":"ftse"},{"path":"https://github.com/paulnorthrop/stat0002/reference/ftse.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"FTSE 100 Share Index — ftse","text":"data frame 1220 observations following 2 variables. date: date. price: closing price date.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble.html","id":null,"dir":"Reference","previous_headings":"","what":"Nebulae data from Hubble (1929) — hubble","title":"Nebulae data from Hubble (1929) — hubble","text":"data used Section 9.1 STAT0002 notes introduce simple linear regression.  dataset contains estimates distance Earth velocity relative Earth 24 nebulae.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nebulae data from Hubble (1929) — hubble","text":"","code":"hubble"},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Nebulae data from Hubble (1929) — hubble","text":"data frame 24 observations following 2 variables. distance: distance, megaparsecs, nebula   Earth. velocity: velocity, kilometres per second,   nebula relative Earth.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Nebulae data from Hubble (1929) — hubble","text":"Hubble, E. (1929) relation distance radial velocity among extra-galactic nebulae. Proceedings National Academy Science, 15, 168-173.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble2.html","id":null,"dir":"Reference","previous_headings":"","what":"Nebulae data from Freedman (2001) — hubble2","title":"Nebulae data from Freedman (2001) — hubble2","text":"Data update Hubble (1929) hubble data. Contains estimates distance Earth velocity relative Earth 24 nebulae.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nebulae data from Freedman (2001) — hubble2","text":"","code":"hubble2"},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Nebulae data from Freedman (2001) — hubble2","text":"data frame 24 observations following 2 variables. distance: distance, megaparsecs, nebula   Earth. velocity: velocity, kilometres per second,   nebula relative Earth.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Nebulae data from Freedman (2001) — hubble2","text":"velocity values column 7 Table 5 Freedman (2001) distance values corresponding values Table 4.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/hubble2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nebulae data from Freedman (2001) — hubble2","text":"Freedman et al. (2001) Final results Hubble space telescope key project measure Hubble constant. Astrophysical Journal, 553, 47-72.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":null,"dir":"Reference","previous_headings":"","what":"Kerrich's coin data — kerrich","title":"Kerrich's coin data — kerrich","text":"summary 10,000 coin throws conducted Jon Kerrich.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kerrich's coin data — kerrich","text":"","code":"kerrich"},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Kerrich's coin data — kerrich","text":"data frame 35 observations 2 variables: throws: number throws conducted. heads: corresponding cumulative number heads     obtained.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kerrich's coin data — kerrich","text":"data considered Section 3.2   STAT0002 notes.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kerrich's coin data — kerrich","text":"Kerrich, J. E. (1946). Experimental Introduction Theory   Probability. E. Munksgaard.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/kerrich.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kerrich's coin data — kerrich","text":"","code":"# This code produces the plot in Figure 3.1 of the STAT0002 notes plot(kerrich$throws, kerrich$heads / kerrich$throws,      ylab = \"proportion of heads\",      xlab = \"number of throws (logarithmic scale)\", lwd = 2, type = \"l\",      log = \"x\", ylim = c(0,1), axes = FALSE) abline(h = 0.5, lty = 2) axis(1, labels = as.character(c(3, 10, 30, 100, 300, 1000, 3000, 10000)),      at=c(3, 10, 30, 100, 300, 1000, 3000, 10000)) axis(2, labels = c(0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0),      at=c(0, 0.2, 0.4, 0.5, 0.6, 0.8, 1.0))"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Leverage and influence movie — lev_inf_movie","title":"Leverage and influence movie — lev_inf_movie","text":"movie examine influence single outlying observation least squares regression line. movie can also opened using smovie::movies() selecting Leverage influence Regression menu. based lev_inf function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leverage and influence movie — lev_inf_movie","text":"","code":"lev_inf_movie(association = c(\"positive\", \"negative\", \"none\"), n = 25)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Leverage and influence movie — lev_inf_movie","text":"association character scalar.  Determines type association (-outlying) observations: \"positive\" positive linear association; \"negative\" negative linear association; \"none\" association. n integer scalar.  size sample (non-outlying) observations.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Leverage and influence movie — lev_inf_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Leverage and influence movie — lev_inf_movie","text":"n pairs observations simulated property   mean response variable \\(y\\) linear function   values explanatory variable \\(x\\).  pairs observations   plotted using filled black circles.  extra observation plotted   using filled red circle.  Initially observation placed   middle plot. Superimposed plot two least squares regression lines:   one based data (`outlier') one   `red' observation removed (`without outlier'.   Initially lines coincide. location `red' observation can changed using   +/- buttons effect position observation   `outlier' line can seen. see red observation outlying, , far   least squares line fitted observations,   influence least squares regression line depends   x-coordinate.  x-coordinate much larger smaller   x-coordinate observations (high leverage)   influence higher similar x-coordinate   observations (low leverage).  observation high   leverage necessarily high influence: y-coordinate   falls close regression line fitted observations   influence low.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/lev_inf_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Leverage and influence movie — lev_inf_movie","text":"","code":"lev_inf_movie()  lev_inf_movie(association = \"none\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple linear regression movie — lin_reg_movie","title":"Simple linear regression movie — lin_reg_movie","text":"movie help visualize fitting regression line using least squares case simple linear regression, , linear regression one response variable one explanatory variable.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple linear regression movie — lin_reg_movie","text":"","code":"lin_reg_movie(data, delta_alpha = 0.1, delta_beta = 1e-04, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple linear regression movie — lin_reg_movie","text":"data data frame two variables numeric matrix 2 columns.  first column must contain response data, second column explanatory data. delta_alpha, delta_beta Numeric scalars.  respective amounts values intercept gradient line increased/decreased one click +/- button. default values set hubble data used example mind. ... arguments, graphical parameters (see par passed plot producing scatter plot response data explanatory data.  example, plotting character used points can chosen using pch. pch length greater 1 first element used.  default value pch 16 (filled circle). labels horizontal vertical axes can specified using xlab ylab respectively.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple linear regression movie — lin_reg_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simple linear regression movie — lin_reg_movie","text":"scatter plot response data explanatory data   produced.  plot superimposed dashed line user   can move, changing intercept alpha gradient beta   using +/- buttons.  initial value alpha mean   response data initial value beta 0.   sizes residuals shown using red lines.   One legends gives current sum squares residuals (SS). Another +/- button allows user add least squares regression   line plot, associated residual sum squares (RSS)   legend, comparison.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/lin_reg_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple linear regression movie — lin_reg_movie","text":"","code":"# Produce movie using the hubble data lin_reg_movie(hubble, pch = 16, xlab = \"recession velocity (km/sec)\",               ylab = \"distance (megaparsecs)\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lymphoma.html","id":null,"dir":"Reference","previous_headings":"","what":"T-cell count data — lymphoma","title":"T-cell count data — lymphoma","text":"numbers certain type T-cell (white blood cell) per cubic mm blood samples taken 42 patients remission lymphoma. 21 patients Hodgkin's lymphoma, 21 non-Hodgkin's lymphoma.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/lymphoma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"T-cell count data — lymphoma","text":"","code":"lymphoma"},{"path":"https://github.com/paulnorthrop/stat0002/reference/lymphoma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"T-cell count data — lymphoma","text":"data frame 42 observations following 2 variables. tcell: numeric vector giving number T-cells. type: factor giving type lymphoma: Hodgkin's   non-Hodgkin's.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"movie compare sampling distributions sample mean sample median based random sample size \\(n\\) standard normal distribution. movie can also opened using smovie::movies() selecting Mean vs median, normal Sampling distributions menu. based lev_inf function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"","code":"mean_vs_median_normal_movie(   n = 10,   delta_n = 1,   pos = 1,   envir = as.environment(pos) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"n integer scalar.  size samples drawn standard normal distribution. delta_n numeric scalar.  amount value sample size increased/decreased one click +/- button. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"movie based simulating repeatedly samples size   n standard normal N(0,1) distribution.  contains   three plots.  top plot contains histogram recently   simulated dataset, N(0,1) probability density function (p.d.f.)   superimposed. time sample simulated sample mean sample median   calculated.  values indicated top plot filled   circle: red circle sample mean blue circle   sample median; added values plotted middle   bottom plots. plot middle contains histogram   sample means simulated samples.  p.d.f.s   sampling distributions sample mean (thick red line)   sample medians (thin blue line) superimposed. plot bottom contains histogram   sample medians simulated samples.  p.d.f.s   sampling distributions sample mean (thin red line)   sample medians (thick blue line) superimposed. extra sample produced clicking + button next   \"number samples size n\". [Ignore - button.]   value sample size can changed using +/-   buttons panel.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_normal_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample mean vs sample median: normally distributed data — mean_vs_median_normal_movie","text":"","code":"mean_vs_median_normal_movie()"},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"movie compare sampling distributions sample mean sample median based random sample size \\(n\\) (central) Student's t distribution. movie can also opened using smovie::movies() selecting Mean vs median, Student t(2) Sampling distributions menu. based lev_inf function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"","code":"mean_vs_median_t_movie(   n = 10,   t_df = 2,   delta_n = 1,   pos = 1,   envir = as.environment(pos) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"n integer scalar.  size samples drawn Student's t distribution. t_df positive scalar.  degrees freedom Student's t distribution (see TDist). delta_n numeric scalar.  amount value sample size increased/decreased one click +/- button. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"movie based simulating repeatedly samples size   n central Student's t distribution degrees   freedom t_df.   contains three plots.   top plot contains histogram recently   simulated dataset, probability density function (p.d.f.)   Student's t distribution t_df degrees freedom   superimposed. time sample simulated sample mean sample median   calculated.  values indicated top plot filled   circle: red circle sample mean blue circle   sample median; added values plotted middle   bottom plots. plot middle contains histogram   sample means simulated samples. plot bottom contains histogram   sample medians simulated samples. extra sample produced clicking + button next   \"number samples size n\". [Ignore - button.]   value sample size can changed using +/-   buttons panel.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/mean_vs_median_t_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample mean vs sample median: Student's t distributed data — mean_vs_median_t_movie","text":"","code":"mean_vs_median_t_movie(t_df = 2)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal areas movie — normal_areas_movie","title":"Normal areas movie — normal_areas_movie","text":"movie show probability standard normal random variable lies within plus minus multiple standard deviation (, 1) varies value multiple.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal areas movie — normal_areas_movie","text":"","code":"normal_areas_movie(starting_multiple = 1, delta_multiple = 1, ndec = 3)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal areas movie — normal_areas_movie","text":"starting_multiple non-negative numeric scalar.  value multiple used first plot. delta_multiple numeric scalar.  amount value multiple increased/decreased one click +/- button. ndec number decimal places round probability superimposed plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal areas movie — normal_areas_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal areas movie — normal_areas_movie","text":"value multiple can changed using   +/buttons panel.   purposes movie, multiple increased   value 5.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_areas_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal areas movie — normal_areas_movie","text":"","code":"normal_areas_movie()"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal p.d.f. movie — normal_pdf_movie","title":"Normal p.d.f. movie — normal_pdf_movie","text":"movie show probability density function (p.d.f.) normal distribution varies mean /variance distribution changed. continuous distributions, including exponential uniform distributions, use smovie::movies() click Continuous menu. based continuous function. (installed smovie package use install.packages(\"smovie\") install .)","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal p.d.f. movie — normal_pdf_movie","text":"","code":"normal_pdf_movie(   starting_mean = 0,   starting_var = 1,   delta_mean = 0.1,   delta_var = 0.1 )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal p.d.f. movie — normal_pdf_movie","text":"starting_mean numeric scalar.  value mean used produce first plot p.d.f. starting_var positive numeric scalar.  value variance used produce first plot p.d.f. delta_mean numeric scalar.  amount value mean increased/decreased one click +/- button mean. delta_var numeric scalar.  amount value variance increased/decreased one click +/- button variance.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal p.d.f. movie — normal_pdf_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal p.d.f. movie — normal_pdf_movie","text":"values mean /variance can changed using   +/- buttons panel.   purposes movie, variance reduced   value 0.1.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_pdf_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal p.d.f. movie — normal_pdf_movie","text":"","code":"normal_pdf_movie()  normal_pdf_movie(delta_var = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal sampling distributions movie — normal_sampling_distns_movie","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"movie show sampling distributions sample mean sample variance based random sample normal distribution depend size \\(n\\) sample.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"","code":"normal_sampling_distns_movie(starting_n = 30, delta_n = 1, mu = 0, sigma = 1)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"starting_n numeric scalar.  value sample size used produce first plot p.d.f. delta_n numeric scalar.  amount value sample size increased/decreased one click +/- button. mu numeric scalar.  mean normal distribution random sample drawn. sigma numeric scalar.  standard deviation normal distribution random sample drawn.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"movie based two plots.  top plot shows   probability density function (p.d.f.) sampling distribution   sample mean, , N(\\(\\mu\\), \\(\\sigma\\)^2 / n) distribution.   bottom plot contains p.d.f. sampling distribution   sample variance, , gamma distribution   (GammaDist) shape parameter   \\((n - 1) / 2\\) rate parameter \\((n - 1) / 2\\sigma^2\\). number samples simulated increased value sample size can changed using +/-   buttons panel.  purposes movie value   \\(n\\) exceed 100.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/normal_sampling_distns_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal sampling distributions movie — normal_sampling_distns_movie","text":"","code":"normal_sampling_distns_movie()"},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births.html","id":null,"dir":"Reference","previous_headings":"","what":"Oxford Birth Times — ox_births","title":"Oxford Birth Times — ox_births","text":"Times spent delivery suite 95 women giving birth John Radcliffe Hospital, Oxford. data taken SMPracticals package provided Ethel Burns.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oxford Birth Times — ox_births","text":"","code":"ox_births"},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Oxford Birth Times — ox_births","text":"data frame 95 observations following 2 variables. day: Day woman arrived. time: Time (hours) spent delivery suite.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Oxford Birth Times — ox_births","text":"Davison, . C. (2003) Statistical Models. Cambridge University Press.   Page 18.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Oxford Birth Times Simulation Movie — ox_births_movie","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"movie illustrate increase size sample simulated continuous probability distribution histogram data gives closer approximation underlying probability density function (p.d.f.).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"","code":"ox_births_movie(starting_n = 100, delta_n = 1000)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"starting_n numeric scalar.  size first sample simulated. delta_n numeric scalar.  amount sample size increased (decreased) one click + (-) button parameter window.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"ox_births_movie first fits   gamma distribution   (see GammaDist) time data   ox_births data.  simulate samples (using   rgamma) fitted gamma distribution produce   histogram simulated data.  p.d.f. fitted gamma distribution   superimposed histogram. study gamma distribution STAT0002, encounter   STAT0003 take next term.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/ox_births_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Oxford Birth Times Simulation Movie — ox_births_movie","text":"","code":"ox_births_movie()"},{"path":"https://github.com/paulnorthrop/stat0002/reference/plot.poisson_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot diagnostics a poisson_process object — plot.poisson_process","title":"Plot diagnostics a poisson_process object — plot.poisson_process","text":"plot method class \"poisson_process\".","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/plot.poisson_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot diagnostics a poisson_process object — plot.poisson_process","text":"","code":"# S3 method for class 'poisson_process' plot(x, y, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/plot.poisson_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot diagnostics a poisson_process object — plot.poisson_process","text":"x object class \"poisson_process\", result call poisson_process_sim. y used. ... Additional arguments passed plot","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/plot.poisson_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot diagnostics a poisson_process object — plot.poisson_process","text":"Nothing returned.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/plot.poisson_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot diagnostics a poisson_process object — plot.poisson_process","text":"","code":"sim1 <- poisson_process_sim(lambda = 2, hours = 24) plot(sim1)  sim2 <- poisson_process_sim(lambda = 2, n_events = 50) plot(sim2, pch = 4, xlab = \"event times\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical checking of Poisson process properties — poisson_process_check","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"movie perform informal graphical checks whether event arrival times consistent arising (one-dimensional, homogeneous) Poisson process.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"","code":"poisson_process_check(   user_data = NULL,   total_time = NULL,   intervals = 1,   unif_bins = NULL,   exp_bins = NULL )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"user_data numeric vector arrival times events. total_time positive numeric scalar.  number time units (example hours) events user_data recorded.  Must smaller largest value user_data. intervals integer scalar.  Must smaller 1. number intervals split time interval (0, total_time) purposes checking property number events occur interval fixed width Poisson distribution.  intervals integer rounded nearest integer. unif_bins positive integer scalar.  number bins use histogram \"times events occur\" described Details.  supplied default number bins used hist used. exp_bins positive integer scalar.  number bins use histogram \"times events\" described Details.  supplied default number bins used hist used.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"movie contains two displays plots: one plot top   one three plots bottom.  rate, \\(\\lambda\\) say,   supposed Poisson process estimated sample mean number   events n_intervals, ,   length(user_data) / intervals.  call estimate   \\(m\\). type plot appears bottom display depends   radio click user. choices \"none\": Nothing plotted \"numbers events hour\": barplot (red bars) giving     proportions hours 0, 1 , 2, ... events.     Also included black bars showing p.m.f.     Poisson(\\(m\\)) random variable. \"times events\": histogram (red rectangles)     sample times events, p.d.f.     exponential(\\(m\\)) random variable superimposed. \"times events occur\": histogram (red rectangles)     simulated event times, p.d.f.     uniform(0, hours) random variable superimposed. type plot can changed clicking appropriate radio   button.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Graphical checking of Poisson process properties — poisson_process_check","text":"","code":"# Data in which an event occurs exactly on the hour poisson_process_check(user_data = (1:24), 24, 24)  poisson_process_check(user_data = (1:24), 24, 24, exp_bins = 100)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Poisson process movie — poisson_process_movie","title":"Poisson process movie — poisson_process_movie","text":"movie illustrate events arrive (one-dimensional, homogeneous) Poisson process rate \\(\\lambda\\) per hour () number events arrive fixed interval length \\(t\\) hours Poisson distribution mean \\(\\lambda t\\); (b) time successive events exponential distribution mean \\(1/\\lambda\\); (c) arrival times (ordered) random sample uniform distribution interval \\((0,t)\\).  Data simulated Poisson process illustrate .  Alternatively, use may supply arrival time data order assess, informally using graphs, whether data seem consistent arising Poisson process.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Poisson process movie — poisson_process_movie","text":"","code":"poisson_process_movie(   lambda = 1,   hours = 24,   pos = 1,   envir = as.environment(pos) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Poisson process movie — poisson_process_movie","text":"lambda positive numeric scalar.  rate Poisson process. [lambda must exceed 200 plots movie designed work larger values lambda.] hours positive integer scalar.  number hours simulate Poisson process rate lambda events per hour. purposes movie hours must smaller 1. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Poisson process movie — poisson_process_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Poisson process movie — poisson_process_movie","text":"movie contains two displays plots: one plot top   one three plots bottom. Data (repeatedly) simulated Poisson process rate   \\(\\lambda\\) events per hour occur time interval   (0, hours) hours.  total numbers events occur   hour also displayed plot.  time button \"simulate   another sequence events\" clicked new set simulated events   produced. type plot appears bottom display depends   radio button clicked user. choices \"none\": Nothing plotted \"numbers events hour\": barplot (red bars) giving     proportions hours 0, 1 , 2, ... events.     Also included black bars showing p.m.f.     Poisson(\\(\\lambda\\)) random variable. \"times events\": histogram (red rectangles)     simulated times events, p.d.f.     exponential(\\(\\lambda\\)) random variable superimposed. \"times events occur\": histogram (red rectangles)     simulated event times, p.d.f.     uniform(0, hours) random variable superimposed. time \"simulate another sequence events\" button clicked   [currently-selected radio button clicked ] new   set events simulated event added   current collection simulated events. Note: early stages simulations     heights black bars \"numbers events hour\"     plot may incorrect extend beyond plot region.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Poisson process movie — poisson_process_movie","text":"","code":"poisson_process_movie(lambda = 2)  poisson_process_movie(lambda = 10)  poisson_process_movie(lambda = 0.5)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulation of a Poisson process — poisson_process_sim","title":"Simulation of a Poisson process — poisson_process_sim","text":"Simulates event times (one-dimensional, homogeneous) Poisson process rate \\(\\lambda\\) per hour.  user options simulate events fixed time period hours hours simulate fixed number n_events events.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulation of a Poisson process — poisson_process_sim","text":"","code":"poisson_process_sim(lambda = 1, hours = 24, n_events = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulation of a Poisson process — poisson_process_sim","text":"lambda positive numeric scalar.  rate Poisson process. hours positive integer scalar.  number hours simulate Poisson process rate \\(\\lambda\\) events per hour. n_events positive integer scalar.  number events simulate.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulation of a Poisson process — poisson_process_sim","text":"numeric vector containing (ordered, smallest largest)   times events occur.  returned object class   \"poisson_process\".","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulation of a Poisson process — poisson_process_sim","text":"n_events supplied exactly n_events   simulated hours effect.  n_events   supplied events simulated time interval   (0, hours).  events occur (0, hours)   value \\(-1\\) returned.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/poisson_process_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulation of a Poisson process — poisson_process_sim","text":"","code":"sim1 <- poisson_process_sim(lambda = 2, hours = 24) plot(sim1)   sim2 <- poisson_process_sim(lambda = 2, n_events = 50) plot(sim2)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/print.screening_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Prints a screening_test object — print.screening_test","title":"Prints a screening_test object — print.screening_test","text":"print method class \"screening_test\".","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/print.screening_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prints a screening_test object — print.screening_test","text":"","code":"# S3 method for class 'screening_test' print(x, digits = max(3L, getOption(\"digits\") - 3L), ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/print.screening_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prints a screening_test object — print.screening_test","text":"x object class \"screening_test\", result call screening_test. digits integer.  number significant digits include printed probabilities.  Passed format. ... Additional arguments.  None used present.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/print.screening_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prints a screening_test object — print.screening_test","text":"Nothing returned.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/print.screening_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prints a screening_test object — print.screening_test","text":"","code":"screening_test(0.1, 0.9, 0.9) #> Prevalence, sensitivity, specificity: #>        P(D)     P(+ | D)  P(- | notD)   #>         0.1          0.9          0.9   #> P(positive test), positive and negative predictive values: #>        P(+)     P(D | +)  P(notD | -)   #>      0.1800       0.5000       0.9878"},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential Quantile-Quantile plots — qqexp","title":"Exponential Quantile-Quantile plots — qqexp","text":"Produces QQ plot compare ordered sample data corresponding quantiles exponential distribution fitted data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential Quantile-Quantile plots — qqexp","text":"","code":"qqexp(   y,   statistic = c(\"mean\", \"median\"),   type = 6,   envelopes = FALSE,   ...,   line = list(col = \"black\", lty = 1, lwd = 1) )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential Quantile-Quantile plots — qqexp","text":"y Sample data statistic character scalar. Selects summary statistic used estimate \\(\\lambda\\), either sample mean sample median. type integer scalar. statistic = \"median\" passed quantile select type sample quantile used estimate sample median. default, type = 6, selects estimator defined STAT002 notes. envelopes Determines whether simulation envelopes added plot.  envelopes = FALSE envelopes added. envelopes positive integer (common choice 19) simulation envelopes based many simulated datasets added. limits envelopes indicated using short horizontal lines. ... Optional arguments passed plot xlab, ylab, main /graphical parameters pch, lty lwd, control appearance main plot. change appearance line equality use argument line. line Determines whether line equality superimposed plot.  line required must list, can contain graphical parameters passed abline, col, lty lwd control appearance line. line list, example, line = 0, line superimposed.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential Quantile-Quantile plots — qqexp","text":"estimate \\(\\lambda\\).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exponential Quantile-Quantile plots — qqexp","text":"rate parameter \\(\\lambda\\) exponential distribution   estimated using 1/mean(y, na.rm = TRUE)   statistic = \"mean\"   log(2)/quantile(y, probs = 0.5, na.rm = TRUE)   statistic = \"median\".  ordered sample data plotted   quantiles fitted exponential distribution. Specifically,   \\(\\)th smallest sample observation plotted   \\(100 / (n + 1)\\%\\) theoretical exponential quantile, \\(n\\)   sample size. plot constrained square. line equality   superimposed plot.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/qqexp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential Quantile-Quantile plots — qqexp","text":"","code":"## Australian Birth Times Data  # Calculate the waiting times until each birth waits <- diff(c(0, aussie_births[, \"time\"]))  # Estimating lambda using the sample mean qqexp(waits)  #> estimate of lambda  #>         0.03066202   # Change the appearance of the points and line qqexp(waits, pch = 16, line = list(lty = 2, col = \"blue\", lwd = 2))  #> estimate of lambda  #>         0.03066202   # Add simulation envelopes qqexp(waits, envelopes = 19)  #> estimate of lambda  #>         0.03066202   # Estimating lambda using the sample median qqexp(waits, statistic = \"median\", envelopes = 19)  #> estimate of lambda  #>          0.0261565"},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile-Quantile plot movie — qq_plot_movie","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"movie illustrate constructions normal Quantile-Quantile (QQ) plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"","code":"qq_plot_movie(data = NULL, mu = NULL, sigma = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"data numeric vector.  Data base QQ plot. mu, sigma Numeric scalars.  mean standard deviation normal distribution data data compared. mu /sigma supplied estimated data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"movie enables user scroll forwards backwards   plots describe way (normal) QQ plot   produced.  movie designed simple illustrative examples   small numbers observations, , small   length(data).  example 9 observations.   cases many observations plots   bit mess!","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/qq_plot_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile-Quantile plot movie — qq_plot_movie","text":"","code":"# Create the same dataset used in the lecture notes/slides set.seed(382) x <- sort(round(rnorm(9, mean = 7.72, sd = 3.57), 2)) qq_plot_movie(data = x, mu = 7.72, sigma = 3.57)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulates from a binomial distribution — rbinomial","title":"Simulates from a binomial distribution — rbinomial","text":"Simulates one value binomial distribution parameters size (number independent Bernoulli trials) prob (probability success given trial).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulates from a binomial distribution — rbinomial","text":"","code":"rbinomial(size, prob)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulates from a binomial distribution — rbinomial","text":"size integer scalar.  number trials. prob numeric scalar.  probability success trial.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulates from a binomial distribution — rbinomial","text":"numeric scalar: simulated number successes size   trials.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulates from a binomial distribution — rbinomial","text":"Take look function's code Stochastic Simulation vignette see whether can understand works.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/rbinomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulates from a binomial distribution — rbinomial","text":"","code":"# Simulate one value from a binomial(6, 0.2) distribution. rbinomial(size = 6, prob = 0.2) #> [1] 1"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter plot with five number summary — scatter","title":"Scatter plot with five number summary — scatter","text":"Produces scatter plot axes labelled respective five number summaries horizontal vertical axis data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter plot with five number summary — scatter","text":"","code":"scatter(x, y, ndec = 1, type = 6, na.rm = FALSE, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter plot with five number summary — scatter","text":"x argument x plot. y argument x plot. ndec numeric vector.  numbers decimal places round five number summaries.  ndec scalar value used axes. type Argument type used call five_number estimate 25%, 50% 75% quantiles. na.rm logical scalar.  true, NA NaNs removed sample quantiles computed. ... arguments passed plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter plot with five number summary — scatter","text":"Nothing, just plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter plot with five number summary — scatter","text":"","code":"x <- rnorm(100) y <- rnorm(100) scatter(x, y)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"movie illustrate effects transformation variable(s) appearance scatter plot, using 2000 U.S. Presidential Election data Florida.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"","code":"scatterplot_movie(   x,   y,   delta_power = 0.1,   pos = 1,   envir = as.environment(pos),   ... )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"x, y Numeric vectors length.  Pairs values plot using scatter plot.  values x plotted horizontal axis, values y vertical axis. delta_power numeric scalar.  amount powers x y increase/decrease one click button parameter window. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment. ... arguments passed plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"scatterplot_movie produces scatter plot input   variables x y can animated   transforming x /y using power transformations.   [fact   Box-Cox transformation   used.]   power x y chosen using parameter windows   containing buttons labelled + -.   Clicking + increases power delta_power   clicking - decreases power delta_power.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatterplot_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"US 2000 Presidential Election Movie: straightening scatter plots — scatterplot_movie","text":"","code":"# Proportion of votes gained by Buchanan pbuch <- 100 * USelection$buch / USelection$tvot  # Produce plot scatterplot_movie(x = USelection$npop, y = pbuch)  # Change the plotting character scatterplot_movie(x = USelection$npop, y = pbuch, pch = 16)   # Identify Palm Beach using a different plotting character county_name <- USelection[, \"co_names\"] pb <- which(county_name == \"PalmBeach\") my_pch <- rep(16, length(county_name)) my_pch[pb] <- 4 scatterplot_movie(x = USelection$npop, y = pbuch, pch = my_pch)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter_hist.html","id":null,"dir":"Reference","previous_headings":"","what":"Scatter plot with marginal histograms — scatter_hist","title":"Scatter plot with marginal histograms — scatter_hist","text":"Produces scatter plot axes supplemented histograms marginal horizontal vertical axis data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter_hist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scatter plot with marginal histograms — scatter_hist","text":"","code":"scatter_hist(x, y, xbreaks = NULL, ybreaks = NULL, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter_hist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scatter plot with marginal histograms — scatter_hist","text":"x argument x plot. y argument x plot. xbreaks numeric vector.  Optional argument breaks hist plotting histogram horizontal axis. ybreaks numeric vector.  Optional argument breaks hist plotting histogram vertical axis. ... arguments passed plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter_hist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scatter plot with marginal histograms — scatter_hist","text":"Nothing, just plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/scatter_hist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scatter plot with marginal histograms — scatter_hist","text":"","code":"x <- rnorm(100) y <- rnorm(100) scatter_hist(x, y)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Screening test calculations — screening_test","title":"Screening test calculations — screening_test","text":"Consider screening test certain disease condition, applied person certain prior, pre-test probability disease. person function calculates probabilities : person disease given test positive; person disease given test negative.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Screening test calculations — screening_test","text":"","code":"screening_test(prior, sensitivity, specificity)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Screening test calculations — screening_test","text":"prior numeric scalar.  pre-test probability \\(P(D)\\) person disease.  absence specific information prevalence disease population, , proportion people disease general population interest. sensitivity numeric scalar.  conditional probability person disease tests positive.  \\(+\\) event randomly chosen person tests positive sensitivity \\(P(+ \\mid D)\\). specificity numeric scalar.  conditional probability person disease tests negative.  \\(-\\) event randomly chosen person test negative sensitivity \\(P(- \\mid {\\rm }D)\\).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Screening test calculations — screening_test","text":"list containing following components pp probability \\(P(+)\\) person test positive. ppv positive predictive value. conditional probability \\(P(D \\mid +)\\) person tests positive disease. npv negative predictive value. conditional probability \\(P({\\rm }D \\mid -)\\) person tests negative disease. prior,sensitivity,specificity input values prior, sensitivity specificity.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Screening test calculations — screening_test","text":"required probabilities calculated using law total probability $$P(+) = P(+ \\mid D) P(D) + P(+ \\mid {\\rm }D) P({\\rm }D)$$ Bayes' theorem $$P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)}$$ $$P({\\rm }D \\mid -) = \\frac{P(- \\mid {\\rm }D) P({\\rm }D)}{P(-)}.$$","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/screening_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Screening test calculations — screening_test","text":"","code":"screening_test(prior = 0.1, sensitivity = 0.9, specificity = 0.9) #> Prevalence, sensitivity, specificity: #>        P(D)     P(+ | D)  P(- | notD)   #>         0.1          0.9          0.9   #> P(positive test), positive and negative predictive values: #>        P(+)     P(D | +)  P(notD | -)   #>      0.1800       0.5000       0.9878"},{"path":"https://github.com/paulnorthrop/stat0002/reference/sea_temps.html","id":null,"dir":"Reference","previous_headings":"","what":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","title":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","text":"Annual average sea surface temperature anomalies (1961-1990 average) Southern Hemisphere 1850-2022.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/sea_temps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","text":"","code":"sea_temps"},{"path":"https://github.com/paulnorthrop/stat0002/reference/sea_temps.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","text":"dataframe 173 rows 2 columns: year: year. temp: temperature anomaly degrees C.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/sea_temps.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","text":"Kennedy, J. J., Rayner, N. ., Atkinson, C. P., & Killick, R. E.   (2019). ensemble data set sea surface temperature change 1850:   Met Office Hadley Centre HadSST.4.0.0.0 data set.   Journal Geophysical Research: Atmospheres, 124,   7719 - 7763. doi:10.1029/2018JD029867 .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/sea_temps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Southern Hemisphere temperature anomalies 1850-2022 — sea_temps","text":"","code":"# Extract data from 1946-2022 s46 <- sea_temps[sea_temps$year> 1945, ] plot(s46, ylab = \"temperature difference (degrees C)\")"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle.html","id":null,"dir":"Reference","previous_headings":"","what":"Challenger Space Shuttle Disaster Dataset — shuttle","title":"Challenger Space Shuttle Disaster Dataset — shuttle","text":"data discussed first STAT0002 lecture. paper (Dalal et al., 1989) data analysed view estimating (retrospectively) probability catastrophic failure Challenger space shuttle launch conditions 28th January 1986.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Challenger Space Shuttle Disaster Dataset — shuttle","text":"","code":"shuttle"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Challenger Space Shuttle Disaster Dataset — shuttle","text":"dataframe 24 rows 5 columns: flight: flight number. date: date. damaged: number O-rings thermal distress. temperature: temperature, degrees Fahrenheit. pressure: pressure, pounds per square inch. first 23 rows contain data test flights.  last row contains data ill-fated flight 28th January 1986, number damaged 0-rings missing (NA).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Challenger Space Shuttle Disaster Dataset — shuttle","text":"Dalal, S. R, Fowlkes, E. B. Hoadley, B. (1989)   Risk Analysis Space Shuttle: Pre-Challenger Prediction   Failure. Journal American Statistical Association,   84(408), 945-957.   http://dx.doi.org/10.1080/01621459.1989.10478858","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Challenger Space Shuttle Disaster Movie — shuttle_movie","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"movie illustrate uncertainty linear logistic regression curves fitted real space shuttle data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"","code":"shuttle_movie(n_reps = 1, pos = 1, envir = as.environment(pos))"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"n_reps integer scalar.  Relevant shuttle_movie . number flights simulate 23 (pre-disaster) temperatures real dataset. example, n_reps = 10 means simulate dataset size 230. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"shuttle_movie produces animated version plot produced shuttle_sim_plot. Calling `shuttle_movie` creates plot containing real data logistic curve fitted real data opens parameter window containing buttons labelled + -. Clicking + adds plot new simulated dataset logistic curve fitted dataset. Clicking - removes mostly recently added dataset.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Challenger Space Shuttle Disaster Movie — shuttle_movie","text":"","code":"# Movie based on datasets of size 23 shuttle_movie()   # Movie based on datasets of size 230 shuttle_movie(n_reps = 10)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate fake space shuttle data — shuttle_sim","title":"Simulate fake space shuttle data — shuttle_sim","text":"Simulates fake O-ring thermal distress data Challenger Space Shuttle launches different launch temperatures.  simulated data based linear logistic regression model fitted real data 23 (pre-disaster) launches.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate fake space shuttle data — shuttle_sim","text":"","code":"shuttle_sim(n_sim = 1, temperature = NULL)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate fake space shuttle data — shuttle_sim","text":"n_sim integer scalar. number fake datasets simulate. temperature numeric vector launch temperatures. temperature supplied 23 launch temperatures   real dataset used. temperature supplied must vector length one   (.e. scalar). event n_sim gives number   simulated numbers damaged O-rings launch temperature   temperature.  temperature length greater one   first element temperature used warning   given.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate fake space shuttle data — shuttle_sim","text":"output depends whether temperature supplied user. temperature supplied shuttle_sim returns dataframe 2 + n_sim columns. Column 1 contains launch temperatures, column 2 contains numbers distressed O-rings real data columns 3 2 + n_sim n_sim simulated datasets. temperature supplied shuttle_sim returns vector length n_sim.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate fake space shuttle data — shuttle_sim","text":"data simulated linear logistic regression model   fitted real (pre-disaster) O-ring distress launch   temperature data.  given launch temperature \\(t\\) model   provides estimate, \\(\\hat{p}(t)\\) say, probability   O-ring suffers thermal distress.  number 6 O-rings   suffers thermal distress simulated   binomial(6, \\(\\hat{p}(t)\\)) distribution, assumption   fates O-rings independent.  repeated   launch temperatures temperatures.   details see   Challenger Space Shuttle Disaster   vignette.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate fake space shuttle data — shuttle_sim","text":"","code":"# Simulate 10 fake datasets of size 23, using the real temperatures. res <- shuttle_sim(n_sim = 10) res #>    temps real sim1 sim2 sim3 sim4 sim5 sim6 sim7 sim8 sim9 sim10 #> 1     66    0    1    0    0    1    1    0    1    0    1     1 #> 2     70    1    0    1    0    0    0    0    0    2    0     0 #> 3     69    0    0    0    2    0    0    0    0    0    2     1 #> 4     68    0    1    0    0    1    0    0    2    0    0     1 #> 5     67    0    0    1    0    2    0    0    1    1    0     0 #> 6     72    0    0    0    0    0    1    0    2    2    0     0 #> 7     73    0    0    1    0    1    0    0    0    0    1     0 #> 8     70    0    0    0    0    0    2    0    1    0    0     0 #> 9     57    1    1    1    1    2    1    2    0    0    0     0 #> 10    63    1    2    0    0    0    0    0    1    0    1     0 #> 11    70    1    0    0    1    0    0    0    0    0    0     1 #> 12    78    0    0    0    0    0    0    0    1    0    0     0 #> 13    67    0    1    2    0    0    1    1    0    0    2     0 #> 14    53    3    3    3    2    4    3    0    2    1    4     2 #> 15    67    0    0    0    2    0    1    1    0    0    0     0 #> 16    75    0    1    0    0    0    0    0    0    0    0     0 #> 17    70    0    1    0    0    0    0    0    0    1    0     0 #> 18    81    0    1    0    0    0    0    0    0    0    0     0 #> 19    76    0    0    0    0    0    2    0    0    0    0     0 #> 20    79    0    0    0    1    0    0    0    0    0    0     0 #> 21    75    2    0    0    0    0    0    0    0    0    0     0 #> 22    76    0    0    0    0    0    0    0    0    0    0     0 #> 23    58    1    1    0    1    3    0    2    1    1    0     2 # Simulate the number of distressed O-rings for 1000 launches at 31 deg F. res <- shuttle_sim(n_sim = 1000, temperature = 31) res[1:100] #>   [1] 4 6 5 6 5 6 6 6 5 6 6 5 5 6 6 6 5 4 6 6 4 5 5 6 6 4 6 6 6 6 6 6 6 6 6 6 5 #>  [38] 6 6 6 4 6 6 6 6 5 6 6 5 6 5 6 6 6 5 5 4 6 5 5 6 6 6 5 5 6 5 6 6 6 5 6 6 6 #>  [75] 4 5 6 5 5 5 6 6 6 6 6 5 6 6 6 6 4 6 4 5 6 6 6 6 6 6 table(res) #> res #>     2     3     4     5     6  #>    13   189  1571  7380 13847"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":null,"dir":"Reference","previous_headings":"","what":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"Illustrates uncertainty estimated probability O-ring suffering thermal distress given launch temperature.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"","code":"shuttle_sim_hists(x, temps, ...)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"x 2-column matrix returned call shuttle_sim_plot temps numeric vector temperatures, degrees Fahrenheit. ... arguments passed hist. [Apart probability, xlab, ylab main, set inside shuttle_sim_hists.]","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"Nothing, just plot.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"details linear logistic model see   Challenger Space Shuttle Disaster   vignette simulation model see   shuttle_sim.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_hists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Space shuttle: uncertainty in estimated probability of O-ring damage — shuttle_sim_hists","text":"","code":"x <- shuttle_sim_plot(n_sim = 1000, plot = FALSE) shuttle_sim_hists(x, temps = c(31, 50, 65, 80), col = 8)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"Illustrates uncertainty fitted values probability O-ring distress different values temperature, based linear logistic regression model fitted real data. Fake data fitted model simulated repeatedly using function shuttle_sim.  linear logistic model fitted simulated datasets. plot produced containing real proportions distressed O-rings, logistic curve fitted real data logistic curves fitted fake data.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"","code":"shuttle_sim_plot(   n_sim = 50,   plot_real_data = TRUE,   n_reps = 1,   plot = TRUE,   ... )"},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"n_sim integer scalar.  number fake datasets simulate, hence number curves simulated data appear plot. plot_real_data logical scalar.  add plot real data linear logistic curve fitted real data? real_data = TRUE “yes” real_data = FALSE “”. n_reps integer scalar.  number flights simulate 23 (pre-disaster) temperatures real dataset. example, n_reps = 10 means simulate dataset size 230. plot logical scalar indicating whether produce plot. ... arguments passed lines function used draw curves simulated datasets.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"numeric matrix 2 columns n_sim rows.   row contains estimates parameters linear   logistic regression model fitted simulated dataset.   first column, alpha_hat, contains estimates   intercept parameter, second column, beta_hat,   estimates slope parameter.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"details linear logistic model see   Challenger Space Shuttle Disaster   vignette simulation model see   shuttle_sim.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/shuttle_sim_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Space shuttle: uncertainty in fitted linear logistic regression curve — shuttle_sim_plot","text":"","code":"shuttle_sim_plot(n_sim = 50)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample skewness functions — skewness","title":"Sample skewness functions — skewness","text":"Calculates sample measures skewness (sample quartile skewness standardized sample skewness) vector data, column matrix data, based estimators described STAT002 notes.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample skewness functions — skewness","text":"","code":"q_skew(x, type = 6, na.rm = FALSE)  skew(x, na.rm = FALSE)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample skewness functions — skewness","text":"x numeric vector matrix. type Relevant q_skew .  Argument type used call quantile estimate 25%, 50% 75% quantiles. na.rm logical scalar.  true, NA NaNs removed x constituent parts sample skewness computed.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample skewness functions — skewness","text":"numeric scalar (input vector) vector (input   matrix).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample skewness functions — skewness","text":"See Chapter 2 STAT002 notes. Sample quartile skewness. Let \\(q_L\\), \\(m\\) \\(q_U\\) sample lower quartile,   mean upper quartile respectively.  measure skewness often called   quartile skewness given   $$[ (q_U - m) - (m - qL) ] / (q_U - q_L).$$ Standardized sample skewness. Denote vector data \\((x_1, ..., x_n)\\) let \\(\\bar{x}\\) \\(s\\) sample mean sample standard deviation respectively. standardized sample skewness given $$(1 / n) \\sum_{=1}^n (x_i - \\bar{x}) ^ 3 / s ^ 3.$$","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/skewness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample skewness functions — skewness","text":"","code":"birth_times <- ox_births[, \"time\"] skew(birth_times) #> [1] 0.6254774 q_skew(birth_times) #> [1] -0.07216495"},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-internal.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal stat0002 functions — stat0002-internal","title":"Internal stat0002 functions — stat0002-internal","text":"Internal stat0002 functions","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-internal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal stat0002 functions — stat0002-internal","text":"","code":"is.positiveinteger(x, tol = .Machine$double.eps^0.5)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-internal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal stat0002 functions — stat0002-internal","text":"functions intended called user.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":null,"dir":"Reference","previous_headings":"","what":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"Provides example datasets, R code tutorials help students taking STAT0002 Introduction Probability Statistics University College London understand course material see R can used perform analyses course. package can also used complement STAT0004 Introduction Practical Statistics, enabling students become familiar R code seeing action playing .","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"useful source information stat0002 home page GitHub. Reference page provides information example datasets, movies (interactive plots), functions performing tasks like creating plot, calculating summary statistics simulating data. tab labelled Articles (use Articles link) contains several tutorials demonstrating use R create content STAT0002 notes related tasks. movies made available via smovie package.  can access menu movies smovie using library(smovie) movies(). See movies details.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":"summary-of-the-main-resources","dir":"Reference","previous_headings":"","what":"Summary of the main resources","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"Tutorials Example data Movies. See also movies Plots Summary statistics Simulation functions","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":"please-note","dir":"Reference","previous_headings":"","what":"Please note","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"main source information material STAT0002 STAT0002 Moodle page. required use `stat0002` package STAT0002, recommended supplement STAT0002 syllabus.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":"how-to-learn-about-r","dir":"Reference","previous_headings":"","what":"How to learn about R","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"best way learn use computer program play code see .  R based functions look like name(), name name function various arguments inserted inside brackets ().  R code provided package see many functions like .  find function called name use either ?name help(name). questions package please ask via stat0002 R package Moodle Forum.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"stat0002: Introduction to Probability and Statistics at UCL — stat0002-package","text":"Maintainer: Paul J. Northrop p.northrop@ucl.ac.uk [copyright holder]","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002movies.html","id":null,"dir":"Reference","previous_headings":"","what":"General information about the movies — stat0002movies","title":"General information about the movies — stat0002movies","text":"movies animations used illustrate key ideas STAT0002.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002movies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"General information about the movies — stat0002movies","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002movies.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"General information about the movies — stat0002movies","text":"list movies see Movies. one functions called R opens small parameter window containing clickable buttons can used change parameters underlying plot. effects buttons see documentation individual functions . parameter window close automatically movie: user needs close manually. movies create objects global environment, , objects listed ls() used.  rm can used remove objects desired.  example rm(name) can used remove object name. smovie package provides user-friendly menu can access movies. Use library(smovie) movies(). See movies details.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/stat0002movies.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General information about the movies — stat0002movies","text":"See examples given individual movies detailed Movies section Reference part stat0002 home page GitHub","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"movie study distribution Pearson chi-squared test statistic used test lack association 2 2 contingency table.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"","code":"two_by_two_movie(data, bin_width = 0.25, pos = 1, envir = as.environment(pos))"},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"data numeric 2 2 matrix, giving observed frequencies 2 2 contingency table. bin_width numeric scalar.  width bins histogram test statistics plotted bottom movie. pos numeric integer.  Used calls assign make information available across successive frames movie. default, uses current environment. envir alternative way (pos) specifying environment. See environment.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"movie split three sections.   top left table displaying contingency table based   frequencies data, row totals, column totals   grand total added.  data row column names   first letters added table.   top right similar table containing frequencies based   simulated data.  simulated data grand total   data.  data simulated assumption   value variable row table associated   value variable column table.   See Section 8.1.2 STAT0002 notes details. tables calculation Pearson   chi-squared test statistic given.  Every time new simulated dataset   produced value test statistic added histogram   containing test statistics simulated data produced.   recent simulated test statistic indicated plot   red circle.   test statistic produced real data indicated plot   blue circle.   p.d.f. chi-squared random variable   one degree freedom superimposed plot.   expected frequencies based real data sufficiently   large distribution test statistic null   hypothesis association approximately distribution. Three radio buttons enable user choose whether simulate   1, 100 1000 datasets.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/two_by_two_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test for lack of association in a 2 by 2 contingency table — two_by_two_movie","text":"","code":"# Ignore department sex_outcome <- apply(UCBAdmissions, 2:1, FUN = sum) colnames(sex_outcome) <- c(\"A\", \"R\") rownames(sex_outcome) <- c(\"M\", \"F\") two_by_two_movie(data = sex_outcome)   # Conditon on department 1 sex_outcome_1 <- UCBAdmissions[, , 1] colnames(sex_outcome_1) <- c(\"A\", \"R\") rownames(sex_outcome_1) <- c(\"M\", \"F\") two_by_two_movie(data = sex_outcome_1)   # Conditon on department 2 sex_outcome_2 <- UCBAdmissions[, , 2] colnames(sex_outcome_2) <- c(\"A\", \"R\") rownames(sex_outcome_2) <- c(\"M\", \"F\") two_by_two_movie(data = sex_outcome_2)"},{"path":"https://github.com/paulnorthrop/stat0002/reference/USelection.html","id":null,"dir":"Reference","previous_headings":"","what":"The 2000 U.S. Presidential Election in Florida — USelection","title":"The 2000 U.S. Presidential Election in Florida — USelection","text":"Voting results demographic data state Florida United States presidential election year 2000.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/USelection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The 2000 U.S. Presidential Election in Florida — USelection","text":"","code":"USelection"},{"path":"https://github.com/paulnorthrop/stat0002/reference/USelection.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The 2000 U.S. Presidential Election in Florida — USelection","text":"data frame 67 observations 22 variables. row relates county Florida. Columns 1-4, county identifiers location:   county number co, county name co_names,   latitude degrees north lat,   longitude degrees west lon. Columns 5-12, county demographic variables:  population 1997 npop, percentage whites 1996 whit, percentage blacks 1996 blac, percentage Hispanics 1996 hisp, percentage population aged 65 1996 o65, percentage population graduated high school (1990 census) hsed, percentage population graduated college (1990 census) coll, mean personal income (1994) inco. Columns 13-22, numbers votes candidates: Bush bush, Gore gore, Browne brow, Nader nade, Harris harr, Hagelin hage, Buchanan buch, McReynolds mcre, Phillips phil, Moorehead moor. Column 23, total number votes cast: tvot. full details see Tables 1 4 Smith (2002).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/USelection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"The 2000 U.S. Presidential Election in Florida — USelection","text":"Smith, R. L. (2002) Statistical Assessment Buchanan's   Vote Palm Beach County, Statistical Science, 17(4),   441-457, http://dx.doi.org/10.1214/ss/1049993203.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank.html","id":null,"dir":"Reference","previous_headings":"","what":"World Bank Data — world_bank","title":"World Bank Data — world_bank","text":"Selected annual World Development Indicators provided World Bank's World Development Indicators database countries world, 1960-2014.  indicators co2_per_capita: total carbon dioxide emissions per     capita, metric tons per person gdp_per_capita: Gross Domestic Product (GDP) per     capita, current US dollars per person population_size: total population size life_expectancy: life expectancy birth, years","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"World Bank Data — world_bank","text":"","code":"co2_per_capita  gdp_per_capita  population_size  life_expectancy"},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"World Bank Data — world_bank","text":"data frame 217 rows (one country) one column   year data, .e 55 columns.   names countries given row names dataset,   e.g. rownames(popn). object class data.frame 217 rows 55 columns. object class data.frame 217 rows 55 columns. object class data.frame 217 rows 55 columns. object class data.frame 217 rows 55 columns.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"World Bank Data — world_bank","text":"World Bank's World Development Indicators database.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank_movie.html","id":null,"dir":"Reference","previous_headings":"","what":"World Bank Development Indicators Movie — world_bank_movie","title":"World Bank Development Indicators Movie — world_bank_movie","text":"Explores graphically relationships four annual World Development Indicators provided World Bank's database countries world, 1960-2014.  Animation used visualise variables inter-relationships vary time.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank_movie.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"World Bank Development Indicators Movie — world_bank_movie","text":"Nothing returned, animation produced.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank_movie.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"World Bank Development Indicators Movie — world_bank_movie","text":"example code Examples creates scatter plot data variables given first two arguments function, .e. log(gdp_per_capita) log(co2_per_capita). pair values represented circle.  area circle proportional argument size, .e. population_size argument col indicates approximate value fourth variable, .e. life_expectancy. scatter plot can animated years points individual country can highlighted red clicking name country. See rp.bubbleplot information. type plot used great effect Hans Rosling. see Hans explain simple terms scientific political issues surrounding data see video","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/reference/world_bank_movie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"World Bank Development Indicators Movie — world_bank_movie","text":"","code":"# Produce the movie.  You may ignore the warning message that is produced. # (I think the cause may be that some countries have a lot of missing data.) got_tcltk <- requireNamespace(\"tcltk\", quietly = TRUE) if (got_tcltk) {   rpanel::rp.bubbleplot(log(gdp_per_capita), log(co2_per_capita), 1960:2014,                         size = population_size, col = life_expectancy,                         interpolate = TRUE, hscale = 1.5, vscale = 1.5) } #> Warning: NaNs produced"},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"stat0002-123-1792024","dir":"Changelog","previous_headings":"","what":"stat0002 1.2.3: 17/9/2024","title":"stat0002 1.2.3: 17/9/2024","text":"Updates 2025/26 session.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"stat0002-122-2292024","dir":"Changelog","previous_headings":"","what":"stat0002 1.2.2: 22/9/2024","title":"stat0002 1.2.2: 22/9/2024","text":"Minor edits 2024/25 session.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"stat0002-121-2492023","dir":"Changelog","previous_headings":"","what":"stat0002 1.2.1: 24/9/2023","title":"stat0002 1.2.1: 24/9/2023","text":"Minor edits 2023/24 session owing changes assessments.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"new-features-1-2-1","dir":"Changelog","previous_headings":"","what":"New features","title":"stat0002 1.2.1: 24/9/2023","text":"new Article, Stochastic Simulation 2, providing details supplement article Stochastic Simulation.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"stat0002 1.2.0: 9/12/2022","text":"new Article, relating Chapter 10 (Correlation) STAT0002 notes. Added dataset exchange, UK/USA/Canadian exchange rates considered Section 10.1 notes.","code":""},{"path":[]},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"stat0002 1.1.0: 4/12/2022","text":"New Articles, relating Chapters 7 (Statistical Inference), 8 (Contingency Tables) 9 (Linear Regression) STAT0002 notes. Added dataset hubble2, update original Hubble (1929) data Freedman et al. (2001).","code":""},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"bug-fixes-and-minor-improvements-1-1-0","dir":"Changelog","previous_headings":"","what":"Bug fixes and minor improvements","title":"stat0002 1.1.0: 4/12/2022","text":"Minor typographical corrections, updating section numbers referring parts STAT0002 notes.","code":""},{"path":"https://github.com/paulnorthrop/stat0002/news/index.html","id":"stat0002-100","dir":"Changelog","previous_headings":"","what":"stat0002 1.0.0","title":"stat0002 1.0.0","text":"Version released students start 2022-23 academic session","code":""}]
